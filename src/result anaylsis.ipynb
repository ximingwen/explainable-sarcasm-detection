{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7669af3-aa13-4cd0-a896-b4217f1cf66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import data_helpers\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "from time import sleep\n",
    "import pickle, argparse\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from tensorflow.keras import layers, Model, regularizers\n",
    "from tensorflow import keras \n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def make_variables(tf_name, k1, k2, initializer):\n",
    "     \n",
    "    return tf.Variable(initializer(shape=[k1, k2], dtype=tf.float32), trainable=True, name=tf_name)\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, data, batch_size=200, shuffle=True):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the number of batches\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Shuffles the indexes if required\n",
    "        data = pd.DataFrame(self.data).to_numpy()\n",
    "        data_size = len(data)\n",
    "        num_batches_per_epoch = int((len(data)-1)/self.batch_size) + 1\n",
    "      \n",
    "        if self.shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        \n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * self.batch_size\n",
    "            end_index = min((batch_num + 1) * self.batch_size, data_size)\n",
    "            output = list(zip(*shuffled_data[start_index:end_index]))\n",
    "            yield output[0],  output[1],  output[2],  output[3]\n",
    "       \n",
    "\n",
    "            \n",
    "#prototype layer\n",
    "class prototypeLayer(keras.layers.Layer):\n",
    "    def __init__(self, k_protos, vect_size, k_cents):\n",
    "        super(prototypeLayer, self).__init__(name='proto_layer')\n",
    "        self.n_protos = k_protos\n",
    "        self.vect_size = vect_size\n",
    "        self.prototypes = make_variables(\"prototypes\", k_protos, vect_size,\n",
    "                                         initializer=tf.constant_initializer(k_cents))\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        tmp1 = tf.expand_dims(inputs, 2)\n",
    "\n",
    "        tmp1 = tf.broadcast_to(tmp1, [tf.shape(tmp1)[0], tf.shape(tmp1)[1], self.n_protos, self.vect_size])\n",
    "        tmp2 = tf.broadcast_to(self.prototypes,\n",
    "                               [tf.shape(tmp1)[0], tf.shape(tmp1)[1], self.n_protos, self.vect_size])\n",
    "        tmp3 = tmp1 - tmp2\n",
    "        tmp4 = tmp3 * tmp3\n",
    "        distances = tf.reduce_sum(tmp4, axis=3)\n",
    "\n",
    "        return distances, self.prototypes\n",
    "\n",
    "#distance layer: to convert the full distance matrix to sparse similarity matrix\n",
    "class distanceLayer(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(distanceLayer, self).__init__(name='distance_layer')\n",
    "        self.a = 0.1\n",
    "        self.beta = 1e6\n",
    "\n",
    "    def e_func(self, x, e=2.7182818284590452353602874713527):\n",
    "        return tf.math.pow(e, -(self.a * x))\n",
    "\n",
    "    # @tf.function\n",
    "    # def call(self, full_distances):\n",
    "    #     min_dist_ind = tf.nn.softmax(-full_distances * self.beta)\n",
    "    #     e_dist = self.e_func(full_distances) + 1e-8\n",
    "    #     dist_hot_vect = min_dist_ind * e_dist\n",
    "    #     return dist_hot_vect\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, full_distances):\n",
    "        e_dist = self.e_func(full_distances) + 1e-8\n",
    "        dist_hot_vect = tf.squeeze(e_dist, axis=0)\n",
    "        return dist_hot_vect\n",
    "\n",
    "\n",
    "class TextCNN(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    A CNN for text classification in TensorFlow 2.x.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling, and softmax layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, sequence_length, num_classes, tokenizer, bert_model, user_embeddings, topic_embeddings, embedding_size, filter_sizes, num_filters, l2_reg_lambda, dropout_keep_prob, k_protos, vect_size):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.max_l = sequence_length\n",
    "        self.l2_reg_lambda = l2_reg_lambda\n",
    "        l2_regularizer = tf.keras.regularizers.l2(l2_reg_lambda)\n",
    "        # Embedding layer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.embedding = bert_model\n",
    "        self.num_filters = num_filters\n",
    "        self.filters_sizes = filter_sizes\n",
    "        self.k_protos = k_protos\n",
    "        self.vect_size = vect_size\n",
    "        \n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=user_embeddings.shape[0], output_dim=user_embeddings.shape[1], weights=[user_embeddings], trainable=False)\n",
    "        self.topic_embedding = tf.keras.layers.Embedding(input_dim=topic_embeddings.shape[0], output_dim=topic_embeddings.shape[1], weights=[topic_embeddings], trainable=False)\n",
    "        self.distance_layer = distanceLayer()\n",
    "\n",
    "        self.conv_layers = []\n",
    "        for filter_size in filter_sizes:\n",
    "            conv_block = tf.keras.Sequential([\n",
    "                layers.Conv2D(num_filters, (filter_size, embedding_size), \n",
    "                              padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(sequence_length - filter_size + 1, 1), \n",
    "                                    strides=(1,1), padding='valid')])\n",
    "            self.conv_layers.append(conv_block)\n",
    "        self.concat_layer = tf.keras.layers.Concatenate()\n",
    "        #self.last_dense = tf.keras.layers.Dense(100, activation='relu')\n",
    "        self.user_topic_dense = tf.keras.layers.Dense(400, activation='relu')\n",
    "        self.dropout = tf.keras.layers.Dropout(1 - dropout_keep_prob)\n",
    "        # Final dense layer with L2 regularization\n",
    "        self.final_dense = tf.keras.layers.Dense(num_classes, activation=\"softmax\", kernel_regularizer=l2_regularizer)\n",
    "\n",
    "    def init_prototypelayer(self, k_cents):\n",
    "        \n",
    "        self.proto_layer = prototypeLayer(self.k_protos, self.vect_size, k_cents)\n",
    "       \n",
    "\n",
    "    def call(self, inputs):\n",
    "       \n",
    "\n",
    "        input_content, input_author, input_topic = inputs\n",
    "\n",
    "       \n",
    "         # Embedding layer\n",
    "        x = self.tokenizer(input_content, padding = \"max_length\", max_length=self.max_l, return_tensors =\"tf\",truncation = True )\n",
    "        x = self.embedding(input_ids = x[\"input_ids\"], attention_mask = x[\"attention_mask\"], output_hidden_states =True)[0]\n",
    "        x = tf.expand_dims(x, -1)\n",
    "\n",
    "\n",
    "        pooled_outputs = []\n",
    "        for conv in self.conv_layers:\n",
    "            conv_out = conv(x)\n",
    "            pooled_outputs.append(conv_out)\n",
    "\n",
    "        num_filters_total = self.num_filters * len(self.filters_sizes)\n",
    "        h_pool = tf.concat(pooled_outputs, axis=1)\n",
    "        h_pool_flat = tf.reshape(h_pool, [-1, num_filters_total])\n",
    "\n",
    "        \n",
    "        x = tf.expand_dims(h_pool_flat, axis=0)\n",
    "        full_distances, protos = self.proto_layer(x)\n",
    "        dist_vect = self.distance_layer(full_distances)\n",
    "\n",
    "       \n",
    "    \n",
    "\n",
    "        #h_last = self.last_dense(dist_vect)\n",
    "\n",
    "        user_embeddings = self.user_embedding(input_author)\n",
    "        topic_embeddings = self.topic_embedding(input_topic)\n",
    "        \n",
    "        combined_vectors = self.concat_layer([dist_vect, user_embeddings, topic_embeddings])\n",
    "        combined_vector_final = self.user_topic_dense(combined_vectors)\n",
    "\n",
    "        \n",
    "        combined_vector_final = self.dropout(combined_vector_final)\n",
    "\n",
    "        scores = self.final_dense(combined_vector_final)\n",
    "\n",
    "        return scores\n",
    "    def embed(self, x):\n",
    "         # Embedding layer\n",
    "        x = self.tokenizer(x, padding = \"max_length\", max_length=self.max_l, return_tensors =\"tf\",truncation = True )\n",
    "        x = self.embedding(input_ids = x[\"input_ids\"], attention_mask = x[\"attention_mask\"], output_hidden_states =True)[0]\n",
    "        x = tf.expand_dims(x, -1)\n",
    "\n",
    "\n",
    "        \n",
    "        pooled_outputs = []\n",
    "        for conv in self.conv_layers:\n",
    "            conv_out = conv(x)\n",
    "            pooled_outputs.append(conv_out)\n",
    "\n",
    "           \n",
    "        \n",
    "        num_filters_total = self.num_filters * len(self.filters_sizes)\n",
    "        \n",
    "        h_pool = tf.concat(pooled_outputs, axis=3)\n",
    "        h_pool_flat = tf.reshape(h_pool, [-1, num_filters_total])\n",
    "\n",
    "      \n",
    "        \n",
    "\n",
    "\n",
    "        return h_pool_flat\n",
    "\n",
    "\n",
    "\n",
    "    def compute_accuracy(self, input_y, scores):\n",
    "        predictions = tf.argmax(scores, 1, name=\"predictions\")\n",
    "        correct_predictions = tf.equal(predictions, tf.argmax(input_y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58f0efa-5d8a-46cd-8bfd-8fb551ff21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b468ec-7175-4aa3-b403-c4f675e54b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "data loaded!\n",
      "loading wgcca embeddings...\n",
      "wgcca embeddings loaded\n",
      "topic emb size:  100\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "print(\"loading data...\")\n",
    "x = pickle.load(open(\"./mainbalancedpickle.p\",\"rb\"))\n",
    "revs, W, W2, word_idx_map, vocab, max_l = x[0], x[1], x[2], x[3], x[4], x[5]\n",
    "print(\"data loaded!\")# Load data\n",
    "\n",
    "print('loading wgcca embeddings...')\n",
    "wgcca_embeddings = np.load('./../users/user_embeddings/user_gcca_embeddings.npz')\n",
    "print('wgcca embeddings loaded')\n",
    "\n",
    "\n",
    "ids = np.concatenate((np.array([\"unknown\"]), wgcca_embeddings['ids']), axis=0)\n",
    "user_embeddings = wgcca_embeddings['G']\n",
    "unknown_vector = np.random.normal(size=(1,100))\n",
    "user_embeddings = np.concatenate((unknown_vector, user_embeddings), axis=0)\n",
    "user_embeddings = user_embeddings.astype(dtype='float32')\n",
    "\n",
    "wgcca_dict = {}\n",
    "for i in range(len(ids)):\n",
    "    wgcca_dict[ids[i]] = int(i)\n",
    "\n",
    "csv_reader = csv.reader(open(\"./../discourse/discourse_features/discourse.csv\"))\n",
    "topic_embeddings = []\n",
    "topic_ids = []\n",
    "for line in csv_reader:\n",
    "    topic_ids.append(line[0])\n",
    "    topic_embeddings.append(line[1:])\n",
    "topic_embeddings = np.asarray(topic_embeddings)\n",
    "topic_embeddings_size = len(topic_embeddings[0])\n",
    "topic_embeddings = topic_embeddings.astype(dtype='float32')\n",
    "print(\"topic emb size: \",topic_embeddings_size)\n",
    "\n",
    "topics_dict = {}\n",
    "for i in range(len(topic_ids)):\n",
    "    try:\n",
    "        topics_dict[topic_ids[i]] = int(i)\n",
    "    except TypeError:\n",
    "        print(i)\n",
    "\n",
    "max_l = 100\n",
    "\n",
    "x_text = []\n",
    "author_text_id = []\n",
    "topic_text_id = []\n",
    "comment_id = []\n",
    "y = []\n",
    "\n",
    "\n",
    "test_x = []\n",
    "test_topic = []\n",
    "test_author = []\n",
    "test_y = []\n",
    "text2id={}\n",
    "for i in range(len(revs)):\n",
    "\n",
    "    text2id[revs[i][\"text\"]] = revs[i][\"id\"]\n",
    "    if revs[i]['split']==1:\n",
    "        x_text.append(revs[i]['text'])\n",
    "        try:\n",
    "            author_text_id.append(wgcca_dict['\"'+revs[i]['author']+'\"'])\n",
    "        except KeyError:\n",
    "            author_text_id.append(0)\n",
    "        try:\n",
    "            topic_text_id.append(topics_dict['\"'+revs[i]['topic']+'\"'])\n",
    "        except KeyError:\n",
    "            topic_text_id.append(0)\n",
    "        y.append(revs[i]['label'])\n",
    "        comment_id.append(revs[i][\"id\"])\n",
    "    else:\n",
    "        test_x.append(revs[i]['text'])\n",
    "        try:\n",
    "            test_author.append(wgcca_dict['\"'+revs[i]['author']+'\"'])\n",
    "        except:\n",
    "            test_author.append(0)\n",
    "        try:\n",
    "            test_topic.append(topics_dict['\"'+revs[i]['topic']+'\"'])\n",
    "        except:\n",
    "            test_topic.append(0)\n",
    "        test_y.append(revs[i]['label'])  \n",
    "\n",
    "\n",
    "y_test = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fffe580a-2e61-4c50-9946-326544f960a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarc_train_file =  \"my_train_balanced.csv\"\n",
    "sarc_test_file = \"my_test_balanced.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4871f510-cd78-4351-9146-35e44a8e7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training = pd.read_csv(\"../data/my_train_balanced.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48d3e5ad-ae90-4105-b521-1a9cbaf0a38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c07fd66</td>\n",
       "      <td>['7uaac']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c07fjge</td>\n",
       "      <td>['7uaac']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c07f3md</td>\n",
       "      <td>['7u896']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c07f3ls</td>\n",
       "      <td>['7u896']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1  2\n",
       "0  c07fd66  ['7uaac']  1\n",
       "1  c07fjge  ['7uaac']  0\n",
       "2  c07f3md  ['7u896']  1\n",
       "3  c07f3ls  ['7u896']  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_training.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad5160f6-b174-4921-9cf2-3842521591dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training.columns = [\"comment\",\"post\",\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a778ea2d-7383-455b-9ba9-a1d939505edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c07fd66</td>\n",
       "      <td>['7uaac']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment       post  label\n",
       "0  c07fd66  ['7uaac']      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_training[all_training[\"comment\"]==\"c07fd66\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b56e144-5aa7-4492-be78-78f94c6f332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec23422-d0f5-4a93-950f-c8aa9a01d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = json.loads(open(\"../data/comments.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb27c32-a090-41ba-822f-941acaa1c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2n={}\n",
    "for c, dictionary in comments.items():\n",
    "   c2n[dictionary[\"text\"]] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14ef09a5-076c-4285-b1d5-879591504c14",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bf3 had the best menu layout , level progression , and unlock system out of any other bf game imo the battlepack system in bf4 was a half assed attempt at packaging something that should never be packaged for the sake of making it feel special just give me my freaking unlocks and be done with it , i got on battlelog about 6 months ago to play some bf4 for the first time in ages , i had over 70 battlepacks to open and it took me almost ten minutes to open them all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mc2n\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbf3 had the best menu layout , level progression , and unlock system out of any other bf game imo the battlepack system in bf4 was a half assed attempt at packaging something that should never be packaged for the sake of making it feel special just give me my freaking unlocks and be done with it , i got on battlelog about 6 months ago to play some bf4 for the first time in ages , i had over 70 battlepacks to open and it took me almost ten minutes to open them all\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bf3 had the best menu layout , level progression , and unlock system out of any other bf game imo the battlepack system in bf4 was a half assed attempt at packaging something that should never be packaged for the sake of making it feel special just give me my freaking unlocks and be done with it , i got on battlelog about 6 months ago to play some bf4 for the first time in ages , i had over 70 battlepacks to open and it took me almost ten minutes to open them all'"
     ]
    }
   ],
   "source": [
    "c2n[\"bf3 had the best menu layout , level progression , and unlock system out of any other bf game imo the battlepack system in bf4 was a half assed attempt at packaging something that should never be packaged for the sake of making it feel special just give me my freaking unlocks and be done with it , i got on battlelog about 6 months ago to play some bf4 for the first time in ages , i had over 70 battlepacks to open and it took me almost ten minutes to open them all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329373d-95ff-4993-8196-0bf78a489803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae68b528-b794-4ad0-8049-96b1a36d8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev Sample Percentage\n",
    "dev_sample_percentage = 0.1\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 768\n",
    "filter_sizes = [3, 4, 5]\n",
    "num_filters = 128\n",
    "dropout_keep_prob = 0.5\n",
    "l2_reg_lambda = 0.5\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 60\n",
    "num_epochs = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a311eaf6-067d-47be-a5f6-d5cc229aa3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Dev split: 139232/15470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-01 03:58:21.393176: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-01 03:58:21.870753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22460 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:25:00.0, compute capability: 8.6\n",
      "2024-01-01 03:58:21.871627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 1286 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2024-01-01 03:58:21.872306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22460 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:61:00.0, compute capability: 8.6\n",
      "2024-01-01 03:58:21.872979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22460 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:a1:00.0, compute capability: 8.6\n",
      "2024-01-01 03:58:21.873669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 22460 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "2024-01-01 03:58:22.280981: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "2024-01-01 03:58:24.458089: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8700\n"
     ]
    }
   ],
   "source": [
    "topic_train = np.asarray(topic_text_id)\n",
    "topic_test = np.asarray(test_topic)\n",
    "author_train = np.asarray(author_text_id)\n",
    "author_test = np.asarray(test_author)\n",
    "id_train = np.asarray(comment_id)\n",
    "\n",
    "\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = np.asarray(x_text)[shuffle_indices]\n",
    "y_shuffled = np.asarray(y)[shuffle_indices]\n",
    "\n",
    "\n",
    "topic_train_shuffled = topic_train[shuffle_indices]\n",
    "author_train_shuffled = author_train[shuffle_indices]\n",
    "\n",
    "# Split train/test set\n",
    "# TODO: This is very crude, should use cross-validation\n",
    "\n",
    "dev_sample_index = -1 * int(dev_sample_percentage * float(len(y)))\n",
    "x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "topic_train, topic_dev = topic_train_shuffled[:dev_sample_index], topic_train_shuffled[dev_sample_index:]\n",
    "author_train, author_dev = author_train_shuffled[:dev_sample_index], author_train_shuffled[dev_sample_index:]\n",
    "id_train, id_dev = id_train_shuffled[:dev_sample_index], id_train_shuffled[dev_sample_index:]\n",
    "y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "\n",
    "print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))\n",
    "\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "x_dev = np.asarray(x_dev)\n",
    "author_train = np.asarray(author_train)\n",
    "author_dev = np.asarray(author_dev)\n",
    "topic_train = np.asarray(topic_train)\n",
    "topic_dev = np.asarray(topic_dev)\n",
    "y_train = np.asarray(y_train)\n",
    "y_dev = np.asarray(y_dev)\n",
    "# word_idx_map[\"@\"] = 0\n",
    "# rev_dict = {v: k for k, v in word_idx_map.items()}\n",
    "\n",
    "# Training\n",
    "# ==================================================\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = TFBertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "for layer in bert_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "k_protos, vect_size = 15, 384\n",
    "\n",
    "ProtoCNN = TextCNN(\n",
    "    sequence_length=max_l,\n",
    "    num_classes=len(y_train[0]) ,\n",
    "    tokenizer = tokenizer,\n",
    "    bert_model = bert_model,\n",
    "    user_embeddings = user_embeddings,\n",
    "    topic_embeddings = topic_embeddings,\n",
    "    embedding_size=embedding_dim,\n",
    "    filter_sizes=list(map(int, filter_sizes)),\n",
    "    num_filters=num_filters,\n",
    "    l2_reg_lambda=l2_reg_lambda,\n",
    "    dropout_keep_prob = dropout_keep_prob,\n",
    "    k_protos = k_protos,\n",
    "    vect_size = vect_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# random.shuffle(x_text)\n",
    "sample_sentences = x_text[:15000]\n",
    "sample_sentences_vects = []\n",
    "for i in range(300):\n",
    "    batch = sample_sentences[i * 50:(i + 1) * 50]\n",
    "    vect = ProtoCNN.embed(batch)\n",
    "    sample_sentences_vects.append(vect.numpy())\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "sample_sentences_vect = np.concatenate(sample_sentences_vects, axis=0)\n",
    "\n",
    "\n",
    "kmedoids = KMedoids(n_clusters=k_protos, random_state=0).fit(sample_sentences_vect)\n",
    "k_cents = kmedoids.cluster_centers_\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "ProtoCNN.init_prototypelayer(k_cents)\n",
    "\n",
    "\n",
    "predictions = ProtoCNN([x_train[:2].tolist(), author_train[:2], topic_train[:2]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0d53895b-f779-4b5b-82c3-3a21776eeca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f5ff7069660>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN.load_weights(\"runs/bert_cascade_proto_div_loss-0.8/best_classifier.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "33896981-f311-469d-b373-071c18026972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(list(zip(x_train, author_train, topic_train, y_train)), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "232cc781-0981-4c15-a861-ab6f78bf8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences_vects = []\n",
    "sample_labels = []\n",
    "for i, inputs in enumerate(train_loader): \n",
    "    \n",
    "    x_batch, author_batch, topic_batch, y_batch = inputs  \n",
    "    vect = ProtoCNN.embed(x_batch) \n",
    "    sample_sentences_vects.append(vect.numpy())\n",
    "    sample_labels.extend([x.tolist() for x in y_batch])\n",
    "    \n",
    "\n",
    "   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6700a032-140e-4247-813d-a4a8751e684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sent_vect = np.concatenate(sample_sentences_vects, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "326f22ce-5c77-4ff6-a66c-e29a4c26e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPrototypes(sample_sentences,sample_sent_vects, sample_y, k_protos=10,printOutput=False, k_closest_sents = 20):\n",
    "    \n",
    "    prototypes = ProtoCNN.proto_layer.prototypes.numpy()\n",
    "    #data_size = 10000\n",
    "    d_pos = {}\n",
    "    data_size = 150000\n",
    "    for p_count, p in enumerate(prototypes):\n",
    "       \n",
    "        s_count = 0\n",
    "        d_pos[p_count] = {}\n",
    "        for i, s in enumerate(sample_sent_vect[:data_size]):\n",
    "            #if len(sample_sentences[i]) < 20 or len(sample_sentences[i]) > 100:\n",
    "            if len(sample_sentences[i]) < 30 or sample_y[i][1]==0:\n",
    "                continue\n",
    "            d_pos[p_count][i] = np.linalg.norm(sample_sent_vect[i] - p)\n",
    "            s_count += 1\n",
    " \n",
    "\n",
    "    mappedPrototypes = {}    \n",
    "   \n",
    "    recorded_protos_score = {}\n",
    "    print(\"Prototypes: \")\n",
    "    for l in range(k_protos):\n",
    "        # print(\"prototype index = \", l)\n",
    "        recorded_protos_score[l] = {}\n",
    "        sorted_d = sorted(d_pos[l].items(), key=operator.itemgetter(1))\n",
    "        print(l)\n",
    "        mappedPrototypes[l]=[]\n",
    "        for k in range(k_closest_sents):\n",
    "            i = sorted_d[k][0]\n",
    "            score = sorted_d[k][1]\n",
    "            # print(\"[db] sorted_d \",sorted_d[0])\n",
    "            # print(\"[db] sample_sentences[sorted_d[0][0]]: \",sample_sentences[sorted_d[0][0]])\n",
    "            mappedPrototypes[l].append((sample_sentences[i].strip(), score, sample_y[i][1]))\n",
    "            if k<10:\n",
    "                print(sorted_d[k], sample_sentences[i],sample_y[i][1])\n",
    "        #print(mappedPrototypes[l])\n",
    "\n",
    "    \n",
    "    return mappedPrototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f764654-27ce-4d18-94bf-b56224b1a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e29cd2ac-d9e3-41f2-9b3c-7352bb9dda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments2id = comments[\"d1nhsrd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad0cb9b1-60e7-49a6-973f-46606d424feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c07fd66</td>\n",
       "      <td>['7uaac']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment       post  label\n",
       "0  c07fd66  ['7uaac']      1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_training[all_training[\"comment\"]==\"c07fd66\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abe50a3e-cedd-487f-87cf-99b14511f602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototypes: \n",
      "0\n",
      "(4836, 0.9561245) afk or negative attitude though more of afk but since the firewall issues happened i only report for afk if the person leaves mid game due to rage or leaving without saying why 1\n",
      "(966, 0.96359783) joke 's on you i'm not having any children 1\n",
      "(5470, 0.97721153) i do n't think that word means what you think it means 1\n",
      "(8501, 0.97721153) there 's a special place in hell for her 1\n",
      "(9618, 0.97721153) finally the leafs win something brings a tear to my eye 1\n",
      "(5786, 1.0457137) stop waging unnecessary wars in the middle east then its always weird when the government bitches about the government , as if they dont have all the power to change policy 1\n",
      "(2359, 1.0516869) they should raise the price of alcohol to lower alcohol abuse too ! 1\n",
      "(9293, 1.0768752) how to lose gays to conservatives once republicans realize they lost the marriage fight 1\n",
      "(7336, 1.0916734) old money is stuck in the past , paypal is so progressive 1\n",
      "(11082, 1.0945343) i'm sure he 's disappointed in the thought of playing somewhere else 1\n",
      "1\n",
      "(4836, 0.772855) afk or negative attitude though more of afk but since the firewall issues happened i only report for afk if the person leaves mid game due to rage or leaving without saying why 1\n",
      "(966, 0.83208376) joke 's on you i'm not having any children 1\n",
      "(5470, 0.8787607) i do n't think that word means what you think it means 1\n",
      "(8501, 0.8787607) there 's a special place in hell for her 1\n",
      "(9618, 0.8787607) finally the leafs win something brings a tear to my eye 1\n",
      "(2359, 0.8891481) they should raise the price of alcohol to lower alcohol abuse too ! 1\n",
      "(5786, 0.92822784) stop waging unnecessary wars in the middle east then its always weird when the government bitches about the government , as if they dont have all the power to change policy 1\n",
      "(382, 0.93076164) the commercial itself is annoying she 's cute 1\n",
      "(7336, 0.9390599) old money is stuck in the past , paypal is so progressive 1\n",
      "(19, 0.94155836) nothing says high intelligence like logical consistancy 1\n",
      "2\n",
      "(4836, 1.1365082) afk or negative attitude though more of afk but since the firewall issues happened i only report for afk if the person leaves mid game due to rage or leaving without saying why 1\n",
      "(966, 1.1522815) joke 's on you i'm not having any children 1\n",
      "(5470, 1.1917803) i do n't think that word means what you think it means 1\n",
      "(8501, 1.1917803) there 's a special place in hell for her 1\n",
      "(9618, 1.1917803) finally the leafs win something brings a tear to my eye 1\n",
      "(2359, 1.2189347) they should raise the price of alcohol to lower alcohol abuse too ! 1\n",
      "(9293, 1.2441312) how to lose gays to conservatives once republicans realize they lost the marriage fight 1\n",
      "(7336, 1.2493804) old money is stuck in the past , paypal is so progressive 1\n",
      "(5786, 1.2557408) stop waging unnecessary wars in the middle east then its always weird when the government bitches about the government , as if they dont have all the power to change policy 1\n",
      "(1975, 1.2616254) oh noes , creeper , do n't block me , i 'll be so torn up ! 1\n",
      "3\n",
      "(4836, 0.9290949) afk or negative attitude though more of afk but since the firewall issues happened i only report for afk if the person leaves mid game due to rage or leaving without saying why 1\n",
      "(966, 0.96123695) joke 's on you i'm not having any children 1\n",
      "(5470, 0.97257006) i do n't think that word means what you think it means 1\n",
      "(8501, 0.97257006) there 's a special place in hell for her 1\n",
      "(9618, 0.97257006) finally the leafs win something brings a tear to my eye 1\n",
      "(2359, 1.0595659) they should raise the price of alcohol to lower alcohol abuse too ! 1\n",
      "(7336, 1.0784425) old money is stuck in the past , paypal is so progressive 1\n",
      "(19, 1.0802325) nothing says high intelligence like logical consistancy 1\n",
      "(9293, 1.0876167) how to lose gays to conservatives once republicans realize they lost the marriage fight 1\n",
      "(5786, 1.0879575) stop waging unnecessary wars in the middle east then its always weird when the government bitches about the government , as if they dont have all the power to change policy 1\n",
      "4\n",
      "(4836, 1.1087098) afk or negative attitude though more of afk but since the firewall issues happened i only report for afk if the person leaves mid game due to rage or leaving without saying why 1\n",
      "(966, 1.1437685) joke 's on you i'm not having any children 1\n",
      "(5470, 1.1522883) i do n't think that word means what you think it means 1\n",
      "(8501, 1.1522883) there 's a special place in hell for her 1\n",
      "(9618, 1.1522883) finally the leafs win something brings a tear to my eye 1\n",
      "(2359, 1.1874927) they should raise the price of alcohol to lower alcohol abuse too ! 1\n",
      "(5786, 1.1980168) stop waging unnecessary wars in the middle east then its always weird when the government bitches about the government , as if they dont have all the power to change policy 1\n",
      "(9293, 1.2057385) how to lose gays to conservatives once republicans realize they lost the marriage fight 1\n",
      "(2948, 1.2209765) i wonder how long it 'll take for nothing to happen 1\n",
      "(382, 1.2243488) the commercial itself is annoying she 's cute 1\n",
      "5\n",
      "(4836, 1.5050324) afk or negative attitude though more of afk but since the firewall issues happened i only report for afk if the person leaves mid game due to rage or leaving without saying why 1\n",
      "(966, 1.5082674) joke 's on you i'm not having any children 1\n",
      "(5470, 1.5532486) i do n't think that word means what you think it means 1\n",
      "(8501, 1.5532486) there 's a special place in hell for her 1\n",
      "(9618, 1.5532486) finally the leafs win something brings a tear to my eye 1\n",
      "(9293, 1.5540793) how to lose gays to conservatives once republicans realize they lost the marriage fight 1\n",
      "(2359, 1.5586205) they should raise the price of alcohol to lower alcohol abuse too ! 1\n",
      "(5786, 1.5626501) stop waging unnecessary wars in the middle east then its always weird when the government bitches about the government , as if they dont have all the power to change policy 1\n",
      "(9062, 1.5775524) underestimate a low health quaid in ca at your own peril 1\n",
      "(382, 1.580424) the commercial itself is annoying she 's cute 1\n",
      "6\n",
      "(4836, 0.99388826) afk or negative attitude though more of afk but since the firewall issues happened i only report for afk if the person leaves mid game due to rage or leaving without saying why 1\n",
      "(966, 0.99443656) joke 's on you i'm not having any children 1\n",
      "(5470, 1.0181234) i do n't think that word means what you think it means 1\n",
      "(8501, 1.0181234) there 's a special place in hell for her 1\n",
      "(9618, 1.0181234) finally the leafs win something brings a tear to my eye 1\n",
      "(5786, 1.056322) stop waging unnecessary wars in the middle east then its always weird when the government bitches about the government , as if they dont have all the power to change policy 1\n",
      "(2359, 1.062959) they should raise the price of alcohol to lower alcohol abuse too ! 1\n",
      "(7336, 1.0975126) old money is stuck in the past , paypal is so progressive 1\n",
      "(9293, 1.1043148) how to lose gays to conservatives once republicans realize they lost the marriage fight 1\n",
      "(8260, 1.1206121) finally , some original content in this subreddit 1\n",
      "7\n",
      "(4836, 1.201597) afk or negative attitude though more of afk but since the firewall issues happened i only report for afk if the person leaves mid game due to rage or leaving without saying why 1\n",
      "(966, 1.206625) joke 's on you i'm not having any children 1\n",
      "(5470, 1.2342819) i do n't think that word means what you think it means 1\n",
      "(8501, 1.2342819) there 's a special place in hell for her 1\n",
      "(9618, 1.2342819) finally the leafs win something brings a tear to my eye 1\n",
      "(2359, 1.2955664) they should raise the price of alcohol to lower alcohol abuse too ! 1\n",
      "(5786, 1.3049178) stop waging unnecessary wars in the middle east then its always weird when the government bitches about the government , as if they dont have all the power to change policy 1\n",
      "(7336, 1.3147454) old money is stuck in the past , paypal is so progressive 1\n",
      "(9293, 1.3216243) how to lose gays to conservatives once republicans realize they lost the marriage fight 1\n",
      "(382, 1.3254725) the commercial itself is annoying she 's cute 1\n",
      "8\n",
      "(4836, 1.0846808) afk or negative attitude though more of afk but since the firewall issues happened i only report for afk if the person leaves mid game due to rage or leaving without saying why 1\n",
      "(966, 1.1069539) joke 's on you i'm not having any children 1\n",
      "(5470, 1.1326531) i do n't think that word means what you think it means 1\n",
      "(8501, 1.1326531) there 's a special place in hell for her 1\n",
      "(9618, 1.1326531) finally the leafs win something brings a tear to my eye 1\n",
      "(2359, 1.155685) they should raise the price of alcohol to lower alcohol abuse too ! 1\n",
      "(5786, 1.1842419) stop waging unnecessary wars in the middle east then its always weird when the government bitches about the government , as if they dont have all the power to change policy 1\n",
      "(9293, 1.2045711) how to lose gays to conservatives once republicans realize they lost the marriage fight 1\n",
      "(7336, 1.2064501) old money is stuck in the past , paypal is so progressive 1\n",
      "(11082, 1.2087201) i'm sure he 's disappointed in the thought of playing somewhere else 1\n",
      "9\n",
      "(4836, 0.9953081) afk or negative attitude though more of afk but since the firewall issues happened i only report for afk if the person leaves mid game due to rage or leaving without saying why 1\n",
      "(966, 1.0056007) joke 's on you i'm not having any children 1\n",
      "(5470, 1.0445607) i do n't think that word means what you think it means 1\n",
      "(8501, 1.0445607) there 's a special place in hell for her 1\n",
      "(9618, 1.0445607) finally the leafs win something brings a tear to my eye 1\n",
      "(2359, 1.0526152) they should raise the price of alcohol to lower alcohol abuse too ! 1\n",
      "(5786, 1.0820841) stop waging unnecessary wars in the middle east then its always weird when the government bitches about the government , as if they dont have all the power to change policy 1\n",
      "(9293, 1.0909246) how to lose gays to conservatives once republicans realize they lost the marriage fight 1\n",
      "(19, 1.1062604) nothing says high intelligence like logical consistancy 1\n",
      "(7336, 1.1085325) old money is stuck in the past , paypal is so progressive 1\n"
     ]
    }
   ],
   "source": [
    "mapped_prototype = showPrototypes(sample_sentences,sample_sent_vect, sample_labels, k_protos=10,printOutput=False, k_closest_sents = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6304c664-4a13-463d-8606-48016e25102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPrototypes(ProtoCNN, sample_sentences,sample_sent_vects,k_protos=15,printOutput=False):\n",
    "    prototypes = ProtoCNN.proto_layer.prototypes.numpy()\n",
    "    #data_size = 10000\n",
    "    d_pos = {}\n",
    "    for p_count, p in enumerate(prototypes):\n",
    "        print('p_count = ', p_count)\n",
    "        s_count = 0\n",
    "        d_pos[p_count] = {}\n",
    "        for i, s in enumerate(sample_sent_vects):\n",
    "            if len(sample_sentences[i]) < 20 :\n",
    "                continue\n",
    "            d_pos[p_count][i] = np.linalg.norm(sample_sent_vects[i] - p)\n",
    "            s_count += 1\n",
    "        print('count = ', s_count)\n",
    "    \n",
    "    \n",
    "    mappedPrototypes = {} \n",
    "    k_closest_sents = 10\n",
    "    recorded_protos_score = {}\n",
    "    print(\"Prototypes: \")\n",
    "    for l in range(k_protos):\n",
    "        # print(\"prototype index = \", l)\n",
    "        recorded_protos_score[l] = {}\n",
    "        sorted_d = sorted(d_pos[l].items(), key=operator.itemgetter(1))\n",
    "        for k in range(k_closest_sents):\n",
    "            i = sorted_d[k][0]\n",
    "            # print(\"[db] sorted_d \",sorted_d[0])\n",
    "            # print(\"[db] sample_sentences[sorted_d[0][0]]: \",sample_sentences[sorted_d[0][0]])\n",
    "            mappedPrototypes[l] = sample_sentences[sorted_d[0][0]].strip()\n",
    "           \n",
    "            #print(sorted_d[k], sample_sentences[i])\n",
    "        print(mappedPrototypes[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6caba8cc-b4b9-4c93-9201-be38f5d85366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pw_distance(A):\n",
    "    r = tf.reduce_sum(A * A, 1)\n",
    "    r = tf.reshape(r, [-1, 1])\n",
    "    D = r - 2 * tf.matmul(A, tf.transpose(A)) + tf.transpose(r)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a6b99d4a-255a-45cc-9134-266087217996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04658692,  0.08148573,  0.07718311, ...,  0.08493915,\n",
       "         0.09445967,  0.09795462],\n",
       "       [ 0.025462  ,  0.05717431,  0.05421162, ...,  0.05526998,\n",
       "         0.05259991,  0.13021095],\n",
       "       [ 0.01885531,  0.06329141,  0.0172288 , ...,  0.04997756,\n",
       "         0.0773843 ,  0.04898995],\n",
       "       ...,\n",
       "       [-0.00148784,  0.03370793,  0.07756134, ...,  0.00104265,\n",
       "         0.0702292 ,  0.06720568],\n",
       "       [ 0.00819621,  0.05842676,  0.04430661, ...,  0.08267815,\n",
       "         0.02784036,  0.15792556],\n",
       "       [ 0.05129506,  0.02122571,  0.03022781, ...,  0.03197355,\n",
       "         0.0905187 ,  0.08947792]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "715e2924-f333-4a22-b7b8-653c6975735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "protos = ProtoCNN.proto_layer.prototypes.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d38fe226-d716-4464-bda2-efe3fc7b9165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 384)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "19e4e690-00ed-4bbb-8ce4-cb417af6b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pw_distance(protos)\n",
    "diag_ones = tf.convert_to_tensor(np.eye(k_protos, dtype=float))\n",
    "diag_ones = tf.dtypes.cast(diag_ones, tf.float32)\n",
    "d1 = d + diag_ones * tf.reduce_max(d)\n",
    "d2 = tf.reduce_min(d1, axis=1)\n",
    "min_d2_dist = tf.reduce_min(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "16ec3f52-7961-4dd4-aee8-27b82c68122f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.288455>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_d2_dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "610d87d2-3cbf-405a-84ce-a82660936212",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f569f54b-9545-4ddd-b60b-372fa1708030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_count =  0\n",
      "count =  118697\n",
      "p_count =  1\n",
      "count =  118697\n",
      "p_count =  2\n",
      "count =  118697\n",
      "p_count =  3\n",
      "count =  118697\n",
      "p_count =  4\n",
      "count =  118697\n",
      "p_count =  5\n",
      "count =  118697\n",
      "p_count =  6\n",
      "count =  118697\n",
      "p_count =  7\n",
      "count =  118697\n",
      "p_count =  8\n",
      "count =  118697\n",
      "p_count =  9\n",
      "count =  118697\n",
      "p_count =  10\n",
      "count =  118697\n",
      "p_count =  11\n",
      "count =  118697\n",
      "p_count =  12\n",
      "count =  118697\n",
      "p_count =  13\n",
      "count =  118697\n",
      "p_count =  14\n",
      "count =  118697\n"
     ]
    }
   ],
   "source": [
    "prototypes = ProtoCNN.proto_layer.prototypes.numpy()\n",
    "#data_size = 10000\n",
    "d_pos = {}\n",
    "for p_count, p in enumerate(prototypes):\n",
    "    print('p_count = ', p_count)\n",
    "    s_count = 0\n",
    "    d_pos[p_count] = {}\n",
    "    for i, s in enumerate(x_train):\n",
    "        if len( x_train[i]) < 20 :\n",
    "            continue\n",
    "        d_pos[p_count][i] = np.linalg.norm(sample_sent_vect[i] - p)\n",
    "        s_count += 1\n",
    "    print('count = ', s_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1cc7c613-1d8a-4c29-bcda-7879c8d2b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_count =  0\n",
      "count =  118697\n",
      "p_count =  1\n",
      "count =  118697\n",
      "p_count =  2\n",
      "count =  118697\n",
      "p_count =  3\n",
      "count =  118697\n",
      "p_count =  4\n",
      "count =  118697\n",
      "p_count =  5\n",
      "count =  118697\n",
      "p_count =  6\n",
      "count =  118697\n",
      "p_count =  7\n",
      "count =  118697\n",
      "p_count =  8\n",
      "count =  118697\n",
      "p_count =  9\n",
      "count =  118697\n",
      "p_count =  10\n",
      "count =  118697\n",
      "p_count =  11\n",
      "count =  118697\n",
      "p_count =  12\n",
      "count =  118697\n",
      "p_count =  13\n",
      "count =  118697\n",
      "p_count =  14\n",
      "count =  118697\n",
      "Prototypes: \n",
      "because applying braking forces through your chain is the most efficient way to slow down your wheels\n",
      "yes , infowars is the place to find solutions to all our problems\n",
      "good thing his trebuchet jammed\n",
      "omg that lady should be kicked out for breastfeeding in public !\n",
      "so that 's where they make xboxs\n",
      "because that will only make them more accepting !\n",
      "cool now we can spend more time playing with books instead of reading them\n",
      "well , they certainly got their goal of appearing on those subreddits\n",
      "oh great , i packed mandzukic and kouyate earlier today before they were transferred\n",
      "hm , charges for cephalopod abuse should be added !\n",
      "but muh hundred bajillion deaths due to communism !\n",
      "maybe we need to segregate catholics like sono since they have a tendency to molest children\n",
      "yeah but one american life is priceless compared to any other person\n",
      "but those are n't real christians\n",
      "but now all this would not be possible without god making the rain in the first place\n"
     ]
    }
   ],
   "source": [
    "#show the list of prototypes\n",
    "showPrototypes(ProtoCNN, x_train,sample_sent_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58970369-d48f-4852-a221-77f0c6e882fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cu2g2p8'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_train[604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c687251c-01b4-4b6d-885d-2a7f67784d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pretty sure it was basically mushu from mulan \\\\?'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7fc63a4d-0359-4f98-8e32-f15e5d7920d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c07fd66</td>\n",
       "      <td>['7uaac']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment       post  label\n",
       "0  c07fd66  ['7uaac']      1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_training[all_training[\"comment\"]==\"c07fd66\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8fd7ebe4-f838-4973-a867-1ec89ab59ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"I only fear failing on the bench press, but that's why I only BP in a power rack.\",\n",
       " 'author': 'Thojos',\n",
       " 'score': 9,\n",
       " 'ups': 9,\n",
       " 'downs': 0,\n",
       " 'created_utc': 1439499693,\n",
       " 'date': '2015-08',\n",
       " 'subreddit': 'bodybuilding'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[\"cu217s2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e71606e-65fb-4777-8a17-1de984a49977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a296249-7ac4-4afc-a43c-b4eb44e75798",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcomments\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comments' is not defined"
     ]
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d22daf-97a5-4514-8c09-a4a09caec48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
