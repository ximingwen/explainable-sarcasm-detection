{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e7140b1-bc8b-4b88-bee3-e732ba50fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b63e2725-c55e-4d88-827a-b9b72a9a041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5872283738812741676\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23551737856\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7843232950300974549\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 21:36:07.921620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 22460 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6f2f26d-ef5f-4f48-9104-9297666266d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "#import neccesary packages\n",
    "#import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
    "from datetime import datetime\n",
    "from scipy.spatial import distance_matrix\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e45529e-47d7-4a0f-8b7e-162d677eb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1126aa1-a44b-4991-b23d-d9e644d41d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, Model, regularizers\n",
    "\n",
    "def make_variables(tf_name, k1, k2, initializer):\n",
    "     \n",
    "    return tf.Variable(initializer(shape=[k1, k2], dtype=tf.float32), trainable=True, name=tf_name)\n",
    "\n",
    "#prototype layer\n",
    "class prototypeLayer(keras.layers.Layer):\n",
    "    def __init__(self, k_protos, vect_size, k_cents):\n",
    "        super(prototypeLayer, self).__init__(name='proto_layer')\n",
    "        self.n_protos = k_protos\n",
    "        self.vect_size = vect_size\n",
    "        self.prototypes = make_variables(\"prototypes\", k_protos, vect_size,\n",
    "                                         initializer=tf.constant_initializer(k_cents))\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        tmp1 = tf.expand_dims(inputs, 2)\n",
    "        \n",
    "        tmp1 = tf.broadcast_to(tmp1, [tf.shape(tmp1)[0], tf.shape(tmp1)[1], self.n_protos, self.vect_size])\n",
    "        tmp2 = tf.broadcast_to(self.prototypes,\n",
    "                               [tf.shape(tmp1)[0], tf.shape(tmp1)[1], self.n_protos, self.vect_size])\n",
    "        tmp3 = tmp1 - tmp2\n",
    "        tmp4 = tmp3 * tmp3\n",
    "        distances = tf.reduce_sum(tmp4, axis=3)\n",
    "        \n",
    "        return distances, self.prototypes\n",
    "\n",
    "#distance layer: to convert the full distance matrix to sparse similarity matrix\n",
    "class distanceLayer(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(distanceLayer, self).__init__(name='distance_layer')\n",
    "        self.a = 0.1\n",
    "        self.beta = 1e6\n",
    "\n",
    "    def e_func(self, x, e=2.7182818284590452353602874713527):\n",
    "        return tf.math.pow(e, -(self.a * x))\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, full_distances):\n",
    "        min_dist_ind = tf.nn.softmax(-full_distances * self.beta)\n",
    "        e_dist = self.e_func(full_distances) + 1e-8\n",
    "        dist_hot_vect = min_dist_ind * e_dist\n",
    "        return dist_hot_vect\n",
    "    \n",
    "    \n",
    "class PrototypeCNN(Model):\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence_length, num_classes, vocab_size, pretrained_embeddings, word_idx_map,\\\n",
    "                 embedding_size, filter_sizes, num_filters, l2_reg_lambda, dropout_keep_prob, k_protos, vect_size):\n",
    "\n",
    "        \n",
    "        super(PrototypeCNN, self).__init__()\n",
    "        self.k_protos = k_protos\n",
    "        self.vect_size = vect_size\n",
    "        self.full_distences = None\n",
    "        self.full_onehot_distances = None\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=embedding_size,weights = [pretrained_embeddings],trainable=True)  # Optional: Set to True if you want to fine-tune the embeddings during training\n",
    "\n",
    "        \n",
    "        self.convs = []\n",
    "        for filter_size in filter_sizes:\n",
    "            conv_block = tf.keras.Sequential([\n",
    "                layers.Conv2D(num_filters, (filter_size, embedding_size), \n",
    "                              padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(sequence_length - filter_size + 1, 1), \n",
    "                                    strides=(1,1), padding='valid')])\n",
    "            self.convs.append(conv_block)\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.distance_layer = distanceLayer()\n",
    "        self.dropout = layers.Dropout(dropout_keep_prob)  # keep_prob will be supplied by call argument\n",
    "        self.fc = layers.Dense(num_classes, \n",
    "                               kernel_regularizer=regularizers.l2(l2_reg_lambda), \n",
    "                               activation='softmax')\n",
    "\n",
    "    def init_prototypelayer(self, k_cents):\n",
    "        self.proto_layer = prototypeLayer(self.k_protos, self.vect_size, k_cents)\n",
    "        \n",
    "    def call(self, x):\n",
    "        # Embedding layer\n",
    "        x = self.embedding(x)\n",
    "        x = tf.expand_dims(x, -1)\n",
    "  \n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "            pooled_outputs.append(c)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        x = tf.concat(pooled_outputs, axis=-1)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        full_distances, protos = self.proto_layer(x)\n",
    "       \n",
    "        dist_hot_vect = self.distance_layer(full_distances)\n",
    "        \n",
    "\n",
    "        x = self.dropout(dist_hot_vect)\n",
    "        x = self.fc(x)\n",
    "        x = tf.squeeze(x, axis=0)\n",
    "        #return x, self.fc.weights[0], self.fc.weights[1]\n",
    "        \n",
    "       \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def embed(self,x):\n",
    "        # Embedding layer\n",
    "        x = self.embedding(x)\n",
    "        x = tf.expand_dims(x, -1)\n",
    "\n",
    "\n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            #print(x.shape)\n",
    "            \n",
    "            c = conv(x)\n",
    "            pooled_outputs.append(c)\n",
    "           \n",
    "\n",
    "        # Combine all the pooled features\n",
    "        x = tf.concat(pooled_outputs, axis=-1)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def full_distance(self, x):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = tf.expand_dims(x, -1)\n",
    "  \n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "            pooled_outputs.append(c)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        x = tf.concat(pooled_outputs, axis=-1)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        full_distances, protos = self.proto_layer(x)\n",
    "        \n",
    "        return full_distances\n",
    "    \n",
    "    def one_hot_distance(self, x):\n",
    "        \n",
    "         # Embedding layer\n",
    "        x = self.embedding(x)\n",
    "        x = tf.expand_dims(x, -1)\n",
    "  \n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "            pooled_outputs.append(c)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        x = tf.concat(pooled_outputs, axis=-1)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        full_distances, protos = self.proto_layer(x)\n",
    "       \n",
    "        dist_hot_vect = self.distance_layer(full_distances)\n",
    "        \n",
    "        return dist_hot_vect\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4975a7f8-e6a8-4438-85bf-a2141c34a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method simple project prototypes to the closest sentences in\n",
    "#sample_sent_vects\n",
    "def projection(sample_sentences,sample_sent_vects,data_size=10000):\n",
    "    prototypes = ProtoCNN.proto_layer.prototypes\n",
    "    d_pos = {}\n",
    "    #for each prototype\n",
    "    for p_count, p in enumerate(prototypes):\n",
    "        print('[db] p_count = ', p_count)\n",
    "        s_count = 0\n",
    "        d_pos[p_count] = {}\n",
    "        #find its distances to all sample sentences\n",
    "        for i, s in enumerate(sample_sent_vects[:data_size]):\n",
    "            if len(sample_sentences[i]) < 5 or len(sample_sentences[i]) > 100:\n",
    "                continue\n",
    "            d_pos[p_count][i] = np.linalg.norm(sample_sent_vects[i] - p)\n",
    "            s_count += 1\n",
    "    #sort those distances, then assign the closest ones to new prototypes\n",
    "    new_protos = []\n",
    "    for p_count, p in enumerate(prototypes):\n",
    "        sorted_d = sorted(d_pos[p_count].items(), key=operator.itemgetter(1))\n",
    "        new_protos.append(sample_sent_vects[sorted_d[0][0]])\n",
    "    #return these values\n",
    "\n",
    "    return new_protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba83b7c3-e819-486f-b03c-db2cd0de28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the list of prototypes\n",
    "def showPrototypes(sample_sentences,sample_sent_vects, sample_y, k_protos=10,printOutput=False, k_closest_sents = 20):\n",
    "    \n",
    "    prototypes = ProtoCNN.proto_layer.prototypes.numpy()\n",
    "    #data_size = 10000\n",
    "    d_pos = {}\n",
    "    data_size = 150000\n",
    "    for p_count, p in enumerate(prototypes):\n",
    "       \n",
    "        s_count = 0\n",
    "        d_pos[p_count] = {}\n",
    "        for i, s in enumerate(sample_sent_vect[:data_size]):\n",
    "            #if len(sample_sentences[i]) < 20 or len(sample_sentences[i]) > 100:\n",
    "            if len(sample_sentences[i]) < 30 or sample_y[i][1]==0:\n",
    "                continue\n",
    "            d_pos[p_count][i] = np.linalg.norm(sample_sent_vect[i] - p)\n",
    "            s_count += 1\n",
    " \n",
    "\n",
    "    mappedPrototypes = {}    \n",
    "   \n",
    "    recorded_protos_score = {}\n",
    "    print(\"Prototypes: \")\n",
    "    for l in range(k_protos):\n",
    "        # print(\"prototype index = \", l)\n",
    "        recorded_protos_score[l] = {}\n",
    "        sorted_d = sorted(d_pos[l].items(), key=operator.itemgetter(1))\n",
    "        print(l)\n",
    "        mappedPrototypes[l]=[]\n",
    "        for k in range(k_closest_sents):\n",
    "            i = sorted_d[k][0]\n",
    "            score = sorted_d[k][1]\n",
    "            # print(\"[db] sorted_d \",sorted_d[0])\n",
    "            # print(\"[db] sample_sentences[sorted_d[0][0]]: \",sample_sentences[sorted_d[0][0]])\n",
    "            mappedPrototypes[l].append((sample_sentences[i].strip(), score, sample_y[i][1]))\n",
    "            if k<10:\n",
    "                print(sorted_d[k], sample_sentences[i],sample_y[i][1])\n",
    "        #print(mappedPrototypes[l])\n",
    "\n",
    "    \n",
    "    return mappedPrototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "211b7091-11a9-404b-980c-769756f085b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to generate the number of closest sentences to each prototype\n",
    "def protoFreq(self,sample_sent_vect):\n",
    "    d = {}\n",
    "    for sent in sample_sent_vect:\n",
    "        sent_dist = {}\n",
    "        for i, p in enumerate(self.prototypes):\n",
    "            sent_dist[i] = np.linalg.norm(sent - p)\n",
    "            if i not in d:\n",
    "                d[i] = 0\n",
    "        sorted_sent_d = sorted(sent_dist.items(), key=operator.itemgetter(1))\n",
    "        # print(sorted_sent_d)\n",
    "        picked_protos = sorted_sent_d[0][0]\n",
    "        d[picked_protos] += 1\n",
    "    print(\"Prototype freq = \", d)\n",
    "    x = sorted(d.items(), key=lambda item: item[1], reverse=True)\n",
    "    print(\"sorted :\",x)\n",
    "\n",
    "#re-train the model with new pruned prototype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b33f3373-3d81-4d34-a9d9-144a198ce0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruningTrain(self,new_k_protos,x_train,y_train,x_test,y_test):\n",
    "    #print(\"[db] self prototypes: \",self.prototypes)\n",
    "    k_cents = self.prototypes[:new_k_protos]\n",
    "    k_cents = [p.numpy() for p in k_cents]\n",
    "    #print(\"[db] k_cents = \",k_cents)\n",
    "    self.createModel(k_cents=k_cents,k_protos=new_k_protos)\n",
    "    self.train(x_train,y_train,x_test,y_test)\n",
    "\n",
    "# generate the sentence value for each prototype\n",
    "# and 10 closest sentences to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f4d691e-f19f-42d9-b9f4-e1c4fb1367d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showTrajectory(self,input,sample_sentences,sample_vect):\n",
    "    if len(self.mappedPrototypes) == 0:\n",
    "        self.showPrototypes(sample_sentences,sample_vect,printOutput=False)\n",
    "    prototypes = [self.mappedPrototypes[k].strip() for k in self.mappedPrototypes]\n",
    "    vP, vS = self.embed(prototypes), self.embed(input)\n",
    "    dStoP = {}\n",
    "    for sCount, s in enumerate(vS):\n",
    "        dStoP[sCount] = {}\n",
    "        for i, p in enumerate(vP):\n",
    "            dStoP[sCount][i] = np.linalg.norm(vS[sCount] - p)\n",
    "\n",
    "    mappedProtos, mappedScore, mappedDist = [], [], []\n",
    "    for sCount, s in enumerate(vS):\n",
    "        sorted_d = sorted(dStoP[sCount].items(), key=operator.itemgetter(1))\n",
    "        mappedProtos.append(prototypes[sorted_d[0][0]])\n",
    "\n",
    "    #for small dataset, we use a pretrained sentiment model. We can use any\n",
    "    #model for sentiment scores\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    print(\"[db] mappedProtos \", mappedProtos)\n",
    "    scores = []\n",
    "    for s in mappedProtos:\n",
    "        # sentiment_dict = sid_obj.polarity_scores(s)\n",
    "        scores.append(0.5 + sid_obj.polarity_scores(s)['compound'] / 2)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "029d1de7-6903-43f0-a8a8-3af4cfe1b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sample_percentage = .1\n",
    "\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 300\n",
    "filter_sizes =\"3,4,5\"\n",
    "num_filters = 128\n",
    "dropout_keep_prob = 0.5\n",
    "l2_reg_lambda = 0.5\n",
    "max_l =100\n",
    "# Training parameters\n",
    "batch_size = 4096\n",
    "num_epochs = 100\n",
    "evaluate_every = 100\n",
    "checkpoint_everyt = 100\n",
    "num_checkpoints = 5\n",
    "\n",
    "# Misc Parameters\n",
    "allow_soft_placement = True\n",
    "log_device_placement = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215181e-3bb5-453f-b0ea-17c8fa8258fb",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ffa0bc6-bc08-442d-b25a-6f5e7b777de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output directory:  /big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/runs/1698788246\n",
      "loading data...\n",
      "data loaded!\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(int(time.time()))\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "print(\"output directory: \", out_dir)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "# Data Preparation\n",
    "# ==================================================\n",
    "\n",
    "# Load data\n",
    "\n",
    "print(\"loading data...\")\n",
    "x = pickle.load(open(\"./mainbalancedpickle.p\",\"rb\"))\n",
    "revs, W, W2, word_idx_map, vocab, max_l = x[0], x[1], x[2], x[3], x[4], x[5]\n",
    "print(\"data loaded!\")# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02072226-262a-4309-b982-a650ffd41111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, max_l= 100):\n",
    "    \n",
    "    encoded_X = []\n",
    "    for i in range(len(text)):\n",
    "        encoded_X.append(np.asarray([word_idx_map[word] for word in text[i].split()]))\n",
    "\n",
    "    # padding\n",
    "    for i in range(len(encoded_X)):\n",
    "        if( len(encoded_X[i]) < max_l ):\n",
    "            encoded_X[i] = np.append(encoded_X[i],np.zeros(max_l-len(encoded_X[i])))\n",
    "        elif( len(encoded_X[i]) > max_l ):\n",
    "            encoded_X[i] = encoded_X[i][0:max_l]\n",
    "    encoded_X = np.asarray(encoded_X)\n",
    "    \n",
    "    return encoded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5e94a494-8b8e-4201-a15a-39f647276947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_l = 100\n",
    "\n",
    "x_text = []\n",
    "y = []\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "for i in range(len(revs)):\n",
    "    if revs[i]['split']==1:\n",
    "        x_text.append(revs[i]['text'])\n",
    "        y.append(revs[i]['label'])\n",
    "    else:\n",
    "        test_x.append(revs[i]['text'])\n",
    "        test_y.append(revs[i]['label'])  \n",
    "\n",
    "y = np.asarray(y)\n",
    "y_test = np.asarray(test_y)\n",
    "\n",
    "\n",
    "x =  encode(x_text)\n",
    "x_test = encode(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0887d32-5377-40ec-a109-2f7272a26dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(x_text,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "758e4d4b-3732-4e02-9f12-112651b5ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Dev split: 139232/15470\n"
     ]
    }
   ],
   "source": [
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "\n",
    "# Split train/test set\n",
    "# TODO: This is very crude, should use cross-validation\n",
    "\n",
    "dev_sample_index = -1 * int(dev_sample_percentage * float(len(y)))\n",
    "x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "x_dev = np.asarray(x_dev)\n",
    "y_train = np.asarray(y_train)\n",
    "y_dev = np.asarray(y_dev)\n",
    "word_idx_map[\"@\"] = 0\n",
    "rev_dict = {v: k for k, v in word_idx_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f88e3e0-469d-452c-8bf6-a9ea4253e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_protos, vect_size = 10, 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d705569-a75c-46e2-bab8-19acde24af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProtoCNN = PrototypeCNN(sequence_length=max_l,\n",
    "    num_classes=len(y_train[0]),\n",
    "    vocab_size=len(W),\n",
    "    pretrained_embeddings = W,\n",
    "    word_idx_map = word_idx_map,\n",
    "    embedding_size=embedding_dim,\n",
    "    filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
    "    num_filters=num_filters,\n",
    "    l2_reg_lambda=l2_reg_lambda,\n",
    "    dropout_keep_prob = dropout_keep_prob,\n",
    "    k_protos = k_protos,\n",
    "    vect_size = vect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aec7682e-cb3d-4d2c-9ab1-35a215c9e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_word_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ccac8a6a-70e4-4b7b-bb53-d75950c88f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in word_idx_map.items():\n",
    "    id_word_map[idx] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22bbd133-de1a-4c73-b76a-8f84cde6591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ProtoCNN.embed(encode(x_text[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b1f4a6e-0cee-4062-a201-a80395510832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c32dd5ef-8d40-40a6-b91e-e8445e335b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(x_text)\n",
    "sample_sentences = x_text[:15000]\n",
    "encoded_sample_sentences = encode(sample_sentences)\n",
    "sample_sent_vects =[]\n",
    "\n",
    "sample_sent_vect = ProtoCNN.embed(encoded_sample_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b1327e9c-9674-4f87-8dd6-0a8b76cc5ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([15000, 384])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sent_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f869b9e4-76ab-4349-a456-797eff1b3dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 384)\n"
     ]
    }
   ],
   "source": [
    "k_protos = 10\n",
    "kmedoids = KMedoids(n_clusters=k_protos, random_state=0).fit(sample_sent_vect)\n",
    "k_cents = kmedoids.cluster_centers_\n",
    "print(k_cents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2b5b266d-7de9-41b1-8147-c05ff7e2e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProtoCNN.init_prototypelayer(k_cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b97c064f-2f9a-45d7-be39-b2a17cb30eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 21:38:09.691218: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "y= ProtoCNN(x_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "82166faa-3a49-4c23-a017-57bfd4a78b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.54959184, 0.45040822],\n",
       "       [0.64327854, 0.35672143]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af5d1a-e4f0-4f69-aa51-999d966d9be4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eae7ff8e-640a-4694-9e0e-c55f12e24ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/runs/1698788683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "timestamp = str(int(time.time()))\n",
    "# Output directory for models and summaries\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "# Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6a87776e-eac1-4230-9722-6f8449b2c747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139232, 100)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1b4ff0c-d662-4f0f-8017-03f108fb5e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139232, 2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1250b421-7872-434f-a700-645b9ef5a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProtoCNN = tf.keras.models.load_model(os.path.join(out_dir,\"my_weights-finetune.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f5c08b70-3f72-48f2-bf14-5fd5ed016a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use Adam optimizer with default learning rate 0.0001.\n",
    "#Change this value based on your preference\n",
    "#out_dir = \"/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/runs/1686708033\"\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=.0001)\n",
    "ProtoCNN.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d8f32b12-fc25-40bd-9b30-d3da29c70aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_object = pickle.load(open(os.path.join(out_dir,\"optimizer.pt\"), 'rb'))\n",
    "#ProtoCNN.optimizer.set_weights(loaded_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f989d673-aeeb-4226-ac8e-9b3db577815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "34/34 [==============================] - 306s 5s/step - loss: 2.4826 - accuracy: 0.4957 - val_loss: 2.4514 - val_accuracy: 0.4934\n",
      "Epoch 2/2000\n",
      "34/34 [==============================] - 8s 222ms/step - loss: 2.4500 - accuracy: 0.4981 - val_loss: 2.4239 - val_accuracy: 0.4987\n",
      "Epoch 3/2000\n",
      "34/34 [==============================] - 8s 221ms/step - loss: 2.4250 - accuracy: 0.4975 - val_loss: 2.3971 - val_accuracy: 0.5019\n",
      "Epoch 4/2000\n",
      "34/34 [==============================] - 8s 222ms/step - loss: 2.3999 - accuracy: 0.5008 - val_loss: 2.3735 - val_accuracy: 0.5006\n",
      "Epoch 5/2000\n",
      "34/34 [==============================] - 8s 223ms/step - loss: 2.3750 - accuracy: 0.5015 - val_loss: 2.3494 - val_accuracy: 0.5008\n",
      "Epoch 6/2000\n",
      "34/34 [==============================] - 8s 224ms/step - loss: 2.3495 - accuracy: 0.5007 - val_loss: 2.3239 - val_accuracy: 0.5021\n",
      "Epoch 7/2000\n",
      "34/34 [==============================] - 8s 234ms/step - loss: 2.3241 - accuracy: 0.5008 - val_loss: 2.3007 - val_accuracy: 0.5020\n",
      "Epoch 8/2000\n",
      "34/34 [==============================] - 8s 234ms/step - loss: 2.3008 - accuracy: 0.4998 - val_loss: 2.2779 - val_accuracy: 0.5014\n",
      "Epoch 9/2000\n",
      "34/34 [==============================] - 8s 232ms/step - loss: 2.2784 - accuracy: 0.5000 - val_loss: 2.2545 - val_accuracy: 0.5019\n",
      "Epoch 10/2000\n",
      "34/34 [==============================] - 8s 232ms/step - loss: 2.2545 - accuracy: 0.5009 - val_loss: 2.2319 - val_accuracy: 0.5022\n",
      "Epoch 11/2000\n",
      "34/34 [==============================] - 8s 229ms/step - loss: 2.2325 - accuracy: 0.4991 - val_loss: 2.2098 - val_accuracy: 0.5020\n",
      "Epoch 12/2000\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 2.2104 - accuracy: 0.4991 - val_loss: 2.1879 - val_accuracy: 0.5022\n",
      "Epoch 13/2000\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 2.1867 - accuracy: 0.5012 - val_loss: 2.1659 - val_accuracy: 0.5021\n",
      "Epoch 14/2000\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 2.1658 - accuracy: 0.4992 - val_loss: 2.1443 - val_accuracy: 0.5021\n",
      "Epoch 15/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 2.1437 - accuracy: 0.5005 - val_loss: 2.1232 - val_accuracy: 0.5021\n",
      "Epoch 16/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 2.1223 - accuracy: 0.5019 - val_loss: 2.1022 - val_accuracy: 0.5021\n",
      "Epoch 17/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 2.1021 - accuracy: 0.4983 - val_loss: 2.0816 - val_accuracy: 0.5021\n",
      "Epoch 18/2000\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 2.0812 - accuracy: 0.4997 - val_loss: 2.0614 - val_accuracy: 0.5021\n",
      "Epoch 19/2000\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 2.0608 - accuracy: 0.4978 - val_loss: 2.0415 - val_accuracy: 0.5021\n",
      "Epoch 20/2000\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 2.0398 - accuracy: 0.5016 - val_loss: 2.0216 - val_accuracy: 0.5021\n",
      "Epoch 21/2000\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 2.0200 - accuracy: 0.4998 - val_loss: 2.0022 - val_accuracy: 0.5020\n",
      "Epoch 22/2000\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 2.0001 - accuracy: 0.5003 - val_loss: 1.9828 - val_accuracy: 0.5019\n",
      "Epoch 23/2000\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 1.9808 - accuracy: 0.4998 - val_loss: 1.9637 - val_accuracy: 0.5019\n",
      "Epoch 24/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.9620 - accuracy: 0.4988 - val_loss: 1.9447 - val_accuracy: 0.5021\n",
      "Epoch 25/2000\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.9430 - accuracy: 0.4990 - val_loss: 1.9261 - val_accuracy: 0.5021\n",
      "Epoch 26/2000\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.9242 - accuracy: 0.4995 - val_loss: 1.9076 - val_accuracy: 0.5021\n",
      "Epoch 27/2000\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.9050 - accuracy: 0.5033 - val_loss: 1.8894 - val_accuracy: 0.5021\n",
      "Epoch 28/2000\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.8872 - accuracy: 0.5008 - val_loss: 1.8714 - val_accuracy: 0.5022\n",
      "Epoch 29/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.8698 - accuracy: 0.4991 - val_loss: 1.8536 - val_accuracy: 0.5023\n",
      "Epoch 30/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.8519 - accuracy: 0.4994 - val_loss: 1.8361 - val_accuracy: 0.5023\n",
      "Epoch 31/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.8340 - accuracy: 0.5013 - val_loss: 1.8188 - val_accuracy: 0.5023\n",
      "Epoch 32/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.8167 - accuracy: 0.5013 - val_loss: 1.8017 - val_accuracy: 0.5023\n",
      "Epoch 33/2000\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 1.7998 - accuracy: 0.4998 - val_loss: 1.7847 - val_accuracy: 0.5026\n",
      "Epoch 34/2000\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 1.7831 - accuracy: 0.4991 - val_loss: 1.7680 - val_accuracy: 0.5027\n",
      "Epoch 35/2000\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 1.7659 - accuracy: 0.5015 - val_loss: 1.7515 - val_accuracy: 0.5029\n",
      "Epoch 36/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.7495 - accuracy: 0.5010 - val_loss: 1.7353 - val_accuracy: 0.5023\n",
      "Epoch 37/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.7332 - accuracy: 0.5007 - val_loss: 1.7191 - val_accuracy: 0.5032\n",
      "Epoch 38/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.7172 - accuracy: 0.5007 - val_loss: 1.7034 - val_accuracy: 0.5019\n",
      "Epoch 39/2000\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.7012 - accuracy: 0.5014 - val_loss: 1.6877 - val_accuracy: 0.5013\n",
      "Epoch 40/2000\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.6864 - accuracy: 0.4973 - val_loss: 1.6722 - val_accuracy: 0.5006\n",
      "Epoch 41/2000\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.6701 - accuracy: 0.5013 - val_loss: 1.6569 - val_accuracy: 0.5038\n",
      "Epoch 42/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.6554 - accuracy: 0.4981 - val_loss: 1.6418 - val_accuracy: 0.5050\n",
      "Epoch 43/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.6401 - accuracy: 0.4992 - val_loss: 1.6269 - val_accuracy: 0.5078\n",
      "Epoch 44/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.6251 - accuracy: 0.4990 - val_loss: 1.6121 - val_accuracy: 0.5117\n",
      "Epoch 45/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.6107 - accuracy: 0.4974 - val_loss: 1.5976 - val_accuracy: 0.5195\n",
      "Epoch 46/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.5957 - accuracy: 0.4994 - val_loss: 1.5832 - val_accuracy: 0.5301\n",
      "Epoch 47/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.5817 - accuracy: 0.4978 - val_loss: 1.5690 - val_accuracy: 0.5379\n",
      "Epoch 48/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.5669 - accuracy: 0.5003 - val_loss: 1.5550 - val_accuracy: 0.5430\n",
      "Epoch 49/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.5529 - accuracy: 0.5003 - val_loss: 1.5411 - val_accuracy: 0.5511\n",
      "Epoch 50/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.5391 - accuracy: 0.4998 - val_loss: 1.5274 - val_accuracy: 0.5506\n",
      "Epoch 51/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.5253 - accuracy: 0.5005 - val_loss: 1.5139 - val_accuracy: 0.5469\n",
      "Epoch 52/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.5114 - accuracy: 0.5024 - val_loss: 1.5006 - val_accuracy: 0.5405\n",
      "Epoch 53/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.4981 - accuracy: 0.5025 - val_loss: 1.4874 - val_accuracy: 0.5381\n",
      "Epoch 54/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.4851 - accuracy: 0.5013 - val_loss: 1.4744 - val_accuracy: 0.5374\n",
      "Epoch 55/2000\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.4729 - accuracy: 0.4970 - val_loss: 1.4616 - val_accuracy: 0.5295\n",
      "Epoch 56/2000\n",
      "10/34 [=======>......................] - ETA: 5s - loss: 1.4637 - accuracy: 0.5010"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m maxEvalRes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m      6\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m checkpoint_dir,  \u001b[38;5;66;03m# Specify the path to save the checkpoints\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Save only the model weights\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Print a message when a checkpoint is saved\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )    \n\u001b[0;32m---> 12\u001b[0m \u001b[43mProtoCNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "\n",
    "maxEvalRes = 0\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_dir,  # Specify the path to save the checkpoints\n",
    "    save_weights_only=True,  # Save only the model weights\n",
    "    monitor='val_loss',  # Monitor the validation loss for saving the best weights\n",
    "    save_best_only=True,  # Save only the best weights based on the monitored metric\n",
    "    verbose=1  # Print a message when a checkpoint is saved\n",
    ")    \n",
    "ProtoCNN.fit(x_train,y_train, batch_size = 4096, epochs=2000, verbose=1, validation_data= (x_dev, y_dev))\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95333a4-c450-42cd-88eb-81baab02da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(opt.get_weights(), open(os.path.join(out_dir, 'optimizer.pt'), 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a6124975-2783-46e4-b779-61a2c730ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProtoCNN.save_weights(os.path.join(out_dir,\"my_weights-finetune.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "16cf1db3-529c-4440-b102-5dce8a653f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/runs/1686708033/my_weights-finetune.pt/assets\n"
     ]
    }
   ],
   "source": [
    "ProtoCNN.save(os.path.join(out_dir,\"my_weights-finetune.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1dafb8d3-bab4-4fa5-8be0-fbc916c2cc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd1655769d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN.load_weights(os.path.join(out_dir,\"my_weights-finetune.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ae7c77-624a-4ff6-bb59-be3c0d89f810",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ProtoCNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mProtoCNN\u001b[49m\u001b[38;5;241m.\u001b[39mload_weights(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc/runs/10_31/best_classifier.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ProtoCNN' is not defined"
     ]
    }
   ],
   "source": [
    "ProtoCNN.load_weights(os.path.join(\"src/runs/10_31/best_classifier.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33ae79e5-7953-44cf-8230-2ba851181529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev_step(x_batch, y_batch):\n",
    "    \"\"\"\n",
    "    Evaluates model on a dev set\n",
    "    \"\"\"\n",
    "    logits= ProtoCNN.predict(x_batch)\n",
    "\n",
    "   \n",
    "\n",
    "    prediction_losses = tf.keras.losses.categorical_crossentropy(y_batch, tf.nn.softmax(logits))\n",
    "\n",
    "    loss =  prediction_losses \n",
    "\n",
    "\n",
    "    predictions = tf.argmax(logits, 1)\n",
    "    correct_predictions = tf.equal(predictions, tf.argmax(y_batch, 1))\n",
    "    \n",
    "    return loss, correct_predictions\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a35f2311-b7c0-461d-a9b4-400ba50bdbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5bc06996-53cc-45b7-81b3-539e44f60b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "264d0458-54f9-4306-a779-86ca74a5aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create testing dataset\n",
    "test_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5a6d942-f46a-46a4-bc5f-f7ef384c4015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 16/16 [00:04<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.6460427641868591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in tqdm(test_loader.batch(4096)):    \n",
    "    test_loss, correct_predictions = dev_step(x_batch, y_batch)  \n",
    "    if correct_predictions_test is None:\n",
    "        correct_predictions_test = correct_predictions\n",
    "    else:\n",
    "        correct_predictions_test = tf.concat((correct_predictions_test, correct_predictions), axis=0)\n",
    "\n",
    "test_accuracy = tf.reduce_mean(tf.cast(correct_predictions_test, tf.float32))\n",
    "print(\"test accuracy {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "032f5a2a-4a7a-497d-adda-22acaa8f930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarc_comments = [ rev['text'] for rev in revs if rev['label'][1]==1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7b9c07d8-763f-4f14-a7a0-f60348c682e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['looks like its time to convince the chineese that siberian tiger bones improve boners',\n",
       " 'shutting down the government and the military at the same time !',\n",
       " \"yay , now i do n't have to pay taxes !\",\n",
       " 'a modern day shakespeare',\n",
       " 'god im done with this sub fuckin circle jerk shit',\n",
       " 'looks like a fun format',\n",
       " 'this film is a serious game changer !',\n",
       " \"well , if you do n't have anything to hide then there is nothing to fear\",\n",
       " 'admissions are great , i get to skip the whole investigation and just ban you !',\n",
       " 'as we all know , apple are the only ones who can innovate',\n",
       " 'hahahaha handicapped people omg lol',\n",
       " \"it 's worth every penny to bring jeeezus back\",\n",
       " 'i hear mien kamph is a very popular book',\n",
       " \"well i'm glad to know that the government still considers shutting down voluntary marketplaces an essential service during the shutdown\",\n",
       " 'trade geno and sid for miller sounds like a great trade',\n",
       " 'wow , never saw that coming',\n",
       " \"if english was good enough for jesus , then it 's good enough for me !\",\n",
       " \"i thought we had something going , what like how ted bundy and his 'girlfriends' had something \\\\?\",\n",
       " 'newest book must have been too close to the truth , amirite \\\\?',\n",
       " 'dude , the hotkey for recall is b , just press it and wait for the whole channel',\n",
       " 'please \\\\( think of the fucking karma',\n",
       " \"i'm sure a business that spends that much time on the fucking counter will be successful beyond their wildest dreams\",\n",
       " 'aww , my heart goes out to those poor nsa workers',\n",
       " \"they 're probably safer there than in america , what with all the discrimination christians face here\",\n",
       " 'let me hop right on that',\n",
       " 'too bad no vendors sell it',\n",
       " \"no that 's funny !\",\n",
       " \"it 's her genes man do n't be oppressive\",\n",
       " \"i ca n't tell the difference between x amp y and red amp blue , they are like the same game !\",\n",
       " \"no but without the government there would n't be any paths to walk on in the woods , there would be no roads , no gift shops , no maps but now that they exist we should probably just get rid of the government\",\n",
       " \"this is a totally original joke that i 've never heard on the internet before\",\n",
       " 'i dunno the rite of spring makes for great breakfast music',\n",
       " 'this is so deep',\n",
       " 'if he continues this rate of one player of the month every month , he will have 40 player of the month awards ten seasons from now',\n",
       " \"op does n't like the fact that smart people have iphones\",\n",
       " 'yeah , because those late third trimester abortions are all the rage these days',\n",
       " 'yeah just like gold farming',\n",
       " \"but but , i thought if the library at alexandria had n't been burned by dark ages christians we would be exploring galaxies !\",\n",
       " 'why must the straight white man always suffer \\\\?',\n",
       " \"i have you know i'm a red belt in boxing and a green belt in no gi bjj\",\n",
       " 'i wish i was literally doing nothing with my life',\n",
       " 'has worked very well with other games , like dota 2 and league of legends',\n",
       " 'sick whip !',\n",
       " 'yeah , fuck the people and the country , this is a matter of pride',\n",
       " \"i know that you 've just been pining away for ten years wishing he 'd ask you to procreate\",\n",
       " \"sounds like something big corporations do it 's not legal \\\\?\",\n",
       " 'yes , you are the only one',\n",
       " 'great parenting there',\n",
       " 'nothing says romantic love like bend over and let me give it to you',\n",
       " 'cool maybe people will stop hating fags now',\n",
       " 'rookie mistake , always lead with the 9 dick',\n",
       " 'thin privilege is getting a real mri in a hospital',\n",
       " 'the picture is nsfw',\n",
       " 'how dare she comment on something',\n",
       " 'link to nexus mod page \\\\?',\n",
       " \"they 're going to announce that the moon landing was faked\",\n",
       " 'yes , i can definitely see how \\\\( slowly \\\\) self assembling legos can more efficiently handle many tasks that a sturdy robotic arm cannot',\n",
       " \"mourinho really destroyed mata 's career huh \\\\?\",\n",
       " \"ca n't imagine why there are downvotes on this\",\n",
       " \"i do n't know guys , that apology seems really sincere\",\n",
       " 'oh , well , if she was insane , then she deserved to be shot , in spite of being unarmed',\n",
       " 'better to have no parents than gay parents',\n",
       " 'i thought fosters was the pride of australia \\\\?',\n",
       " 'they only have wars to thin them out a bit , its probably the reason for the rise of civilisation',\n",
       " 'but the diamond lane has been such a success',\n",
       " \"because a man ca n't be a mentor for a younger man boy without having a sexual driven intention\",\n",
       " \"you forgot the pint of ben and jerry 's , dvd of the notebook , and a long pink glittery satin nightie\",\n",
       " 'hey those wars paid my salary and got me a bitching computer , bro',\n",
       " 'i always like to start with a resounding fuck the po lice it filters out my audience , engages those who remain and really makes a statement about my personal beliefs',\n",
       " \"yah , that 's what they are doing\",\n",
       " \"but that 's because they did n't download the hd\",\n",
       " \"well that 's a fantastic reason to deny yourself a great experience\",\n",
       " 'but guys r truth sucks',\n",
       " 'until a republican does it',\n",
       " \"yeah because theres no possible reason ever to do something illegal that is n't a stupid choice\",\n",
       " 'dupes dupes enjoy b amp calling majicou right now',\n",
       " \"where 's rommel \\\\?\",\n",
       " 'yes , this is a big problem , better push through common core !',\n",
       " 'you laugh now , but proper use of hyphens is of critical importance in our field',\n",
       " 'well bust out the big box of crayons and color me shocked',\n",
       " 'what were you thinking , leading him on like that \\\\?',\n",
       " \"yeah fucking homeless people why do n't they just buy more money like good upstanding folks in dc do !\",\n",
       " 'video is obviously edited , if your elo was as high as peefsmash , then you would see that spiders are perfectly fine and that no such evidence of broken spiders exist you baddie',\n",
       " 'i was expecting a picture of a toddler',\n",
       " 'better learn to kiss ass guys',\n",
       " \"well , that was the least biased article i 've read all day\",\n",
       " 'well they are better than us , and are obviously entitled to use the space that is no longer useful to them as a garbage pale',\n",
       " \"awwww that 's racist\",\n",
       " 'has anyone focked with him yet \\\\?',\n",
       " 'well glad to see turkey had nothing to riot about',\n",
       " 'permanently ribbed for your pleasure',\n",
       " 'my gender',\n",
       " \"it 's not like the us economy going to shit will affect my country\",\n",
       " 'fuck yeah , white power !',\n",
       " \"i know that 's wrestling superstar virgil , but who are the others \\\\?\",\n",
       " 'yes lucky is nearly being demolished by two trucks , wish i could be that lucky',\n",
       " \"age does n't matter , unless you turn him down\",\n",
       " \"because if negging does n't work , a picture of my dick is definitely going to seal the deal\",\n",
       " 'this picture excellently shows your alice costume',\n",
       " \"he 's a terrible individual that should be impeached\"]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarc_comments[500:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4c3b5126-a5b2-4cf9-87dc-440e85cf471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test giving a prediction value to an input\n",
    "testS = [\"i guess no one at google 's ever been on a plane and wanted to listen to their music library\",\n",
    "         \"it 's like windows phone 7 and that worked great\",\n",
    "        'religion must have the answer',\n",
    "        'until a republican does it'\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9dcc1b7b-008c-4047-ace7-00b441e5e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= encode(testS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "27c275e1-ff05-4345-8ad7-e33bded21b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5124252 , 0.48757482],\n",
       "       [0.49226758, 0.50773245],\n",
       "       [0.4995483 , 0.5004517 ],\n",
       "       [0.51824856, 0.48175144]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "67dc8c97-cf57-4427-ac3a-f6eb3fee210e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 10), dtype=float32, numpy=\n",
       "array([[[ 2.7111988 ,  2.8435276 ,  2.8580358 ,  2.4625027 ,\n",
       "          2.8837852 ,  3.2298265 ,  2.8851266 ,  2.779249  ,\n",
       "          2.7834678 ,  2.695945  ],\n",
       "        [13.555579  , 13.56708   , 13.608713  , 13.089714  ,\n",
       "         13.671051  , 14.761423  , 14.198931  , 13.693032  ,\n",
       "         13.776615  , 13.339384  ],\n",
       "        [ 8.140151  ,  8.293659  ,  8.2329035 ,  7.875981  ,\n",
       "          8.249426  ,  8.662914  ,  8.463434  ,  8.189972  ,\n",
       "          8.333049  ,  7.9773016 ],\n",
       "        [ 0.99792427,  1.0499238 ,  1.040509  ,  0.7297432 ,\n",
       "          1.0358859 ,  1.2475713 ,  1.0940286 ,  1.0371547 ,\n",
       "          1.0157193 ,  0.9604418 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN.full_distance(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "caaaefc3-b992-450d-92ed-a90361e51815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 10), dtype=float32, numpy=\n",
       "array([[[0.        , 0.        , 0.        , 0.78172654, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.27009773, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.4549362 , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.9296246 , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN.one_hot_distance(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857578d-24ab-4569-90dc-7420cb22adb9",
   "metadata": {},
   "source": [
    "# Show prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f8009004-0eed-42bd-ba31-0e8907d27834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose with data to sample\n",
    "#compute vector values of sentences\n",
    "import random\n",
    "\n",
    "random.shuffle(train_data)\n",
    "sample_sentences = train_data[:150000]\n",
    "\n",
    "sample_sentences, sample_y = zip(*train_data)\n",
    "encoded_sample_sentences = encode(sample_sentences)\n",
    "sample_sent_vects =[]\n",
    "for i in range(3):\n",
    "    sample_sent_vect = ProtoCNN.embed(encoded_sample_sentences[i*50000:(i+1)*50000])\n",
    "    sample_sent_vects.append(sample_sent_vect)\n",
    "\n",
    "sample_sent_vect = tf.concat(sample_sent_vects, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fed805e3-d819-4ae7-9442-895d46c030db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototypes: \n",
      "0\n",
      "(44384, 0.59639615) i hear there is even an uk one 1\n",
      "(119485, 0.5967583) these kids are going places in life 1\n",
      "(9329, 0.5996673) then you find out it was a land line 1\n",
      "(69175, 0.60089) that seems like someone i wanna hang out with 1\n",
      "(122428, 0.6031556) robin has been in every fe game since the first one 1\n",
      "(76009, 0.60461885) obby nothing gets me hot like o o 1\n",
      "(122435, 0.604776) she really seems to be enjoying it 1\n",
      "(38294, 0.60514015) both of them combined or each of them \\? 1\n",
      "(55014, 0.6053043) whose the girl on the bottom left \\? 1\n",
      "(117943, 0.60653824) who let her leave the house line that 1\n",
      "1\n",
      "(119485, 0.6018789) these kids are going places in life 1\n",
      "(44384, 0.608037) i hear there is even an uk one 1\n",
      "(69175, 0.61627233) that seems like someone i wanna hang out with 1\n",
      "(122428, 0.617497) robin has been in every fe game since the first one 1\n",
      "(76009, 0.62080157) obby nothing gets me hot like o o 1\n",
      "(122435, 0.621308) she really seems to be enjoying it 1\n",
      "(9329, 0.621637) then you find out it was a land line 1\n",
      "(117943, 0.62188625) who let her leave the house line that 1\n",
      "(133437, 0.6236718) i present the best friend of the year 1\n",
      "(53259, 0.62463146) the geometry is strong with this one 1\n",
      "2\n",
      "(44384, 0.5831432) i hear there is even an uk one 1\n",
      "(122428, 0.5904349) robin has been in every fe game since the first one 1\n",
      "(69175, 0.59280723) that seems like someone i wanna hang out with 1\n",
      "(119485, 0.59322816) these kids are going places in life 1\n",
      "(32937, 0.5954087) underratted comment of the day 1\n",
      "(117943, 0.60170656) who let her leave the house line that 1\n",
      "(76009, 0.6041391) obby nothing gets me hot like o o 1\n",
      "(44837, 0.605074) actually that 's the third hand 1\n",
      "(100966, 0.605084) this isnt a repost of something that was front page today 1\n",
      "(138103, 0.60571325) that looks more like it 's next to point 1\n",
      "3\n",
      "(119485, 0.3135772) these kids are going places in life 1\n",
      "(44384, 0.3172326) i hear there is even an uk one 1\n",
      "(117943, 0.32124335) who let her leave the house line that 1\n",
      "(69175, 0.32230243) that seems like someone i wanna hang out with 1\n",
      "(62302, 0.3228807) you could n't make up a title like that 1\n",
      "(130623, 0.32551184) someone 's moving house and home 1\n",
      "(75365, 0.32663426) he looks exactly like what i 'd imagine someone like this to look like 1\n",
      "(122428, 0.32718822) robin has been in every fe game since the first one 1\n",
      "(76009, 0.32777935) obby nothing gets me hot like o o 1\n",
      "(98885, 0.32828987) something for meth or something like that 1\n",
      "4\n",
      "(44384, 0.6082071) i hear there is even an uk one 1\n",
      "(119485, 0.60869145) these kids are going places in life 1\n",
      "(122428, 0.61276007) robin has been in every fe game since the first one 1\n",
      "(69175, 0.6159998) that seems like someone i wanna hang out with 1\n",
      "(117943, 0.617122) who let her leave the house line that 1\n",
      "(76009, 0.6179304) obby nothing gets me hot like o o 1\n",
      "(53259, 0.61882365) the geometry is strong with this one 1\n",
      "(122435, 0.62138885) she really seems to be enjoying it 1\n",
      "(66787, 0.62140054) this is n't on the front page or anything already 1\n",
      "(85208, 0.62225467) i think the title really passes in this case 1\n",
      "5\n",
      "(44384, 0.7273682) i hear there is even an uk one 1\n",
      "(119485, 0.7377776) these kids are going places in life 1\n",
      "(117943, 0.73851156) who let her leave the house line that 1\n",
      "(69175, 0.73923284) that seems like someone i wanna hang out with 1\n",
      "(122428, 0.745358) robin has been in every fe game since the first one 1\n",
      "(26902, 0.74751705) i think i had a seizure while reading this 1\n",
      "(33038, 0.7486297) ben carson would like to have a word 1\n",
      "(76009, 0.7516241) obby nothing gets me hot like o o 1\n",
      "(32937, 0.7518057) underratted comment of the day 1\n",
      "(122435, 0.7535135) she really seems to be enjoying it 1\n",
      "6\n",
      "(44384, 0.64066017) i hear there is even an uk one 1\n",
      "(119485, 0.6470041) these kids are going places in life 1\n",
      "(76009, 0.6522161) obby nothing gets me hot like o o 1\n",
      "(117943, 0.65262914) who let her leave the house line that 1\n",
      "(69175, 0.65703857) that seems like someone i wanna hang out with 1\n",
      "(122428, 0.6589552) robin has been in every fe game since the first one 1\n",
      "(122435, 0.66059154) she really seems to be enjoying it 1\n",
      "(93803, 0.66322654) this person is going to go far in life 1\n",
      "(65722, 0.6659496) funniest thing ive ever seen in my entire life 1\n",
      "(62302, 0.66678375) you could n't make up a title like that 1\n",
      "7\n",
      "(44384, 0.5800428) i hear there is even an uk one 1\n",
      "(76009, 0.59111315) obby nothing gets me hot like o o 1\n",
      "(69175, 0.59369564) that seems like someone i wanna hang out with 1\n",
      "(117943, 0.5963245) who let her leave the house line that 1\n",
      "(122428, 0.5984019) robin has been in every fe game since the first one 1\n",
      "(119485, 0.6015933) these kids are going places in life 1\n",
      "(9329, 0.60541177) then you find out it was a land line 1\n",
      "(133437, 0.6084397) i present the best friend of the year 1\n",
      "(125268, 0.609801) also , if you have just a little bit of ketchup left pour in some water and shake it up 1\n",
      "(33038, 0.6110608) ben carson would like to have a word 1\n",
      "8\n",
      "(44384, 0.59924656) i hear there is even an uk one 1\n",
      "(119485, 0.6047484) these kids are going places in life 1\n",
      "(122428, 0.6097351) robin has been in every fe game since the first one 1\n",
      "(117943, 0.61271435) who let her leave the house line that 1\n",
      "(69175, 0.6130508) that seems like someone i wanna hang out with 1\n",
      "(76009, 0.61474687) obby nothing gets me hot like o o 1\n",
      "(53259, 0.61475676) the geometry is strong with this one 1\n",
      "(70286, 0.6184868) i just love that it takes the video that long to get to the point 1\n",
      "(32937, 0.62032974) underratted comment of the day 1\n",
      "(93803, 0.62146324) this person is going to go far in life 1\n",
      "9\n",
      "(44384, 0.53771305) i hear there is even an uk one 1\n",
      "(119485, 0.5432793) these kids are going places in life 1\n",
      "(117943, 0.5436392) who let her leave the house line that 1\n",
      "(76009, 0.54999053) obby nothing gets me hot like o o 1\n",
      "(9329, 0.550529) then you find out it was a land line 1\n",
      "(69175, 0.55125946) that seems like someone i wanna hang out with 1\n",
      "(93803, 0.5517626) this person is going to go far in life 1\n",
      "(144893, 0.552848) hahahahahahhahahahahahahahahahahahahahahahahahaha 1\n",
      "(122435, 0.5543476) she really seems to be enjoying it 1\n",
      "(18994, 0.5566247) mit if you do n't know when to use to or too 1\n"
     ]
    }
   ],
   "source": [
    "mapped_prototype = showPrototypes(sample_sentences,sample_sent_vect,sample_y, k_protos=10,printOutput=False, k_closest_sents = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c46d1f14-6112-4dce-83d0-a35ff82b50ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('these kids are going places in life', 0.3135772, 1),\n",
       " ('i hear there is even an uk one', 0.3172326, 1),\n",
       " ('who let her leave the house line that', 0.32124335, 1),\n",
       " ('that seems like someone i wanna hang out with', 0.32230243, 1),\n",
       " (\"you could n't make up a title like that\", 0.3228807, 1),\n",
       " (\"someone 's moving house and home\", 0.32551184, 1),\n",
       " (\"he looks exactly like what i 'd imagine someone like this to look like\",\n",
       "  0.32663426,\n",
       "  1),\n",
       " ('robin has been in every fe game since the first one', 0.32718822, 1),\n",
       " ('obby nothing gets me hot like o o', 0.32777935, 1),\n",
       " ('something for meth or something like that', 0.32828987, 1),\n",
       " ('i just love that it takes the video that long to get to the point',\n",
       "  0.3287512,\n",
       "  1),\n",
       " (\"that looks more like it 's next to point\", 0.32890695, 1),\n",
       " ('she really seems to be enjoying it', 0.33070856, 1),\n",
       " ('the one with the bear , i think', 0.33257347, 1),\n",
       " ('i think i had a seizure while reading this', 0.33272243, 1),\n",
       " ('funniest thing ive ever seen in my entire life', 0.33317474, 1),\n",
       " (\"does n't look like an issue for me\", 0.3342791, 1),\n",
       " ('the fact that people actually disagree with me sometimes', 0.3363693, 1),\n",
       " ('underratted comment of the day', 0.33721542, 1),\n",
       " ('this person is going to go far in life', 0.33753684, 1),\n",
       " ('the geometry is strong with this one', 0.338559, 1),\n",
       " (\"this is n't on the front page or anything already\", 0.33967176, 1),\n",
       " ('why not put the full thing on it', 0.34032157, 1),\n",
       " ('when i see your face it does give me hell', 0.34149516, 1),\n",
       " ('sad thing is , i can actually belive this', 0.34167826, 1),\n",
       " ('regretting my decision to go with each passing day', 0.34179804, 1),\n",
       " ('can someone explain this for me \\\\?', 0.34213352, 1),\n",
       " ('you know i think this guy has a chance of making it', 0.34213576, 1),\n",
       " (\"actually that 's the third hand\", 0.34297392, 1),\n",
       " ('this guy is almost as good as me', 0.34312445, 1),\n",
       " (\"it 's not as if he 's the titular character or anything\", 0.3433476, 1),\n",
       " ('reverse spin direction and push it', 0.34385487, 1),\n",
       " ('use pliers or a wrench to pull it out', 0.34417415, 1),\n",
       " (\"i ca n't think of any two people i 'd rather get up close and personal with\",\n",
       "  0.34451818,\n",
       "  1),\n",
       " ('that was me , i got high and started drawing on shit', 0.344531, 1),\n",
       " ('while i read this during a shit', 0.34476843, 1),\n",
       " ('whose the girl on the bottom left \\\\?', 0.34512696, 1),\n",
       " ('the hype is strong in this one', 0.34538028, 1),\n",
       " ('ben carson would like to have a word', 0.34550968, 1),\n",
       " ('both of them combined or each of them \\\\?', 0.34637365, 1),\n",
       " ('then you find out it was a land line', 0.34771985, 1),\n",
       " ('one eye poke made the fight \\\\) \\\\) \\\\)', 0.3478808, 1),\n",
       " ('i think the title really passes in this case', 0.34862307, 1),\n",
       " ('where is the all of the above \\\\?', 0.35043287, 1),\n",
       " ('i came here to cringe not to think', 0.3506609, 1),\n",
       " ('really terrible stuff in there', 0.35132548, 1),\n",
       " ('nono finger sits on the front row to the left', 0.3515544, 1),\n",
       " (\"i do n't think i 'd take my salt any other way\", 0.35186923, 1),\n",
       " ('was it the computer on the left \\\\?', 0.35187796, 1),\n",
       " ('better let as many of them into europe as possible', 0.3523066, 1),\n",
       " (\"it 's out on my birthday \\\\) someone here should by it for me\",\n",
       "  0.3525476,\n",
       "  1),\n",
       " ('i cant stay and work here for ever', 0.35292253, 1),\n",
       " ('deserves to crash with a shirt like that', 0.35434902, 1),\n",
       " ('\\\\( just like the person making that photo \\\\)', 0.3543504, 1),\n",
       " (\"mit if you do n't know when to use to or too\", 0.35495317, 1),\n",
       " ('one looks a bit worse the bottom one i think', 0.35497248, 1),\n",
       " ('i think you might be the first person to ever complain about this in the history of time',\n",
       "  0.3552216,\n",
       "  1),\n",
       " ('should have shot him or strung him up from a tree just in case',\n",
       "  0.35523936,\n",
       "  1),\n",
       " ('it took a whole month for that \\\\?', 0.3553446, 1),\n",
       " ('by doing the same thing i do every night and day nothing', 0.3557903, 1),\n",
       " ('should have kept this in house', 0.356741, 1),\n",
       " ('was there anything else in this video \\\\?', 0.3571822, 1),\n",
       " ('burning man became terrible exactly the year after i went that one time',\n",
       "  0.35728908,\n",
       "  1),\n",
       " ('what a whiny little prick on the left', 0.35746264, 1),\n",
       " (\"i 've been thinking about this all day\", 0.35759634, 1),\n",
       " ('can i request one for my school', 0.35782492, 1),\n",
       " ('i think you are confusing with', 0.35787094, 1),\n",
       " ('is there a difference between them \\\\?', 0.35826674, 1),\n",
       " ('right that almost the same thing', 0.35840473, 1),\n",
       " (\"easily the most fucked up thing i 've seen today\", 0.35866416, 1),\n",
       " ('this is going to the front page', 0.35923013, 1),\n",
       " ('can i log in using facebook \\\\?', 0.35942808, 1),\n",
       " ('does this qualify as a scary moment too \\\\?', 0.3595601, 1),\n",
       " ('hollywood need to make a movie on this', 0.35956013, 1),\n",
       " ('just trying 2 fit in but stand out', 0.35960123, 1),\n",
       " ('what do you do at that hour , if not this \\\\?', 0.35965958, 1),\n",
       " ('onlinebots living up to their name', 0.3604018, 1),\n",
       " ('now that looks like a president i could have a beer with', 0.3606794, 1),\n",
       " ('sounds like jesus himself said this', 0.3607124, 1),\n",
       " ('he might get that this year tbh', 0.36084092, 1),\n",
       " ('this isnt a repost of something that was front page today', 0.3612252, 1),\n",
       " ('i love reminiscing about that day myself', 0.36168668, 1),\n",
       " ('see what happens when you do spinning shit', 0.36211467, 1),\n",
       " ('is this guy rich or something \\\\?', 0.36289462, 1),\n",
       " ('your not supposed to mention that', 0.36335245, 1),\n",
       " ('a superior phone , like say , a galaxy would have been able to take that',\n",
       "  0.36363792,\n",
       "  1),\n",
       " ('i present the best friend of the year', 0.36383536, 1),\n",
       " ('the war on christmas is getting out of hand', 0.363868, 1),\n",
       " ('why are you posting stuff from back in january \\\\?', 0.36397707, 1),\n",
       " ('also , if you have just a little bit of ketchup left pour in some water and shake it up',\n",
       "  0.36414933,\n",
       "  1),\n",
       " ('south park has been any good since the fifth season of the simpsons',\n",
       "  0.36521426,\n",
       "  1),\n",
       " ('anybody got a link to the video \\\\?', 0.36533156, 1),\n",
       " ('is that not part of the process \\\\?', 0.36554062, 1),\n",
       " ('blame the west works every time', 0.36574072, 1),\n",
       " (\"funniest thing i 've seen in a while\", 0.36575007, 1),\n",
       " ('just the fucking way i like it', 0.3665198, 1),\n",
       " ('how did they get the picture \\\\?', 0.36662766, 1),\n",
       " (\"you go first and then i 'll think about it\", 0.36763626, 1),\n",
       " ('everything happens for a reason', 0.3676815, 1),\n",
       " ('is it a five or ten page book \\\\?', 0.3678158, 1)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_prototype[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "43a7a2b6-0ce9-4b39-86b6-4663e0f0366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_prototype_150000 = mapped_prototype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "567915d2-daad-42eb-8854-df23b609cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_sentences(sent, mapped_prototype):\n",
    "    sentence_embed = ProtoCNN.embed(np.expand_dims(sent, 0))\n",
    "   \n",
    "    protos = [x[0] for x in mapped_prototype]\n",
    "    proto_embed = ProtoCNN.embed(encode(protos))\n",
    "    distances = [(index, np.linalg.norm(embed - sentence_embed)) for index, embed in enumerate(proto_embed)]\n",
    "    output = [mapped_prototype[x[0]] for x in sorted(distances, key= lambda x: x[1])]\n",
    "    \n",
    "    return output[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a51235df-a56c-465a-b0b1-459b642326b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('better let as many of them into europe as possible', 0.3523066, 1),\n",
       " ('onlinebots living up to their name', 0.3604018, 1),\n",
       " ('everything happens for a reason', 0.3676815, 1),\n",
       " (\"you could n't make up a title like that\", 0.3228807, 1),\n",
       " ('why not put the full thing on it', 0.34032157, 1),\n",
       " ('really terrible stuff in there', 0.35132548, 1),\n",
       " ('you know i think this guy has a chance of making it', 0.34213576, 1),\n",
       " ('i came here to cringe not to think', 0.3506609, 1),\n",
       " ('deserves to crash with a shirt like that', 0.35434902, 1),\n",
       " ('your not supposed to mention that', 0.36335245, 1)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_sentences(x[0], mapped_prototype[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6d8f6155-1107-4329-8dc9-6774f60c52b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"i 've been thinking about this all day\", 0.35759634, 1),\n",
       " ('by doing the same thing i do every night and day nothing', 0.3557903, 1),\n",
       " ('now that looks like a president i could have a beer with', 0.3606794, 1),\n",
       " ('this person is going to go far in life', 0.33753684, 1),\n",
       " ('a superior phone , like say , a galaxy would have been able to take that',\n",
       "  0.36363792,\n",
       "  1),\n",
       " ('burning man became terrible exactly the year after i went that one time',\n",
       "  0.35728908,\n",
       "  1),\n",
       " ('i cant stay and work here for ever', 0.35292253, 1),\n",
       " ('better let as many of them into europe as possible', 0.3523066, 1),\n",
       " ('sounds like jesus himself said this', 0.3607124, 1),\n",
       " ('should have shot him or strung him up from a tree just in case',\n",
       "  0.35523936,\n",
       "  1)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_sentences(x[1], mapped_prototype[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e04ed7f5-6f50-43e0-a2a3-11a143746d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('can i request one for my school', 0.35782492, 1),\n",
       " ('your not supposed to mention that', 0.36335245, 1),\n",
       " ('i cant stay and work here for ever', 0.35292253, 1),\n",
       " ('sad thing is , i can actually belive this', 0.34167826, 1),\n",
       " (\"you go first and then i 'll think about it\", 0.36763626, 1),\n",
       " ('funniest thing ive ever seen in my entire life', 0.33317474, 1),\n",
       " ('you know i think this guy has a chance of making it', 0.34213576, 1),\n",
       " ('i just love that it takes the video that long to get to the point',\n",
       "  0.3287512,\n",
       "  1),\n",
       " ('everything happens for a reason', 0.3676815, 1),\n",
       " (\"i do n't think i 'd take my salt any other way\", 0.35186923, 1)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_sentences(x[2], mapped_prototype[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ba70c87e-6615-4f02-af09-d9ced8cec690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'until a republican does it'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testS[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6a93668a-5a03-40ee-8b1c-f5b0b1903306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('right that almost the same thing', 0.35840473, 1),\n",
       " ('while i read this during a shit', 0.34476843, 1),\n",
       " ('your not supposed to mention that', 0.36335245, 1),\n",
       " ('just the fucking way i like it', 0.3665198, 1),\n",
       " (\"you could n't make up a title like that\", 0.3228807, 1),\n",
       " ('sad thing is , i can actually belive this', 0.34167826, 1),\n",
       " ('something for meth or something like that', 0.32828987, 1),\n",
       " ('she really seems to be enjoying it', 0.33070856, 1),\n",
       " ('see what happens when you do spinning shit', 0.36211467, 1),\n",
       " ('that was me , i got high and started drawing on shit', 0.344531, 1)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_sentences(x[3], mapped_prototype[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "7aef54d6-b336-41d3-b923-3bdcabf72c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e872131f-fa08-4ba8-8871-1c2fecb3ff59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"i 've been thinking about this all day\", 0.35759634, 1)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_prototype[3][63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6a81dfcc-abad-48fd-9427-b36285cf9dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 384), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.01237033],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.01237033],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.01237033],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.01237033],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.01237033],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.05296943]], dtype=float32)>"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto3_embed list_c.index(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "5506ff2b-0db0-4888-8b4a-15b11e159c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('these kids are going places in life', 0.3135772, 1),\n",
       " ('i hear there is even an uk one', 0.3172326, 1),\n",
       " ('who let her leave the house line that', 0.32124335, 1),\n",
       " ('that seems like someone i wanna hang out with', 0.32230243, 1),\n",
       " (\"you could n't make up a title like that\", 0.3228807, 1),\n",
       " (\"someone 's moving house and home\", 0.32551184, 1),\n",
       " (\"he looks exactly like what i 'd imagine someone like this to look like\",\n",
       "  0.32663426,\n",
       "  1),\n",
       " ('robin has been in every fe game since the first one', 0.32718822, 1),\n",
       " ('obby nothing gets me hot like o o', 0.32777935, 1),\n",
       " ('something for meth or something like that', 0.32828987, 1),\n",
       " ('i just love that it takes the video that long to get to the point',\n",
       "  0.3287512,\n",
       "  1),\n",
       " (\"that looks more like it 's next to point\", 0.32890695, 1),\n",
       " ('she really seems to be enjoying it', 0.33070856, 1),\n",
       " ('the one with the bear , i think', 0.33257347, 1),\n",
       " ('i think i had a seizure while reading this', 0.33272243, 1),\n",
       " ('funniest thing ive ever seen in my entire life', 0.33317474, 1),\n",
       " (\"does n't look like an issue for me\", 0.3342791, 1),\n",
       " ('the fact that people actually disagree with me sometimes', 0.3363693, 1),\n",
       " ('underratted comment of the day', 0.33721542, 1),\n",
       " ('this person is going to go far in life', 0.33753684, 1),\n",
       " ('the geometry is strong with this one', 0.338559, 1),\n",
       " (\"this is n't on the front page or anything already\", 0.33967176, 1),\n",
       " ('why not put the full thing on it', 0.34032157, 1),\n",
       " ('when i see your face it does give me hell', 0.34149516, 1),\n",
       " ('sad thing is , i can actually belive this', 0.34167826, 1),\n",
       " ('regretting my decision to go with each passing day', 0.34179804, 1),\n",
       " ('can someone explain this for me \\\\?', 0.34213352, 1),\n",
       " ('you know i think this guy has a chance of making it', 0.34213576, 1),\n",
       " (\"actually that 's the third hand\", 0.34297392, 1),\n",
       " ('this guy is almost as good as me', 0.34312445, 1),\n",
       " (\"it 's not as if he 's the titular character or anything\", 0.3433476, 1),\n",
       " ('reverse spin direction and push it', 0.34385487, 1),\n",
       " ('use pliers or a wrench to pull it out', 0.34417415, 1),\n",
       " (\"i ca n't think of any two people i 'd rather get up close and personal with\",\n",
       "  0.34451818,\n",
       "  1),\n",
       " ('that was me , i got high and started drawing on shit', 0.344531, 1),\n",
       " ('while i read this during a shit', 0.34476843, 1),\n",
       " ('whose the girl on the bottom left \\\\?', 0.34512696, 1),\n",
       " ('the hype is strong in this one', 0.34538028, 1),\n",
       " ('ben carson would like to have a word', 0.34550968, 1),\n",
       " ('both of them combined or each of them \\\\?', 0.34637365, 1),\n",
       " ('then you find out it was a land line', 0.34771985, 1),\n",
       " ('one eye poke made the fight \\\\) \\\\) \\\\)', 0.3478808, 1),\n",
       " ('i think the title really passes in this case', 0.34862307, 1),\n",
       " ('where is the all of the above \\\\?', 0.35043287, 1),\n",
       " ('i came here to cringe not to think', 0.3506609, 1),\n",
       " ('really terrible stuff in there', 0.35132548, 1),\n",
       " ('nono finger sits on the front row to the left', 0.3515544, 1),\n",
       " (\"i do n't think i 'd take my salt any other way\", 0.35186923, 1),\n",
       " ('was it the computer on the left \\\\?', 0.35187796, 1),\n",
       " ('better let as many of them into europe as possible', 0.3523066, 1),\n",
       " (\"it 's out on my birthday \\\\) someone here should by it for me\",\n",
       "  0.3525476,\n",
       "  1),\n",
       " ('i cant stay and work here for ever', 0.35292253, 1),\n",
       " ('\\\\( just like the person making that photo \\\\)', 0.3543504, 1),\n",
       " (\"mit if you do n't know when to use to or too\", 0.35495317, 1),\n",
       " ('one looks a bit worse the bottom one i think', 0.35497248, 1),\n",
       " ('i think you might be the first person to ever complain about this in the history of time',\n",
       "  0.3552216,\n",
       "  1),\n",
       " ('should have shot him or strung him up from a tree just in case',\n",
       "  0.35523936,\n",
       "  1),\n",
       " ('it took a whole month for that \\\\?', 0.3553446, 1),\n",
       " ('by doing the same thing i do every night and day nothing', 0.3557903, 1),\n",
       " ('should have kept this in house', 0.356741, 1),\n",
       " ('was there anything else in this video \\\\?', 0.3571822, 1),\n",
       " ('burning man became terrible exactly the year after i went that one time',\n",
       "  0.35728908,\n",
       "  1),\n",
       " ('what a whiny little prick on the left', 0.35746264, 1),\n",
       " (\"i 've been thinking about this all day\", 0.35759634, 1),\n",
       " ('can i request one for my school', 0.35782492, 1),\n",
       " ('i think you are confusing with', 0.35787094, 1),\n",
       " ('is there a difference between them \\\\?', 0.35826674, 1),\n",
       " ('right that almost the same thing', 0.35840473, 1),\n",
       " ('did this get deleted off the front page yet \\\\?', 0.35856345, 1),\n",
       " (\"easily the most fucked up thing i 've seen today\", 0.35866416, 1),\n",
       " ('this is going to the front page', 0.35923013, 1),\n",
       " ('can i log in using facebook \\\\?', 0.35942808, 1),\n",
       " ('does this qualify as a scary moment too \\\\?', 0.3595601, 1),\n",
       " ('hollywood need to make a movie on this', 0.35956013, 1),\n",
       " ('just trying 2 fit in but stand out', 0.35960123, 1),\n",
       " ('what do you do at that hour , if not this \\\\?', 0.35965958, 1),\n",
       " ('onlinebots living up to their name', 0.3604018, 1),\n",
       " ('now that looks like a president i could have a beer with', 0.3606794, 1),\n",
       " ('sounds like jesus himself said this', 0.3607124, 1),\n",
       " ('he might get that this year tbh', 0.36084092, 1),\n",
       " ('this isnt a repost of something that was front page today', 0.3612252, 1),\n",
       " ('i love reminiscing about that day myself', 0.36168668, 1),\n",
       " ('see what happens when you do spinning shit', 0.36211467, 1),\n",
       " ('is this guy rich or something \\\\?', 0.36289462, 1),\n",
       " ('your not supposed to mention that', 0.36335245, 1),\n",
       " ('a superior phone , like say , a galaxy would have been able to take that',\n",
       "  0.36363792,\n",
       "  1),\n",
       " ('i present the best friend of the year', 0.36383536, 1),\n",
       " ('the war on christmas is getting out of hand', 0.363868, 1),\n",
       " ('why are you posting stuff from back in january \\\\?', 0.36397707, 1),\n",
       " ('also , if you have just a little bit of ketchup left pour in some water and shake it up',\n",
       "  0.36414933,\n",
       "  1),\n",
       " ('south park has been any good since the fifth season of the simpsons',\n",
       "  0.36521426,\n",
       "  1),\n",
       " ('anybody got a link to the video \\\\?', 0.36533156, 1),\n",
       " ('blame the west works every time', 0.36574072, 1),\n",
       " (\"funniest thing i 've seen in a while\", 0.36575007, 1),\n",
       " ('clinton will be done if this happens', 0.36631563, 1),\n",
       " ('just the fucking way i like it', 0.3665198, 1),\n",
       " ('how did they get the picture \\\\?', 0.36662766, 1),\n",
       " (\"you go first and then i 'll think about it\", 0.36763626, 1),\n",
       " ('everything happens for a reason', 0.3676815, 1),\n",
       " ('is it a five or ten page book \\\\?', 0.3678158, 1)]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_prototype[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "1841c2b6-7aaf-4df0-a6bf-e7706550a187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shrek , especially the first one', 0.5935609, 0),\n",
       " (\"holy shit it 's already been a year \\\\?\", 0.6024625, 0),\n",
       " ('brazilian in britain , probably both', 0.6050657, 0),\n",
       " ('the rifle from a regular store and my sister painted it', 0.60792977, 0),\n",
       " ('do you mind giving me the demo of that \\\\?', 0.60851675, 0),\n",
       " ('none of them can stop the time', 0.6088037, 0),\n",
       " ('anyone have a video of the incident \\\\?', 0.60930187, 0),\n",
       " ('one of the names is visible towards the bottom', 0.6107298, 0),\n",
       " ('give portland some love for once', 0.61119914, 0),\n",
       " ('make it twice as thick with a battery that lasts twice as long',\n",
       "  0.6117877,\n",
       "  0),\n",
       " ('he just got on a list by searching for that', 0.61233556, 0),\n",
       " ('16 is a worryingly high number', 0.6130593, 0),\n",
       " (\"what 's the source for this \\\\?\", 0.61373526, 0),\n",
       " ('hope you enjoy it other people are paying for it', 0.61425763, 0),\n",
       " ('did you even watch the video \\\\?', 0.6157763, 0),\n",
       " ('they were not going to gain anything anyway', 0.6159876, 0),\n",
       " ('the us could learn a thing or two from this', 0.6166027, 0),\n",
       " ('does this not load on mobile for others \\\\?', 0.6172237, 0),\n",
       " ('side to side or front to back \\\\?', 0.6201905, 0),\n",
       " ('and im dancing d i kinda like that', 0.620812, 0),\n",
       " ('are we not doing phrasing anymore \\\\?', 0.62093306, 0),\n",
       " ('do i have to play a single match to get these \\\\?', 0.62313, 0),\n",
       " ('people are taking this very seriously', 0.62326515, 0),\n",
       " ('these extra large scissors are getting out of hand', 0.624424, 0),\n",
       " ('regretting my decision to go with each passing day', 0.6249399, 1),\n",
       " ('your character looks like shit', 0.624956, 0),\n",
       " ('you can get it on minions too i think', 0.6250879, 0),\n",
       " ('joan of arc rollin in her grave', 0.6258995, 0),\n",
       " ('blame the west works every time', 0.6265719, 1),\n",
       " ('also , if you have just a little bit of ketchup left pour in some water and shake it up',\n",
       "  0.6269192,\n",
       "  1),\n",
       " ('flags from other countries would be nice too', 0.62702686, 0),\n",
       " ('links to other videos anyone \\\\?', 0.62774837, 0),\n",
       " ('the members were too young to be on facebook \\\\?', 0.6281299, 0),\n",
       " ('do you want turd sandwich or a giant douche \\\\?', 0.6285826, 0),\n",
       " ('is that dodger for press heart to continue \\\\?', 0.62987214, 0),\n",
       " ('full metal jacket opened my eyes to this one', 0.6300228, 0),\n",
       " ('someone is not going to get a walk after donny gets home', 0.6301969, 0),\n",
       " ('are people still buying this stuff \\\\?', 0.6306597, 0),\n",
       " (\"i think you 're talking about the web \\\\?\", 0.63081646, 0),\n",
       " ('a sequel to the martian would be pretty cool i think', 0.6308886, 0),\n",
       " ('england algeria in the 2010 world cup', 0.63140756, 0),\n",
       " ('one eye poke made the fight \\\\) \\\\) \\\\)', 0.6320329, 1),\n",
       " ('unfortunately , i feel like bradford is next', 0.6328622, 0),\n",
       " (\"looks like shit but i 'd still eat it\", 0.6328915, 0),\n",
       " (\"that 's actually kind of sad in a way\", 0.6333719, 0),\n",
       " ('freshman year , high school or college \\\\?', 0.6334113, 1),\n",
       " ('for real though , i kinda want a hamburger now', 0.6342192, 0),\n",
       " ('are wwe rings stiffer than others \\\\?', 0.6349757, 0),\n",
       " ('hello phillip schofield , i fuck lobsters for money', 0.63667554, 0),\n",
       " ('does this really need to be posted week after week \\\\?', 0.63672155, 0),\n",
       " ('did he pull up to the wrong side of the pump \\\\?', 0.63681144, 0),\n",
       " (\"i 'd love this , i hate that fucker\", 0.63688725, 0),\n",
       " ('i think you are confusing with', 0.63728064, 1),\n",
       " ('oce challenger looking good this year', 0.63760686, 0),\n",
       " ('the same old story unfortunately', 0.63812655, 0),\n",
       " ('too early to tell by the looks of it', 0.6381723, 0),\n",
       " ('i was wondering when it was going to happen', 0.63826644, 0),\n",
       " (\"this is simply one of the most retarded articles i 've read in a long while\",\n",
       "  0.6385116,\n",
       "  0),\n",
       " ('well there is a lot of pink on it', 0.639449, 1),\n",
       " ('classes start next week , looking forward to this feeling again',\n",
       "  0.63948315,\n",
       "  1),\n",
       " ('but seriously , what actually happened \\\\?', 0.6397859, 0),\n",
       " ('is it me or is that freddy in the corner getting closer \\\\?',\n",
       "  0.64014393,\n",
       "  0),\n",
       " ('until the clutch shits the bed', 0.64027137, 0),\n",
       " ('literally never had this happen to me', 0.6403277, 0),\n",
       " ('tim meadows needs to be the next colonel', 0.64034045, 0),\n",
       " ('shut up and take my money already', 0.640674, 1),\n",
       " ('onlinebots living up to their name', 0.6413125, 1),\n",
       " ('is that a puffin in a bear suit \\\\?', 0.64151627, 0),\n",
       " ('i think this is the kind of shit we can do without here', 0.64157754, 0),\n",
       " ('she is winning , what polls are they looking at \\\\?', 0.642666, 0),\n",
       " (\"i'm live in roanoke and just learning of this\", 0.64278626, 0),\n",
       " ('more articles about this subject please', 0.64295685, 1),\n",
       " ('roadhog cosplay on point though', 0.64314085, 0),\n",
       " ('haha is this a joke , i actually laughed', 0.6437672, 0),\n",
       " ('is that from land of the rising sun \\\\?', 0.64441746, 0),\n",
       " ('anything that makes noise and or mess', 0.6446741, 0),\n",
       " ('is this out in the us already \\\\?', 0.6453868, 0),\n",
       " ('something that will sit on the website for months labeled coming soon',\n",
       "  0.6454906,\n",
       "  0),\n",
       " (\"you could n't pay me to watch a game at an awkward angle like that\",\n",
       "  0.64553314,\n",
       "  0),\n",
       " ('the oceans grow stronger with each passing day', 0.64600027, 0),\n",
       " (\"stickin' up for the little guy ' \\\\)\", 0.646011, 0),\n",
       " ('how does a man run for public office with a face that is that punchable \\\\?',\n",
       "  0.6461115,\n",
       "  0),\n",
       " ('can someone write that out so i can copy and paste it onto a friends profile picture \\\\?',\n",
       "  0.6469502,\n",
       "  0),\n",
       " ('writings was on the wall with the amount pt nephew gets', 0.6478189, 0),\n",
       " ('are you serious get out of here with this nonsense', 0.64805365, 0),\n",
       " ('that intros incredibly long considering it leads to nothing', 0.6483552, 0),\n",
       " ('welcome to yesterday i guess \\\\?', 0.64849085, 0),\n",
       " ('thought this was from the onion', 0.64878327, 0),\n",
       " ('wtf are these governments doing \\\\?', 0.6498942, 0),\n",
       " ('does anyone listen to the un \\\\?', 0.6501581, 0),\n",
       " ('judging by the downvotes on imgur there are a lot of jealous people on there',\n",
       "  0.6507733,\n",
       "  0),\n",
       " ('except it was san bernardino pd', 0.65157425, 0),\n",
       " ('should i just mail her my testicles \\\\?', 0.65248674, 0),\n",
       " (\"reddit 's a dating site now \\\\?\", 0.65369195, 0),\n",
       " ('the soviets start cheering for rocky at the end of the fourth one',\n",
       "  0.65382624,\n",
       "  0),\n",
       " ('do you really want me to just list every single film \\\\?', 0.653862, 0),\n",
       " ('eugh i accidentally clicked on a link to the mirror', 0.6541268, 0),\n",
       " ('try looking in some fortified house in abbottabad maybe \\\\?',\n",
       "  0.65431523,\n",
       "  0),\n",
       " ('everything happens for a reason', 0.6543567, 1),\n",
       " ('it looks it looks like someone put underwear on their head', 0.65444565, 0)]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_prototype[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d00d3-52b8-422e-95ad-c5464bc568b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
