{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4c51718a-c044-43dc-87d9-df230a20d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "# see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "68278d05-da9d-4334-b937-73f69f1bb855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6543432497992315206\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 23551737856\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5205972013172701355\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 18:11:03.926497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 22460 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f6f2f26d-ef5f-4f48-9104-9297666266d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "#import neccesary packages\n",
    "#import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
    "from datetime import datetime\n",
    "from scipy.spatial import distance_matrix\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "302ef895-0af6-48aa-905b-8bb2c69d7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4e45529e-47d7-4a0f-8b7e-162d677eb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a1126aa1-a44b-4991-b23d-d9e644d41d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, Model, regularizers\n",
    "\n",
    "def make_variables(tf_name, k1, k2, initializer):\n",
    "     \n",
    "    return tf.Variable(initializer(shape=[k1, k2], dtype=tf.float32), trainable=True, name=tf_name)\n",
    "\n",
    "#prototype layer\n",
    "class prototypeLayer(keras.layers.Layer):\n",
    "    def __init__(self, k_protos, vect_size, k_cents):\n",
    "        super(prototypeLayer, self).__init__(name='proto_layer')\n",
    "        self.n_protos = k_protos\n",
    "        self.vect_size = vect_size\n",
    "        self.prototypes = make_variables(\"prototypes\", k_protos, vect_size,\n",
    "                                         initializer=tf.constant_initializer(k_cents))\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        print(\"inputs \", inputs.shape)\n",
    "        tmp1 = tf.expand_dims(inputs, 2)\n",
    "        print(\"tmp1 \", tmp1.shape)\n",
    "        tmp1 = tf.broadcast_to(tmp1, [tf.shape(tmp1)[0], tf.shape(tmp1)[1], self.n_protos, self.vect_size])\n",
    "\n",
    "        print(\"tmp1 \", tmp1.shape)\n",
    "        print(\"prototypes \", self.prototypes)\n",
    "        tmp2 = tf.broadcast_to(self.prototypes,\n",
    "                               [tf.shape(tmp1)[0], tf.shape(tmp1)[1], self.n_protos, self.vect_size])\n",
    "\n",
    "        print(\"tmp2 \", tmp2.shape)\n",
    "        tmp3 = tmp1 - tmp2\n",
    "        tmp4 = tmp3 * tmp3\n",
    "        distances = tf.reduce_sum(tmp4, axis=3)\n",
    "        print(\"distances \", distances.shape)\n",
    "        \n",
    "        return distances, self.prototypes\n",
    "\n",
    "#distance layer: to convert the full distance matrix to sparse similarity matrix\n",
    "class distanceLayer(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(distanceLayer, self).__init__(name='distance_layer')\n",
    "        self.a = 0.1\n",
    "        self.beta = 1e6\n",
    "\n",
    "    def e_func(self, x, e=2.7182818284590452353602874713527):\n",
    "        return tf.math.pow(e, -(self.a * x))\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, full_distances):\n",
    "        min_dist_ind = tf.nn.softmax(-full_distances * self.beta)\n",
    "        e_dist = self.e_func(full_distances) + 1e-8\n",
    "        dist_hot_vect = min_dist_ind * e_dist\n",
    "        return dist_hot_vect\n",
    "    \n",
    "    \n",
    "class PrototypeCNN_Bert(Model):\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence_length, num_classes, tokenizer,bert_model, embedding_size, filter_sizes, num_filters, l2_reg_lambda, dropout_keep_prob, k_protos, vect_size):\n",
    "\n",
    "        \n",
    "        super(PrototypeCNN_Bert, self).__init__()\n",
    "        self.k_protos = k_protos\n",
    "        self.vect_size = vect_size\n",
    "        self.full_distences = None\n",
    "        self.full_onehot_distances = None\n",
    "        self.embedding = bert_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_l =sequence_length\n",
    "        \n",
    "        RNN_CELL_SIZE = 128\n",
    "        self.convs = []\n",
    "        \n",
    "        for filter_size in filter_sizes:\n",
    "            conv_block = tf.keras.Sequential([\n",
    "                layers.Conv2D(num_filters, (filter_size, embedding_size), \n",
    "                              padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(sequence_length - filter_size + 1, 1), \n",
    "                                    strides=(1,1), padding='valid')])\n",
    "            self.convs.append(conv_block)\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.distance_layer = distanceLayer()\n",
    "        self.LSTM = LSTM(RNN_CELL_SIZE, return_sequences=True, return_state=True)\n",
    "        self.dropout = layers.Dropout(dropout_keep_prob)  # keep_prob will be supplied by call argument\n",
    "        self.fc = layers.Dense(num_classes, \n",
    "                               kernel_regularizer=regularizers.l2(l2_reg_lambda), \n",
    "                               activation='softmax')\n",
    "\n",
    "    def init_prototypelayer(self, k_cents):\n",
    "        self.proto_layer = prototypeLayer(self.k_protos, self.vect_size, k_cents)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "         \n",
    "        # Embedding layer\n",
    "       \n",
    "        x = self.tokenizer(x, padding = \"max_length\", max_length=self.max_l, return_tensors =\"tf\",truncation = True )\n",
    "        outputs = self.embedding(input_ids = x[\"input_ids\"], attention_mask = x[\"attention_mask\"], output_hidden_states =True)\n",
    "        x = list(outputs.hidden_states)[-1]\n",
    "        x = tf.expand_dims(x, -1)\n",
    "\n",
    "        print(\"embedding \", x.shape)\n",
    "        \n",
    "        \n",
    "        # batch * 768\n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "            pooled_outputs.append(c)\n",
    "            print(c.shape)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        x = tf.concat(pooled_outputs, axis=-1)\n",
    "        print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "    \n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        \n",
    "        full_distances, protos = self.proto_layer(x)\n",
    "         \n",
    "        dist_hot_vect = self.distance_layer(full_distances)\n",
    "        \n",
    "        # 1*batch_size*10\n",
    "        \n",
    "        \n",
    "#         lstmop, forward_h, forward_c = self.LSTM(tf.squeeze(dist_hot_vect))\n",
    "#         z1 = self.fc(lstmop[:, -1, :])\n",
    "#         z = tf.squeeze(z1, axis=0)\n",
    "        \n",
    "        x = self.dropout(dist_hot_vect)\n",
    "        x = self.fc(x)\n",
    "        x = tf.squeeze(x, axis=0)\n",
    "        \n",
    "\n",
    "\n",
    "        #return x, self.fc.weights[0], self.fc.weights[1]\n",
    "\n",
    "       \n",
    "        \n",
    "        return x, full_distances, protos\n",
    "    \n",
    "    def embed(self,x):\n",
    "        # Embedding layer\n",
    "        \n",
    "        x = self.tokenizer(x, padding = \"max_length\", max_length=self.max_l, return_tensors =\"tf\",truncation = True  )\n",
    "        x = self.embedding(input_ids = x[\"input_ids\"], attention_mask = x[\"attention_mask\"])[0]\n",
    "        x = tf.expand_dims(x, -1) #2*200*768*\n",
    "        \n",
    "\n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            #print(x.shape)\n",
    "            \n",
    "            c = conv(x)\n",
    "            \n",
    "            pooled_outputs.append(c)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        x = tf.concat(pooled_outputs, axis=-1)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def full_distance(self, x):\n",
    "        \n",
    "        x = tokenizer(x, padding = \"max_length\", max_length=200, return_tensors =\"tf\"  )\n",
    "        x = self.embedding(x)\n",
    "        x = tf.expand_dims(x, -1) #2*200*768*1\n",
    "  \n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "            pooled_outputs.append(c)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        x = tf.concat(pooled_outputs, axis=-1)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        full_distances, protos = self.proto_layer(x)\n",
    "        \n",
    "        return full_distances\n",
    "    \n",
    "    def one_hot_distance(self, x):\n",
    "        \n",
    "         # Embedding layer\n",
    "        x = self.embedding(x)\n",
    "        x = tf.expand_dims(x, -1)\n",
    "  \n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "            pooled_outputs.append(c)\n",
    "        return pooled_outputs\n",
    "\n",
    "        # # Combine all the pooled features\n",
    "        # x = tf.concat(pooled_outputs, axis=-1)\n",
    "        # x = self.flatten(x)\n",
    "        \n",
    "        # x = tf.expand_dims(x, axis=0)\n",
    "        # full_distances, protos = self.proto_layer(x)\n",
    "       \n",
    "        # dist_hot_vect = self.distance_layer(full_distances)\n",
    "        \n",
    "        # return dist_hot_vect\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4975a7f8-e6a8-4438-85bf-a2141c34a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method simple project prototypes to the closest sentences in\n",
    "#sample_sent_vects\n",
    "def projection(sample_sentences,sample_sent_vects,data_size=10000):\n",
    "    prototypes = ProtoCNN.proto_layer.prototypes\n",
    "    d_pos = {}\n",
    "    #for each prototype\n",
    "    for p_count, p in enumerate(prototypes):\n",
    "        print('[db] p_count = ', p_count)\n",
    "        s_count = 0\n",
    "        d_pos[p_count] = {}\n",
    "        #find its distances to all sample sentences\n",
    "        for i, s in enumerate(sample_sent_vects[:data_size]):\n",
    "            if len(sample_sentences[i]) < 5 or len(sample_sentences[i]) > 100:\n",
    "                continue\n",
    "            d_pos[p_count][i] = np.linalg.norm(sample_sent_vects[i] - p)\n",
    "            s_count += 1\n",
    "    #sort those distances, then assign the closest ones to new prototypes\n",
    "    new_protos = []\n",
    "    for p_count, p in enumerate(prototypes):\n",
    "        sorted_d = sorted(d_pos[p_count].items(), key=operator.itemgetter(1))\n",
    "        new_protos.append(sample_sent_vects[sorted_d[0][0]])\n",
    "    #return these values\n",
    "\n",
    "    return new_protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ba83b7c3-e819-486f-b03c-db2cd0de28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the list of prototypes\n",
    "def showPrototypes(sample_sentences,sample_sent_vects, sample_y, k_protos=10,printOutput=False, k_closest_sents = 20):\n",
    "    \n",
    "    prototypes = ProtoCNN.proto_layer.prototypes.numpy()\n",
    "    #data_size = 10000\n",
    "    d_pos = {}\n",
    "    data_size = 150000\n",
    "    for p_count, p in enumerate(prototypes):\n",
    "       \n",
    "        s_count = 0\n",
    "        d_pos[p_count] = {}\n",
    "        for i, s in enumerate(sample_sent_vect[:data_size]):\n",
    "            #if len(sample_sentences[i]) < 20 or len(sample_sentences[i]) > 100:\n",
    "            if len(sample_sentences[i]) < 30 or sample_y[i][1]==0:\n",
    "                continue\n",
    "            d_pos[p_count][i] = np.linalg.norm(sample_sent_vect[i] - p)\n",
    "            s_count += 1\n",
    " \n",
    "\n",
    "    mappedPrototypes = {}    \n",
    "   \n",
    "    recorded_protos_score = {}\n",
    "    print(\"Prototypes: \")\n",
    "    for l in range(k_protos):\n",
    "        # print(\"prototype index = \", l)\n",
    "        recorded_protos_score[l] = {}\n",
    "        sorted_d = sorted(d_pos[l].items(), key=operator.itemgetter(1))\n",
    "        print(l)\n",
    "        mappedPrototypes[l]=[]\n",
    "        for k in range(k_closest_sents):\n",
    "            i = sorted_d[k][0]\n",
    "            score = sorted_d[k][1]\n",
    "            # print(\"[db] sorted_d \",sorted_d[0])\n",
    "            # print(\"[db] sample_sentences[sorted_d[0][0]]: \",sample_sentences[sorted_d[0][0]])\n",
    "            mappedPrototypes[l].append((sample_sentences[i].strip(), score, sample_y[i][1]))\n",
    "            if k<10:\n",
    "                print(sorted_d[k], sample_sentences[i],sample_y[i][1])\n",
    "        #print(mappedPrototypes[l])\n",
    "\n",
    "    \n",
    "    return mappedPrototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "211b7091-11a9-404b-980c-769756f085b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to generate the number of closest sentences to each prototype\n",
    "def protoFreq(self,sample_sent_vect):\n",
    "    d = {}\n",
    "    for sent in sample_sent_vect:\n",
    "        sent_dist = {}\n",
    "        for i, p in enumerate(self.prototypes):\n",
    "            sent_dist[i] = np.linalg.norm(sent - p)\n",
    "            if i not in d:\n",
    "                d[i] = 0\n",
    "        sorted_sent_d = sorted(sent_dist.items(), key=operator.itemgetter(1))\n",
    "        # print(sorted_sent_d)\n",
    "        picked_protos = sorted_sent_d[0][0]\n",
    "        d[picked_protos] += 1\n",
    "    print(\"Prototype freq = \", d)\n",
    "    x = sorted(d.items(), key=lambda item: item[1], reverse=True)\n",
    "    print(\"sorted :\",x)\n",
    "\n",
    "#re-train the model with new pruned prototype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b33f3373-3d81-4d34-a9d9-144a198ce0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruningTrain(self,new_k_protos,x_train,y_train,x_test,y_test):\n",
    "    #print(\"[db] self prototypes: \",self.prototypes)\n",
    "    k_cents = self.prototypes[:new_k_protos]\n",
    "    k_cents = [p.numpy() for p in k_cents]\n",
    "    #print(\"[db] k_cents = \",k_cents)\n",
    "    self.createModel(k_cents=k_cents,k_protos=new_k_protos)\n",
    "    self.train(x_train,y_train,x_test,y_test)\n",
    "\n",
    "# generate the sentence value for each prototype\n",
    "# and 10 closest sentences to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5f4d691e-f19f-42d9-b9f4-e1c4fb1367d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showTrajectory(self,input,sample_sentences,sample_vect):\n",
    "    if len(self.mappedPrototypes) == 0:\n",
    "        self.showPrototypes(sample_sentences,sample_vect,printOutput=False)\n",
    "    prototypes = [self.mappedPrototypes[k].strip() for k in self.mappedPrototypes]\n",
    "    vP, vS = self.embed(prototypes), self.embed(input)\n",
    "    dStoP = {}\n",
    "    for sCount, s in enumerate(vS):\n",
    "        dStoP[sCount] = {}\n",
    "        for i, p in enumerate(vP):\n",
    "            dStoP[sCount][i] = np.linalg.norm(vS[sCount] - p)\n",
    "\n",
    "    mappedProtos, mappedScore, mappedDist = [], [], []\n",
    "    for sCount, s in enumerate(vS):\n",
    "        sorted_d = sorted(dStoP[sCount].items(), key=operator.itemgetter(1))\n",
    "        mappedProtos.append(prototypes[sorted_d[0][0]])\n",
    "\n",
    "    #for small dataset, we use a pretrained sentiment model. We can use any\n",
    "    #model for sentiment scores\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    print(\"[db] mappedProtos \", mappedProtos)\n",
    "    scores = []\n",
    "    for s in mappedProtos:\n",
    "        # sentiment_dict = sid_obj.polarity_scores(s)\n",
    "        scores.append(0.5 + sid_obj.polarity_scores(s)['compound'] / 2)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "029d1de7-6903-43f0-a8a8-3af4cfe1b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sample_percentage = .1\n",
    "\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 768\n",
    "filter_sizes =\"3,4,5\"\n",
    "num_filters = 128\n",
    "dropout_keep_prob = 0.5\n",
    "l2_reg_lambda = 0.5\n",
    "max_l =100\n",
    "# Training parameters\n",
    "batch_size = 4096\n",
    "num_epochs = 100\n",
    "evaluate_every = 100\n",
    "checkpoint_everyt = 100\n",
    "num_checkpoints = 5\n",
    "\n",
    "# Misc Parameters\n",
    "allow_soft_placement = True\n",
    "log_device_placement = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215181e-3bb5-453f-b0ea-17c8fa8258fb",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0ffa0bc6-bc08-442d-b25a-6f5e7b777de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output directory:  /big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/runs/1702670078\n",
      "loading data...\n",
      "data loaded!\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(int(time.time()))\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "print(\"output directory: \", out_dir)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "# Data Preparation\n",
    "# ==================================================\n",
    "\n",
    "# Load data\n",
    "\n",
    "print(\"loading data...\")\n",
    "x = pickle.load(open(\"./mainbalancedpickle.p\",\"rb\"))\n",
    "revs, W, W2, word_idx_map, vocab, max_l = x[0], x[1], x[2], x[3], x[4], x[5]\n",
    "print(\"data loaded!\")# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "88b87d84-7c17-4fd4-ae30-670de1328ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219368"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "da0e7a5a-363d-4200-850b-09953bce776f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 1,\n",
       " 'id': 'c07fd66',\n",
       " 'text': 'religion must have the answer',\n",
       " 'author': 'Reedzit',\n",
       " 'topic': 'science',\n",
       " 'label': [0, 1],\n",
       " 'num_words': 5,\n",
       " 'split': 1}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dfc94ebc-87e0-4185-89ae-ad5c31fe749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = TFBertModel.from_pretrained(bert_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5e94a494-8b8e-4201-a15a-39f647276947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_l = 100\n",
    "\n",
    "x_text = []\n",
    "y = []\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "for i in range(len(revs)):\n",
    "    if revs[i]['split']==1:\n",
    "        x_text.append(revs[i]['text'])\n",
    "        y.append(revs[i]['label'])\n",
    "    else:\n",
    "        test_x.append(revs[i]['text'])\n",
    "        test_y.append(revs[i]['label'])  \n",
    "\n",
    "y = np.asarray(y)\n",
    "y_test = np.asarray(test_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b4069421-f5a3-4da5-8a16-afd516e9a6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['religion must have the answer',\n",
       " \"it 's obviously tracks from a giant water tractor , farming for giant arctic sea prawn !\",\n",
       " 'wow he smoked pot oh lord hes such a horrible person now',\n",
       " \"wow , his girlfriend is uhm ah fuck it , he 's an olympic champion , who am i to pass judgement\",\n",
       " 'i think the government should track every mormon in the country for subversive activity']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "758e4d4b-3732-4e02-9f12-112651b5ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Dev split: 139232/15470\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = np.asarray(x_text)[shuffle_indices]\n",
    "y_shuffled = np.asarray(y)[shuffle_indices]\n",
    "\n",
    "# Split train/test set\n",
    "# TODO: This is very crude, should use cross-validation\n",
    "\n",
    "dev_sample_index = -1 * int(dev_sample_percentage * float(len(y)))\n",
    "x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "x_dev = np.asarray(x_dev)\n",
    "y_train = np.asarray(y_train)\n",
    "y_dev = np.asarray(y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5edbc0de-a10a-46c9-957b-ca9b1b46a3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"why ca n't i have friends like this\"], dtype='<U1720')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "472eee37-fad7-4388-9bed-3f28d6819c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"why ca n't i have friends like this\", array([1, 0]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0],y_train [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "739d7e5f-11fb-4076-b812-7ccfebabbee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in bert_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6ead1e16-2848-4e62-a80a-a70bd66d9190",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idx_map[\"@\"] = 0\n",
    "rev_dict = {v: k for k, v in word_idx_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6f88e3e0-469d-452c-8bf6-a9ea4253e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_protos, vect_size = 10, 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3d705569-a75c-46e2-bab8-19acde24af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProtoCNN = PrototypeCNN_Bert(sequence_length=max_l,\n",
    "    num_classes=len(y_train[0]),\n",
    "    tokenizer = tokenizer,\n",
    "    bert_model = bert_model,\n",
    "    embedding_size=embedding_dim,\n",
    "    filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
    "    num_filters=num_filters,\n",
    "    l2_reg_lambda=l2_reg_lambda,\n",
    "    dropout_keep_prob = dropout_keep_prob,\n",
    "    k_protos = k_protos,\n",
    "    vect_size = vect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8e72ba2a-98dc-4563-b091-e13f41ee69e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n"
     ]
    }
   ],
   "source": [
    "data = x_text[:2]\n",
    "y = ProtoCNN.embed(data)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5b1f4a6e-0cee-4062-a201-a80395510832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c32dd5ef-8d40-40a6-b91e-e8445e335b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(x_text)\n",
    "sample_sentences = x_text[:15000]\n",
    "sample_sentences_vects = []\n",
    "for i in range(300):\n",
    "    batch = sample_sentences[i*50:(i+1)*50]\n",
    "    vect = ProtoCNN.embed(batch)\n",
    "    sample_sentences_vects.append(vect.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "57fd1cbf-2bd3-402c-b7f9-5e9bd75ffa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences_vect = np.concatenate(sample_sentences_vects, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a384d60-db13-446d-a45d-01e114befb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 384)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentences_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f869b9e4-76ab-4349-a456-797eff1b3dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 384)\n"
     ]
    }
   ],
   "source": [
    "k_protos = 10\n",
    "kmedoids = KMedoids(n_clusters=k_protos, random_state=0).fit(sample_sentences_vect)\n",
    "k_cents = kmedoids.cluster_centers_\n",
    "print(k_cents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2b5b266d-7de9-41b1-8147-c05ff7e2e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProtoCNN.init_prototypelayer(k_cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1f3aabec-a03f-4475-a5b3-1eaf8afca4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding  (2, 100, 768, 1)\n",
      "(2, 1, 1, 128)\n",
      "(2, 1, 1, 128)\n",
      "(2, 1, 1, 128)\n",
      "(2, 1, 1, 384)\n",
      "(2, 384)\n"
     ]
    }
   ],
   "source": [
    "y, dist, protos = ProtoCNN(x_text[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7a57f0bb-34d5-4b07-a3ab-2bc7e7c8b946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2) (1, 2, 10) (10, 384)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape, dist.shape, protos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "79f09411-2daf-4fca-a728-c1b1ff80aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_variables(tf_name, k1, k2, initializer):\n",
    "     \n",
    "    return tf.Variable(initializer(shape=[k1, k2], dtype=tf.float32), trainable=True, name=tf_name)\n",
    "\n",
    "\n",
    "def pw_distance(A):\n",
    "    r = tf.reduce_sum(A * A, 1)\n",
    "    r = tf.reshape(r, [-1, 1])\n",
    "    D = r - 2 * tf.matmul(A, tf.transpose(A)) + tf.transpose(r)\n",
    "    return D\n",
    "\n",
    "def tight_pos_sigmoid_offset(x, offset, e=2.7182818284590452353602874713527):\n",
    "    return 1 / (1 + tf.math.pow(e, (1 * (offset * x - 0.5))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "050205c0-ac14-4cea-9c71-97752ae14315",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost2 = tf.reduce_sum(tf.reduce_min(dist, axis=1))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ced32398-84f0-4537-bf92-614fe43af2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "d= pw_distance(protos)\n",
    "diag_ones = tf.convert_to_tensor(np.eye(k_protos, dtype=float))\n",
    "diag_ones = tf.dtypes.cast(diag_ones, tf.float32)\n",
    "d1 = d + diag_ones * tf.reduce_max(d)\n",
    "d2 = tf.reduce_min(d1, axis=1)\n",
    "min_d2_dist = tf.reduce_min(d2)\n",
    "# the third loss term\n",
    "cost3 = tight_pos_sigmoid_offset(min_d2_dist, 1) + 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e3746811-78d3-4800-a4f1-c34021469665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(dist, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "39adcc2f-2427-4675-82d5-7e24253d07ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "badd9ae6-4a7d-4bd4-b6f1-5de1071a95fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.47345367, 0.5265463 ],\n",
       "       [0.76886785, 0.23113218]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN(x_text[:2], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd8dee1c-a7ee-42ba-a3ff-151ca072b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"prototype_cnn__bert\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tf_bert_model_1 (TFBertMode  multiple                 109482240 \n",
      " l)                                                              \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 1, 1, 128)         295040    \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1, 1, 128)         393344    \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 1, 1, 128)         491648    \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " distance_layer (distanceLay  multiple                 0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 multiple                  0 (unused)\n",
      "                                                                 \n",
      " dropout_74 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  22        \n",
      "                                                                 \n",
      " proto_layer (prototypeLayer  multiple                 3840      \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,666,134\n",
      "Trainable params: 1,183,894\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ProtoCNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af5d1a-e4f0-4f69-aa51-999d966d9be4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01adf81b-f01f-448f-a143-ad2712b63e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "accumulated_steps = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eae7ff8e-640a-4694-9e0e-c55f12e24ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/runs/1698891988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "timestamp = str(int(time.time()))\n",
    "# Output directory for models and summaries\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "# Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a87776e-eac1-4230-9722-6f8449b2c747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139232,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1b4ff0c-d662-4f0f-8017-03f108fb5e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139232, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1250b421-7872-434f-a700-645b9ef5a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProtoCNN = tf.keras.models.load_model(os.path.join(out_dir,\"my_weights-finetune.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5c08b70-3f72-48f2-bf14-5fd5ed016a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use Adam optimizer with default learning rate 0.0001.\n",
    "#Change this value based on your preference\n",
    "out_dir = \"/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/runs/\"+timestamp\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=.0001)\n",
    "#ProtoCNN.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "criterion = keras.losses.CategoricalCrossentropy(from_logits=False, reduction=keras.losses.Reduction.SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8f32b12-fc25-40bd-9b30-d3da29c70aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_object = pickle.load(open(os.path.join(out_dir,\"optimizer.pt\"), 'rb'))\n",
    "#ProtoCNN.optimizer.set_weights(loaded_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04fc40cd-be72-4c5e-85a9-1db65fe35bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# i = 0\n",
    "\n",
    "# maxEvalRes = 0\n",
    "\n",
    "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath = checkpoint_dir,  # Specify the path to save the checkpoints\n",
    "#     save_weights_only=True,  # Save only the model weights\n",
    "#     monitor='val_loss',  # Monitor the validation loss for saving the best weights\n",
    "#     save_best_only=True,  # Save only the best weights based on the monitored metric\n",
    "#     verbose=1  # Print a message when a checkpoint is saved\n",
    "# )    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07afcb7f-53c7-4a79-82bb-f7c5472f3180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data, labels, batch_size=200, shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(data))\n",
    "\n",
    "       \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Returns the number of batches\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # Shuffles the indexes if required\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        \n",
    "        # Yield batches\n",
    "        for i, start_idx in enumerate(range(0, len(self.data), self.batch_size)):\n",
    "            end_idx = min(start_idx + self.batch_size, len(self.data))\n",
    "            batch_indexes = self.indexes[start_idx:end_idx]\n",
    "            yield i, self.data[batch_indexes].tolist(), self.labels[batch_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3a202a2-9668-455a-957d-0a73decf6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "accumulation_steps = 70\n",
    "\n",
    "train_accuracy_metric = tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
    "valid_accuracy_metric = tf.keras.metrics.CategoricalAccuracy(name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0b94217d-a1f8-4374-b699-31db563897ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(x_train, y_train,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c83b1e38-2c3e-4848-a7e7-9d71856c31d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2176"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c913ee9-f45e-4ab5-babc-20b10a18612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfc4680b-bb09-4cf7-b7e8-57ccc5ac04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c882b-1c4a-4680-b2f0-57824b56d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    accumulated_gradients = [tf.zeros_like(var) for var in ProtoCNN.trainable_variables]\n",
    "    accumulated_loss = 0\n",
    "    train_accuracy_metric.reset_state()\n",
    "    for i, inputs, labels in train_loader: \n",
    "       \n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            predictions = ProtoCNN(inputs, training=True) \n",
    "            loss = criterion(labels, predictions)\n",
    "            gradients = tape.gradient(loss, ProtoCNN.trainable_weights)\n",
    "\n",
    "            break;\n",
    "\n",
    "            # Accumulate gradients\n",
    "            accumulated_gradients = [acc_grad + grad for acc_grad, grad in zip(accumulated_gradients, gradients)]\n",
    "            accumulated_loss +=loss\n",
    "            train_accuracy_metric.update_state(labels, predictions)\n",
    "            # Apply gradients every accumulation_steps or at the last batch\n",
    "        if (i + 1) % accumulation_steps == 0 or i == len(train_loader) - 1:\n",
    "            accumulated_gradients = [grad / accumulation_steps for grad in accumulated_gradients]\n",
    "            opt.apply_gradients(zip(accumulated_gradients, ProtoCNN.trainable_weights))\n",
    "            accumulated_gradients = [tf.zeros_like(var) for var in ProtoCNN.trainable_variables]\n",
    "\n",
    "            print(f\"Epoch: {epoch}, Loss: {accumulated_loss.numpy()/(batch_size*accumulation_steps)} {batch_size*(i+1)}/139232 accuracy:{train_accuracy_metric.result().numpy()}\")\n",
    "            accumulated_loss = 0\n",
    "        epoch_loss += loss\n",
    "\n",
    "\n",
    "    valid_loss = 0\n",
    "    y_true = None\n",
    "    y_pred = None\n",
    "    valid_accuracy_metric.reset_state()\n",
    "    for i, inputs, labels in dev_loader: \n",
    "       \n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            predictions = ProtoCNN(inputs, training=True)\n",
    "            loss = criterion(labels, predictions)\n",
    "            #labels = tf.reshape(labels,[1,2])\n",
    "            accumulated_loss +=loss\n",
    "            valid_loss += loss\n",
    "            valid_accuracy_metric.update_state(labels, predictions)\n",
    "            \n",
    "        if (i + 1) % accumulation_steps == 0 or i == len(train_loader) - 1:\n",
    "           \n",
    "            print(f\"Epoch: {epoch}, Loss: {accumulated_loss.numpy()/(batch_size*accumulation_steps)} {batch_size*(i+1)}/139232 accuracy:{valid_accuracy_metric.result().numpy()}\")\n",
    "            accumulated_loss = 0\n",
    "        epoch_loss += loss\n",
    "                  \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9894f-a1e7-479e-af11-c52af9d6bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProtoCNN.fit([\"I am a boy\",\"She is a girl\"], y_train, batch_size = 4096, epochs=2000, verbose=1, validation_data= (x_dev, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95333a4-c450-42cd-88eb-81baab02da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(opt.get_weights(), open(os.path.join(out_dir, 'optimizer.pt'), 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6124975-2783-46e4-b779-61a2c730ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProtoCNN.save_weights(os.path.join(out_dir,\"my_weights-finetune.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "16cf1db3-529c-4440-b102-5dce8a653f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/runs/1686708033/my_weights-finetune.pt/assets\n"
     ]
    }
   ],
   "source": [
    "ProtoCNN.save(os.path.join(out_dir,\"my_weights-finetune.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8547cf5-f79f-4d59-b5ab-7c18e327cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProtoCNN.load_weights(os.path.join(out_dir,\"my_weights-finetune.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b079b984-5523-470d-af23-c4c72635483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProtoCNN.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cc460490-19a5-4176-953c-5e03734561fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[0.3167334 , 0.68326664],\n",
       "       [0.5730032 , 0.4269968 ],\n",
       "       [0.31576294, 0.68423706],\n",
       "       [0.51213247, 0.4878675 ],\n",
       "       [0.588644  , 0.411356  ]], dtype=float32)>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN(x_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd72ab-aade-4fa2-b265-963780dc41d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33ae79e5-7953-44cf-8230-2ba851181529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev_step(x_batch, y_batch):\n",
    "    \"\"\"\n",
    "    Evaluates model on a dev set\n",
    "    \"\"\"\n",
    "    logits= ProtoCNN.predict(x_batch)\n",
    "\n",
    "   \n",
    "\n",
    "    prediction_losses = tf.keras.losses.categorical_crossentropy(y_batch, tf.nn.softmax(logits))\n",
    "\n",
    "    loss =  prediction_losses \n",
    "\n",
    "\n",
    "    predictions = tf.argmax(logits, 1)\n",
    "    correct_predictions = tf.equal(predictions, tf.argmax(y_batch, 1))\n",
    "    \n",
    "    return loss, correct_predictions\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a35f2311-b7c0-461d-a9b4-400ba50bdbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bc06996-53cc-45b7-81b3-539e44f60b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64335f9-7f20-49db-8ef1-2ead45baef12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "264d0458-54f9-4306-a779-86ca74a5aea5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create testing dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((\u001b[43mx_test\u001b[49m, y_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create testing dataset\n",
    "test_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "91796a89-33ae-482b-88c0-abc774fc2039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f4b40613340>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN.load_weights(\"runs/PROTOCNN/epoch_788/best_classifier.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4064bbaf-4206-47ee-8e72-c338c0d5a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(np.array(test_x),np.array(test_y),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c2a4a94-85ca-44e7-8939-d2c417e5cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_metric = tf.keras.metrics.CategoricalAccuracy(name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "52e1dc16-f313-4642-a343-9ff099c6c9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1011"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b1e0ed73-6da8-4081-8e65-2d8edaaa33c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1dd96a2e-f28f-49c1-8dc7-796e0d64737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65870535\n",
      "0.65982145\n",
      "0.66220236\n",
      "0.6640067\n",
      "0.6635268\n",
      "0.66343004\n",
      "0.6619898\n",
      "0.66330916\n",
      "0.6624504\n",
      "0.6618973\n",
      "0.6627638\n",
      "0.6635231\n",
      "0.6644918\n",
      "0.6643335\n",
      "0.66472334\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "test_accuracy_metric.reset_state()\n",
    "for i, inputs, labels in test_loader: \n",
    "  \n",
    "    \n",
    "    predictions = ProtoCNN(inputs, training=False)\n",
    " \n",
    "    test_accuracy_metric.update_state(labels, predictions)\n",
    "        \n",
    "    if (i + 1) % accumulation_steps == 0 or i == len(test_loader) - 1:\n",
    "       \n",
    "      print(test_accuracy_metric.result().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7ce1b9a7-8dbb-4e3c-acd7-066d50d0b81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63058037\n",
      "0.634375\n",
      "0.6334077\n",
      "0.63097095\n",
      "0.62995535\n",
      "0.6307664\n",
      "0.63115436\n",
      "0.6301897\n",
      "0.63149804\n",
      "0.6321875\n",
      "0.6326299\n",
      "0.63238466\n",
      "0.63174796\n",
      "0.6328922\n",
      "0.63286734\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "test_accuracy_metric.reset_state()\n",
    "for i, inputs, labels in test_loader: \n",
    "  \n",
    "    \n",
    "    predictions = ProtoCNN(inputs, training=False)\n",
    " \n",
    "    test_accuracy_metric.update_state(labels, predictions)\n",
    "        \n",
    "    if (i + 1) % accumulation_steps == 0 or i == len(test_loader) - 1:\n",
    "       \n",
    "      print(test_accuracy_metric.result().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69dad939-be0a-408b-925b-e0c5612dee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Bert(Model):\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence_length, num_classes, tokenizer,bert_model, embedding_size, filter_sizes, num_filters, l2_reg_lambda, dropout_keep_prob, k_protos, vect_size):\n",
    "\n",
    "\n",
    "        super(CNN_Bert, self).__init__()\n",
    "        self.k_protos = k_protos\n",
    "        self.vect_size = vect_size\n",
    "        self.full_distences = None\n",
    "        self.full_onehot_distances = None\n",
    "        self.embedding = bert_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_l =sequence_length\n",
    "\n",
    "        RNN_CELL_SIZE = 128\n",
    "        self.convs = []\n",
    "\n",
    "        for filter_size in filter_sizes:\n",
    "            conv_block = tf.keras.Sequential([\n",
    "                layers.Conv2D(num_filters, (filter_size, embedding_size),\n",
    "                              padding='valid', activation='relu'),\n",
    "                layers.MaxPooling2D(pool_size=(sequence_length - filter_size + 1, 1),\n",
    "                                    strides=(1,1), padding='valid')])\n",
    "            self.convs.append(conv_block)\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.distance_layer = distanceLayer()\n",
    "        self.LSTM = LSTM(RNN_CELL_SIZE, return_sequences=True, return_state=True)\n",
    "        self.dropout = layers.Dropout(dropout_keep_prob)  # keep_prob will be supplied by call argument\n",
    "        self.fc = layers.Dense(num_classes,\n",
    "                               kernel_regularizer=regularizers.l2(l2_reg_lambda),\n",
    "                               activation='softmax')\n",
    "\n",
    "    def init_prototypelayer(self, k_cents):\n",
    "        self.proto_layer = prototypeLayer(self.k_protos, self.vect_size, k_cents)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "\n",
    "        # Embedding layer\n",
    "        x = self.tokenizer(x, padding = \"max_length\", max_length=self.max_l, return_tensors =\"tf\",truncation = True )\n",
    "        x = self.embedding(input_ids = x[\"input_ids\"], attention_mask = x[\"attention_mask\"], output_hidden_states =True)[0]\n",
    "        x = tf.expand_dims(x, -1)\n",
    "\n",
    "\n",
    "        # batch * 768\n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "            pooled_outputs.append(c)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "\n",
    "\n",
    "        x = tf.concat(pooled_outputs, axis=3)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x, training=True)\n",
    "        x = self.fc(x)\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "    def embed(self,x):\n",
    "        # Embedding layer\n",
    "\n",
    "        x = self.tokenizer(x, padding = \"max_length\", max_length=self.max_l, return_tensors =\"tf\",truncation = True  )\n",
    "        x = self.embedding(input_ids = x[\"input_ids\"], attention_mask = x[\"attention_mask\"])[0]\n",
    "        x = tf.expand_dims(x, -1) #2*200*768*\n",
    "\n",
    "\n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "\n",
    "            pooled_outputs.append(c)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        x = tf.concat(pooled_outputs, axis=-1)\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def full_distance(self, x):\n",
    "\n",
    "        x = tokenizer(x, padding = \"max_length\", max_length=200, return_tensors =\"tf\"  )\n",
    "        x = self.embedding(x)\n",
    "        x = tf.expand_dims(x, -1) #2*200*768*1\n",
    "\n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "            pooled_outputs.append(c)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        x = tf.concat(pooled_outputs, axis=-1)\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        full_distances, protos = self.proto_layer(x)\n",
    "\n",
    "        return full_distances\n",
    "\n",
    "    def one_hot_distance(self, x):\n",
    "\n",
    "         # Embedding layer\n",
    "        x = self.embedding(x)\n",
    "        x = tf.expand_dims(x, -1)\n",
    "\n",
    "        pooled_outputs = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "            pooled_outputs.append(c)\n",
    "        return pooled_outputs\n",
    "\n",
    "        # # Combine all the pooled features\n",
    "        # x = tf.concat(pooled_outputs, axis=-1)\n",
    "        # x = self.flatten(x)\n",
    "\n",
    "        # x = tf.expand_dims(x, axis=0)\n",
    "        # full_distances, protos = self.proto_layer(x)\n",
    "\n",
    "        # dist_hot_vect = self.distance_layer(full_distances)\n",
    "\n",
    "        # return dist_hot_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3eda547-975b-44e3-9c69-c0cd4deab400",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = CNN_Bert(sequence_length=max_l,\n",
    "    num_classes=len(y_train[0]),\n",
    "    tokenizer = tokenizer,\n",
    "    bert_model = bert_model,\n",
    "    embedding_size=embedding_dim,\n",
    "    filter_sizes=list(map(int, filter_sizes.split(\",\"))),\n",
    "    num_filters=num_filters,\n",
    "    l2_reg_lambda=l2_reg_lambda,\n",
    "    dropout_keep_prob = dropout_keep_prob,\n",
    "    k_protos = k_protos,\n",
    "    vect_size = vect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2177e8f9-432b-4e82-88e0-a41209cc9ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f4b3b082f20>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN.load_weights(\"runs/10_31_baseline_bert/best_classifier.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f39ccabc-e47d-4de0-9185-c1a123e1a7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68794644\n",
      "0.68415177\n",
      "0.68541664\n",
      "0.6876674\n",
      "0.68857145\n",
      "0.6886533\n",
      "0.6878508\n",
      "0.6873884\n",
      "0.6875\n",
      "0.6887054\n",
      "0.6885958\n",
      "0.68816966\n",
      "0.6878434\n",
      "0.688345\n",
      "0.68881637\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "test_accuracy_metric.reset_state()\n",
    "for i, inputs, labels in test_loader: \n",
    "  \n",
    "    \n",
    "    predictions = CNN(inputs, training=False)\n",
    " \n",
    "    test_accuracy_metric.update_state(labels, predictions)\n",
    "        \n",
    "    if (i + 1) % accumulation_steps == 0 or i == len(test_loader) - 1:\n",
    "       \n",
    "      print(test_accuracy_metric.result().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2e3111ca-0f02-4e8d-8528-5d2fc1d55b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'losses.pkl'\n",
    "\n",
    "# Open the file in binary read mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Load the contents from the file and assign it to a variable\n",
    "    # This will deserialize the object contained in the file\n",
    "    your_data = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6f848823-954d-457f-bfd4-3a693c29a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, dev_loss, train_acc, dev_acc,test_acc  = your_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4c940dc6-5df3-4006-9185-dadf492a9fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67638904"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "98da01c4-7fc3-4d2e-a5ec-2ffd6441fa2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78642535"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9c67176a-6025-4717-b03d-7faa42b6d583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.7893638),\n",
       " (2, 0.79043084),\n",
       " (3, 0.7911731),\n",
       " (4, 0.7915133),\n",
       " (5, 0.79154426),\n",
       " (6, 0.79152876),\n",
       " (7, 0.79152876),\n",
       " (8, 0.79152876),\n",
       " (9, 0.79152876),\n",
       " (10, 0.79152876),\n",
       " (11, 0.79152876),\n",
       " (12, 0.79152876),\n",
       " (13, 0.79152876),\n",
       " (14, 0.79152876),\n",
       " (15, 0.79152876),\n",
       " (16, 0.79152876),\n",
       " (17, 0.79152876),\n",
       " (18, 0.79152876),\n",
       " (19, 0.79152876),\n",
       " (20, 0.79152876),\n",
       " (21, 0.79152876),\n",
       " (22, 0.79152876),\n",
       " (24, 0.79152876),\n",
       " (25, 0.79152876),\n",
       " (26, 0.79152876),\n",
       " (27, 0.7915133),\n",
       " (28, 0.7936783),\n",
       " (29, 0.7985804),\n",
       " (30, 0.80342066),\n",
       " (31, 0.805632),\n",
       " (32, 0.8077815),\n",
       " (33, 0.80897224)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eb6eba26-2bab-40e5-a338-b9c44e443479",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m your_data[\u001b[38;5;241m1\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[135], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m your_data[\u001b[38;5;241m1\u001b[39m]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "result = [x.numpy() for x in your_data[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "24c8f0d3-9dc4-4883-941a-625ca8288bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9611.796"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "50ff695c-5441-4c8e-ad7e-3facfc601a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.asarray(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "52a8c18e-ffec-4b63-b2ca-e9c0036484ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1407"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6d942-f46a-46a4-bc5f-f7ef384c4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_batch, y_batch in tqdm(test_loader.batch(4096)):    \n",
    "    test_loss, correct_predictions = dev_step(x_batch, y_batch)  \n",
    "    if correct_predictions_test is None:\n",
    "        correct_predictions_test = correct_predictions\n",
    "    else:\n",
    "        correct_predictions_test = tf.concat((correct_predictions_test, correct_predictions), axis=0)\n",
    "\n",
    "test_accuracy = tf.reduce_mean(tf.cast(correct_predictions_test, tf.float32))\n",
    "print(\"test accuracy {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "032f5a2a-4a7a-497d-adda-22acaa8f930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarc_comments = [ rev['text'] for rev in revs if rev['label'][1]==1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7b9c07d8-763f-4f14-a7a0-f60348c682e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['looks like its time to convince the chineese that siberian tiger bones improve boners',\n",
       " 'shutting down the government and the military at the same time !',\n",
       " \"yay , now i do n't have to pay taxes !\",\n",
       " 'a modern day shakespeare',\n",
       " 'god im done with this sub fuckin circle jerk shit',\n",
       " 'looks like a fun format',\n",
       " 'this film is a serious game changer !',\n",
       " \"well , if you do n't have anything to hide then there is nothing to fear\",\n",
       " 'admissions are great , i get to skip the whole investigation and just ban you !',\n",
       " 'as we all know , apple are the only ones who can innovate',\n",
       " 'hahahaha handicapped people omg lol',\n",
       " \"it 's worth every penny to bring jeeezus back\",\n",
       " 'i hear mien kamph is a very popular book',\n",
       " \"well i'm glad to know that the government still considers shutting down voluntary marketplaces an essential service during the shutdown\",\n",
       " 'trade geno and sid for miller sounds like a great trade',\n",
       " 'wow , never saw that coming',\n",
       " \"if english was good enough for jesus , then it 's good enough for me !\",\n",
       " \"i thought we had something going , what like how ted bundy and his 'girlfriends' had something \\\\?\",\n",
       " 'newest book must have been too close to the truth , amirite \\\\?',\n",
       " 'dude , the hotkey for recall is b , just press it and wait for the whole channel',\n",
       " 'please \\\\( think of the fucking karma',\n",
       " \"i'm sure a business that spends that much time on the fucking counter will be successful beyond their wildest dreams\",\n",
       " 'aww , my heart goes out to those poor nsa workers',\n",
       " \"they 're probably safer there than in america , what with all the discrimination christians face here\",\n",
       " 'let me hop right on that',\n",
       " 'too bad no vendors sell it',\n",
       " \"no that 's funny !\",\n",
       " \"it 's her genes man do n't be oppressive\",\n",
       " \"i ca n't tell the difference between x amp y and red amp blue , they are like the same game !\",\n",
       " \"no but without the government there would n't be any paths to walk on in the woods , there would be no roads , no gift shops , no maps but now that they exist we should probably just get rid of the government\",\n",
       " \"this is a totally original joke that i 've never heard on the internet before\",\n",
       " 'i dunno the rite of spring makes for great breakfast music',\n",
       " 'this is so deep',\n",
       " 'if he continues this rate of one player of the month every month , he will have 40 player of the month awards ten seasons from now',\n",
       " \"op does n't like the fact that smart people have iphones\",\n",
       " 'yeah , because those late third trimester abortions are all the rage these days',\n",
       " 'yeah just like gold farming',\n",
       " \"but but , i thought if the library at alexandria had n't been burned by dark ages christians we would be exploring galaxies !\",\n",
       " 'why must the straight white man always suffer \\\\?',\n",
       " \"i have you know i'm a red belt in boxing and a green belt in no gi bjj\",\n",
       " 'i wish i was literally doing nothing with my life',\n",
       " 'has worked very well with other games , like dota 2 and league of legends',\n",
       " 'sick whip !',\n",
       " 'yeah , fuck the people and the country , this is a matter of pride',\n",
       " \"i know that you 've just been pining away for ten years wishing he 'd ask you to procreate\",\n",
       " \"sounds like something big corporations do it 's not legal \\\\?\",\n",
       " 'yes , you are the only one',\n",
       " 'great parenting there',\n",
       " 'nothing says romantic love like bend over and let me give it to you',\n",
       " 'cool maybe people will stop hating fags now',\n",
       " 'rookie mistake , always lead with the 9 dick',\n",
       " 'thin privilege is getting a real mri in a hospital',\n",
       " 'the picture is nsfw',\n",
       " 'how dare she comment on something',\n",
       " 'link to nexus mod page \\\\?',\n",
       " \"they 're going to announce that the moon landing was faked\",\n",
       " 'yes , i can definitely see how \\\\( slowly \\\\) self assembling legos can more efficiently handle many tasks that a sturdy robotic arm cannot',\n",
       " \"mourinho really destroyed mata 's career huh \\\\?\",\n",
       " \"ca n't imagine why there are downvotes on this\",\n",
       " \"i do n't know guys , that apology seems really sincere\",\n",
       " 'oh , well , if she was insane , then she deserved to be shot , in spite of being unarmed',\n",
       " 'better to have no parents than gay parents',\n",
       " 'i thought fosters was the pride of australia \\\\?',\n",
       " 'they only have wars to thin them out a bit , its probably the reason for the rise of civilisation',\n",
       " 'but the diamond lane has been such a success',\n",
       " \"because a man ca n't be a mentor for a younger man boy without having a sexual driven intention\",\n",
       " \"you forgot the pint of ben and jerry 's , dvd of the notebook , and a long pink glittery satin nightie\",\n",
       " 'hey those wars paid my salary and got me a bitching computer , bro',\n",
       " 'i always like to start with a resounding fuck the po lice it filters out my audience , engages those who remain and really makes a statement about my personal beliefs',\n",
       " \"yah , that 's what they are doing\",\n",
       " \"but that 's because they did n't download the hd\",\n",
       " \"well that 's a fantastic reason to deny yourself a great experience\",\n",
       " 'but guys r truth sucks',\n",
       " 'until a republican does it',\n",
       " \"yeah because theres no possible reason ever to do something illegal that is n't a stupid choice\",\n",
       " 'dupes dupes enjoy b amp calling majicou right now',\n",
       " \"where 's rommel \\\\?\",\n",
       " 'yes , this is a big problem , better push through common core !',\n",
       " 'you laugh now , but proper use of hyphens is of critical importance in our field',\n",
       " 'well bust out the big box of crayons and color me shocked',\n",
       " 'what were you thinking , leading him on like that \\\\?',\n",
       " \"yeah fucking homeless people why do n't they just buy more money like good upstanding folks in dc do !\",\n",
       " 'video is obviously edited , if your elo was as high as peefsmash , then you would see that spiders are perfectly fine and that no such evidence of broken spiders exist you baddie',\n",
       " 'i was expecting a picture of a toddler',\n",
       " 'better learn to kiss ass guys',\n",
       " \"well , that was the least biased article i 've read all day\",\n",
       " 'well they are better than us , and are obviously entitled to use the space that is no longer useful to them as a garbage pale',\n",
       " \"awwww that 's racist\",\n",
       " 'has anyone focked with him yet \\\\?',\n",
       " 'well glad to see turkey had nothing to riot about',\n",
       " 'permanently ribbed for your pleasure',\n",
       " 'my gender',\n",
       " \"it 's not like the us economy going to shit will affect my country\",\n",
       " 'fuck yeah , white power !',\n",
       " \"i know that 's wrestling superstar virgil , but who are the others \\\\?\",\n",
       " 'yes lucky is nearly being demolished by two trucks , wish i could be that lucky',\n",
       " \"age does n't matter , unless you turn him down\",\n",
       " \"because if negging does n't work , a picture of my dick is definitely going to seal the deal\",\n",
       " 'this picture excellently shows your alice costume',\n",
       " \"he 's a terrible individual that should be impeached\"]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarc_comments[500:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4c3b5126-a5b2-4cf9-87dc-440e85cf471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test giving a prediction value to an input\n",
    "testS = [\"i guess no one at google 's ever been on a plane and wanted to listen to their music library\",\n",
    "         \"it 's like windows phone 7 and that worked great\",\n",
    "        'religion must have the answer',\n",
    "        'until a republican does it'\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9dcc1b7b-008c-4047-ace7-00b441e5e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= ProtoCNN.embed(testS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8a3dd3c4-2a0a-40bc-a2b8-d060b556b923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.38821465, 0.6117853 ],\n",
       "       [0.46638945, 0.5336105 ],\n",
       "       [0.3167334 , 0.68326664],\n",
       "       [0.5046599 , 0.4953401 ]], dtype=float32)>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN(testS, training= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "67dc8c97-cf57-4427-ac3a-f6eb3fee210e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 10), dtype=float32, numpy=\n",
       "array([[[ 2.7111988 ,  2.8435276 ,  2.8580358 ,  2.4625027 ,\n",
       "          2.8837852 ,  3.2298265 ,  2.8851266 ,  2.779249  ,\n",
       "          2.7834678 ,  2.695945  ],\n",
       "        [13.555579  , 13.56708   , 13.608713  , 13.089714  ,\n",
       "         13.671051  , 14.761423  , 14.198931  , 13.693032  ,\n",
       "         13.776615  , 13.339384  ],\n",
       "        [ 8.140151  ,  8.293659  ,  8.2329035 ,  7.875981  ,\n",
       "          8.249426  ,  8.662914  ,  8.463434  ,  8.189972  ,\n",
       "          8.333049  ,  7.9773016 ],\n",
       "        [ 0.99792427,  1.0499238 ,  1.040509  ,  0.7297432 ,\n",
       "          1.0358859 ,  1.2475713 ,  1.0940286 ,  1.0371547 ,\n",
       "          1.0157193 ,  0.9604418 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN.full_distance(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "caaaefc3-b992-450d-92ed-a90361e51815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 10), dtype=float32, numpy=\n",
       "array([[[0.        , 0.        , 0.        , 0.78172654, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.27009773, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.4549362 , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.9296246 , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProtoCNN.one_hot_distance(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857578d-24ab-4569-90dc-7420cb22adb9",
   "metadata": {},
   "source": [
    "# Show prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e9683140-48a5-4885-9eda-7e3807c2533a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139232"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1ec1d-0597-4c62-bf3b-822aac4a4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    " vect = ProtoCNN.embed(inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ccdc8b21-d865-4c02-9c37-45a3d2537fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences_vects = []\n",
    "sample_labels = []\n",
    "for i, inputs, labels in train_loader: \n",
    "   \n",
    "    vect = ProtoCNN.embed(inputs) \n",
    "    sample_sentences_vects.append(vect.numpy())\n",
    "    sample_labels.extend(labels.tolist())\n",
    "\n",
    "    if i ==200:\n",
    "        break\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6fad9356-a0fb-43bb-b5b2-c562c05a0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sent_vect = tf.concat(sample_sentences_vects, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fed805e3-d819-4ae7-9442-895d46c030db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[194], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mapped_prototype \u001b[38;5;241m=\u001b[39m showPrototypes(sample_sentences,sample_sent_vect,\u001b[43msample_y\u001b[49m, k_protos\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,printOutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, k_closest_sents \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_y' is not defined"
     ]
    }
   ],
   "source": [
    "mapped_prototype = showPrototypes(sample_sentences,sample_sent_vect, sample_labels, k_protos=10,printOutput=False, k_closest_sents = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c46d1f14-6112-4dce-83d0-a35ff82b50ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('these kids are going places in life', 0.3135772, 1),\n",
       " ('i hear there is even an uk one', 0.3172326, 1),\n",
       " ('who let her leave the house line that', 0.32124335, 1),\n",
       " ('that seems like someone i wanna hang out with', 0.32230243, 1),\n",
       " (\"you could n't make up a title like that\", 0.3228807, 1),\n",
       " (\"someone 's moving house and home\", 0.32551184, 1),\n",
       " (\"he looks exactly like what i 'd imagine someone like this to look like\",\n",
       "  0.32663426,\n",
       "  1),\n",
       " ('robin has been in every fe game since the first one', 0.32718822, 1),\n",
       " ('obby nothing gets me hot like o o', 0.32777935, 1),\n",
       " ('something for meth or something like that', 0.32828987, 1),\n",
       " ('i just love that it takes the video that long to get to the point',\n",
       "  0.3287512,\n",
       "  1),\n",
       " (\"that looks more like it 's next to point\", 0.32890695, 1),\n",
       " ('she really seems to be enjoying it', 0.33070856, 1),\n",
       " ('the one with the bear , i think', 0.33257347, 1),\n",
       " ('i think i had a seizure while reading this', 0.33272243, 1),\n",
       " ('funniest thing ive ever seen in my entire life', 0.33317474, 1),\n",
       " (\"does n't look like an issue for me\", 0.3342791, 1),\n",
       " ('the fact that people actually disagree with me sometimes', 0.3363693, 1),\n",
       " ('underratted comment of the day', 0.33721542, 1),\n",
       " ('this person is going to go far in life', 0.33753684, 1),\n",
       " ('the geometry is strong with this one', 0.338559, 1),\n",
       " (\"this is n't on the front page or anything already\", 0.33967176, 1),\n",
       " ('why not put the full thing on it', 0.34032157, 1),\n",
       " ('when i see your face it does give me hell', 0.34149516, 1),\n",
       " ('sad thing is , i can actually belive this', 0.34167826, 1),\n",
       " ('regretting my decision to go with each passing day', 0.34179804, 1),\n",
       " ('can someone explain this for me \\\\?', 0.34213352, 1),\n",
       " ('you know i think this guy has a chance of making it', 0.34213576, 1),\n",
       " (\"actually that 's the third hand\", 0.34297392, 1),\n",
       " ('this guy is almost as good as me', 0.34312445, 1),\n",
       " (\"it 's not as if he 's the titular character or anything\", 0.3433476, 1),\n",
       " ('reverse spin direction and push it', 0.34385487, 1),\n",
       " ('use pliers or a wrench to pull it out', 0.34417415, 1),\n",
       " (\"i ca n't think of any two people i 'd rather get up close and personal with\",\n",
       "  0.34451818,\n",
       "  1),\n",
       " ('that was me , i got high and started drawing on shit', 0.344531, 1),\n",
       " ('while i read this during a shit', 0.34476843, 1),\n",
       " ('whose the girl on the bottom left \\\\?', 0.34512696, 1),\n",
       " ('the hype is strong in this one', 0.34538028, 1),\n",
       " ('ben carson would like to have a word', 0.34550968, 1),\n",
       " ('both of them combined or each of them \\\\?', 0.34637365, 1),\n",
       " ('then you find out it was a land line', 0.34771985, 1),\n",
       " ('one eye poke made the fight \\\\) \\\\) \\\\)', 0.3478808, 1),\n",
       " ('i think the title really passes in this case', 0.34862307, 1),\n",
       " ('where is the all of the above \\\\?', 0.35043287, 1),\n",
       " ('i came here to cringe not to think', 0.3506609, 1),\n",
       " ('really terrible stuff in there', 0.35132548, 1),\n",
       " ('nono finger sits on the front row to the left', 0.3515544, 1),\n",
       " (\"i do n't think i 'd take my salt any other way\", 0.35186923, 1),\n",
       " ('was it the computer on the left \\\\?', 0.35187796, 1),\n",
       " ('better let as many of them into europe as possible', 0.3523066, 1),\n",
       " (\"it 's out on my birthday \\\\) someone here should by it for me\",\n",
       "  0.3525476,\n",
       "  1),\n",
       " ('i cant stay and work here for ever', 0.35292253, 1),\n",
       " ('deserves to crash with a shirt like that', 0.35434902, 1),\n",
       " ('\\\\( just like the person making that photo \\\\)', 0.3543504, 1),\n",
       " (\"mit if you do n't know when to use to or too\", 0.35495317, 1),\n",
       " ('one looks a bit worse the bottom one i think', 0.35497248, 1),\n",
       " ('i think you might be the first person to ever complain about this in the history of time',\n",
       "  0.3552216,\n",
       "  1),\n",
       " ('should have shot him or strung him up from a tree just in case',\n",
       "  0.35523936,\n",
       "  1),\n",
       " ('it took a whole month for that \\\\?', 0.3553446, 1),\n",
       " ('by doing the same thing i do every night and day nothing', 0.3557903, 1),\n",
       " ('should have kept this in house', 0.356741, 1),\n",
       " ('was there anything else in this video \\\\?', 0.3571822, 1),\n",
       " ('burning man became terrible exactly the year after i went that one time',\n",
       "  0.35728908,\n",
       "  1),\n",
       " ('what a whiny little prick on the left', 0.35746264, 1),\n",
       " (\"i 've been thinking about this all day\", 0.35759634, 1),\n",
       " ('can i request one for my school', 0.35782492, 1),\n",
       " ('i think you are confusing with', 0.35787094, 1),\n",
       " ('is there a difference between them \\\\?', 0.35826674, 1),\n",
       " ('right that almost the same thing', 0.35840473, 1),\n",
       " (\"easily the most fucked up thing i 've seen today\", 0.35866416, 1),\n",
       " ('this is going to the front page', 0.35923013, 1),\n",
       " ('can i log in using facebook \\\\?', 0.35942808, 1),\n",
       " ('does this qualify as a scary moment too \\\\?', 0.3595601, 1),\n",
       " ('hollywood need to make a movie on this', 0.35956013, 1),\n",
       " ('just trying 2 fit in but stand out', 0.35960123, 1),\n",
       " ('what do you do at that hour , if not this \\\\?', 0.35965958, 1),\n",
       " ('onlinebots living up to their name', 0.3604018, 1),\n",
       " ('now that looks like a president i could have a beer with', 0.3606794, 1),\n",
       " ('sounds like jesus himself said this', 0.3607124, 1),\n",
       " ('he might get that this year tbh', 0.36084092, 1),\n",
       " ('this isnt a repost of something that was front page today', 0.3612252, 1),\n",
       " ('i love reminiscing about that day myself', 0.36168668, 1),\n",
       " ('see what happens when you do spinning shit', 0.36211467, 1),\n",
       " ('is this guy rich or something \\\\?', 0.36289462, 1),\n",
       " ('your not supposed to mention that', 0.36335245, 1),\n",
       " ('a superior phone , like say , a galaxy would have been able to take that',\n",
       "  0.36363792,\n",
       "  1),\n",
       " ('i present the best friend of the year', 0.36383536, 1),\n",
       " ('the war on christmas is getting out of hand', 0.363868, 1),\n",
       " ('why are you posting stuff from back in january \\\\?', 0.36397707, 1),\n",
       " ('also , if you have just a little bit of ketchup left pour in some water and shake it up',\n",
       "  0.36414933,\n",
       "  1),\n",
       " ('south park has been any good since the fifth season of the simpsons',\n",
       "  0.36521426,\n",
       "  1),\n",
       " ('anybody got a link to the video \\\\?', 0.36533156, 1),\n",
       " ('is that not part of the process \\\\?', 0.36554062, 1),\n",
       " ('blame the west works every time', 0.36574072, 1),\n",
       " (\"funniest thing i 've seen in a while\", 0.36575007, 1),\n",
       " ('just the fucking way i like it', 0.3665198, 1),\n",
       " ('how did they get the picture \\\\?', 0.36662766, 1),\n",
       " (\"you go first and then i 'll think about it\", 0.36763626, 1),\n",
       " ('everything happens for a reason', 0.3676815, 1),\n",
       " ('is it a five or ten page book \\\\?', 0.3678158, 1)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_prototype[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "43a7a2b6-0ce9-4b39-86b6-4663e0f0366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_prototype_150000 = mapped_prototype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "567915d2-daad-42eb-8854-df23b609cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_sentences(sent, mapped_prototype):\n",
    "    sentence_embed = ProtoCNN.embed(np.expand_dims(sent, 0))\n",
    "   \n",
    "    protos = [x[0] for x in mapped_prototype]\n",
    "    proto_embed = ProtoCNN.embed(encode(protos))\n",
    "    distances = [(index, np.linalg.norm(embed - sentence_embed)) for index, embed in enumerate(proto_embed)]\n",
    "    output = [mapped_prototype[x[0]] for x in sorted(distances, key= lambda x: x[1])]\n",
    "    \n",
    "    return output[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a51235df-a56c-465a-b0b1-459b642326b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('better let as many of them into europe as possible', 0.3523066, 1),\n",
       " ('onlinebots living up to their name', 0.3604018, 1),\n",
       " ('everything happens for a reason', 0.3676815, 1),\n",
       " (\"you could n't make up a title like that\", 0.3228807, 1),\n",
       " ('why not put the full thing on it', 0.34032157, 1),\n",
       " ('really terrible stuff in there', 0.35132548, 1),\n",
       " ('you know i think this guy has a chance of making it', 0.34213576, 1),\n",
       " ('i came here to cringe not to think', 0.3506609, 1),\n",
       " ('deserves to crash with a shirt like that', 0.35434902, 1),\n",
       " ('your not supposed to mention that', 0.36335245, 1)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_sentences(x[0], mapped_prototype[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6d8f6155-1107-4329-8dc9-6774f60c52b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"i 've been thinking about this all day\", 0.35759634, 1),\n",
       " ('by doing the same thing i do every night and day nothing', 0.3557903, 1),\n",
       " ('now that looks like a president i could have a beer with', 0.3606794, 1),\n",
       " ('this person is going to go far in life', 0.33753684, 1),\n",
       " ('a superior phone , like say , a galaxy would have been able to take that',\n",
       "  0.36363792,\n",
       "  1),\n",
       " ('burning man became terrible exactly the year after i went that one time',\n",
       "  0.35728908,\n",
       "  1),\n",
       " ('i cant stay and work here for ever', 0.35292253, 1),\n",
       " ('better let as many of them into europe as possible', 0.3523066, 1),\n",
       " ('sounds like jesus himself said this', 0.3607124, 1),\n",
       " ('should have shot him or strung him up from a tree just in case',\n",
       "  0.35523936,\n",
       "  1)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_sentences(x[1], mapped_prototype[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e04ed7f5-6f50-43e0-a2a3-11a143746d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('can i request one for my school', 0.35782492, 1),\n",
       " ('your not supposed to mention that', 0.36335245, 1),\n",
       " ('i cant stay and work here for ever', 0.35292253, 1),\n",
       " ('sad thing is , i can actually belive this', 0.34167826, 1),\n",
       " (\"you go first and then i 'll think about it\", 0.36763626, 1),\n",
       " ('funniest thing ive ever seen in my entire life', 0.33317474, 1),\n",
       " ('you know i think this guy has a chance of making it', 0.34213576, 1),\n",
       " ('i just love that it takes the video that long to get to the point',\n",
       "  0.3287512,\n",
       "  1),\n",
       " ('everything happens for a reason', 0.3676815, 1),\n",
       " (\"i do n't think i 'd take my salt any other way\", 0.35186923, 1)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_sentences(x[2], mapped_prototype[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ba70c87e-6615-4f02-af09-d9ced8cec690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'until a republican does it'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testS[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6a93668a-5a03-40ee-8b1c-f5b0b1903306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('right that almost the same thing', 0.35840473, 1),\n",
       " ('while i read this during a shit', 0.34476843, 1),\n",
       " ('your not supposed to mention that', 0.36335245, 1),\n",
       " ('just the fucking way i like it', 0.3665198, 1),\n",
       " (\"you could n't make up a title like that\", 0.3228807, 1),\n",
       " ('sad thing is , i can actually belive this', 0.34167826, 1),\n",
       " ('something for meth or something like that', 0.32828987, 1),\n",
       " ('she really seems to be enjoying it', 0.33070856, 1),\n",
       " ('see what happens when you do spinning shit', 0.36211467, 1),\n",
       " ('that was me , i got high and started drawing on shit', 0.344531, 1)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_sentences(x[3], mapped_prototype[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "7aef54d6-b336-41d3-b923-3bdcabf72c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e872131f-fa08-4ba8-8871-1c2fecb3ff59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"i 've been thinking about this all day\", 0.35759634, 1)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_prototype[3][63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6a81dfcc-abad-48fd-9427-b36285cf9dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 384), dtype=float32, numpy=\n",
       "array([[0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.01237033],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.01237033],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.01237033],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.01237033],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.01237033],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01747742, 0.        ,\n",
       "        0.05296943]], dtype=float32)>"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto3_embed list_c.index(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "5506ff2b-0db0-4888-8b4a-15b11e159c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('these kids are going places in life', 0.3135772, 1),\n",
       " ('i hear there is even an uk one', 0.3172326, 1),\n",
       " ('who let her leave the house line that', 0.32124335, 1),\n",
       " ('that seems like someone i wanna hang out with', 0.32230243, 1),\n",
       " (\"you could n't make up a title like that\", 0.3228807, 1),\n",
       " (\"someone 's moving house and home\", 0.32551184, 1),\n",
       " (\"he looks exactly like what i 'd imagine someone like this to look like\",\n",
       "  0.32663426,\n",
       "  1),\n",
       " ('robin has been in every fe game since the first one', 0.32718822, 1),\n",
       " ('obby nothing gets me hot like o o', 0.32777935, 1),\n",
       " ('something for meth or something like that', 0.32828987, 1),\n",
       " ('i just love that it takes the video that long to get to the point',\n",
       "  0.3287512,\n",
       "  1),\n",
       " (\"that looks more like it 's next to point\", 0.32890695, 1),\n",
       " ('she really seems to be enjoying it', 0.33070856, 1),\n",
       " ('the one with the bear , i think', 0.33257347, 1),\n",
       " ('i think i had a seizure while reading this', 0.33272243, 1),\n",
       " ('funniest thing ive ever seen in my entire life', 0.33317474, 1),\n",
       " (\"does n't look like an issue for me\", 0.3342791, 1),\n",
       " ('the fact that people actually disagree with me sometimes', 0.3363693, 1),\n",
       " ('underratted comment of the day', 0.33721542, 1),\n",
       " ('this person is going to go far in life', 0.33753684, 1),\n",
       " ('the geometry is strong with this one', 0.338559, 1),\n",
       " (\"this is n't on the front page or anything already\", 0.33967176, 1),\n",
       " ('why not put the full thing on it', 0.34032157, 1),\n",
       " ('when i see your face it does give me hell', 0.34149516, 1),\n",
       " ('sad thing is , i can actually belive this', 0.34167826, 1),\n",
       " ('regretting my decision to go with each passing day', 0.34179804, 1),\n",
       " ('can someone explain this for me \\\\?', 0.34213352, 1),\n",
       " ('you know i think this guy has a chance of making it', 0.34213576, 1),\n",
       " (\"actually that 's the third hand\", 0.34297392, 1),\n",
       " ('this guy is almost as good as me', 0.34312445, 1),\n",
       " (\"it 's not as if he 's the titular character or anything\", 0.3433476, 1),\n",
       " ('reverse spin direction and push it', 0.34385487, 1),\n",
       " ('use pliers or a wrench to pull it out', 0.34417415, 1),\n",
       " (\"i ca n't think of any two people i 'd rather get up close and personal with\",\n",
       "  0.34451818,\n",
       "  1),\n",
       " ('that was me , i got high and started drawing on shit', 0.344531, 1),\n",
       " ('while i read this during a shit', 0.34476843, 1),\n",
       " ('whose the girl on the bottom left \\\\?', 0.34512696, 1),\n",
       " ('the hype is strong in this one', 0.34538028, 1),\n",
       " ('ben carson would like to have a word', 0.34550968, 1),\n",
       " ('both of them combined or each of them \\\\?', 0.34637365, 1),\n",
       " ('then you find out it was a land line', 0.34771985, 1),\n",
       " ('one eye poke made the fight \\\\) \\\\) \\\\)', 0.3478808, 1),\n",
       " ('i think the title really passes in this case', 0.34862307, 1),\n",
       " ('where is the all of the above \\\\?', 0.35043287, 1),\n",
       " ('i came here to cringe not to think', 0.3506609, 1),\n",
       " ('really terrible stuff in there', 0.35132548, 1),\n",
       " ('nono finger sits on the front row to the left', 0.3515544, 1),\n",
       " (\"i do n't think i 'd take my salt any other way\", 0.35186923, 1),\n",
       " ('was it the computer on the left \\\\?', 0.35187796, 1),\n",
       " ('better let as many of them into europe as possible', 0.3523066, 1),\n",
       " (\"it 's out on my birthday \\\\) someone here should by it for me\",\n",
       "  0.3525476,\n",
       "  1),\n",
       " ('i cant stay and work here for ever', 0.35292253, 1),\n",
       " ('\\\\( just like the person making that photo \\\\)', 0.3543504, 1),\n",
       " (\"mit if you do n't know when to use to or too\", 0.35495317, 1),\n",
       " ('one looks a bit worse the bottom one i think', 0.35497248, 1),\n",
       " ('i think you might be the first person to ever complain about this in the history of time',\n",
       "  0.3552216,\n",
       "  1),\n",
       " ('should have shot him or strung him up from a tree just in case',\n",
       "  0.35523936,\n",
       "  1),\n",
       " ('it took a whole month for that \\\\?', 0.3553446, 1),\n",
       " ('by doing the same thing i do every night and day nothing', 0.3557903, 1),\n",
       " ('should have kept this in house', 0.356741, 1),\n",
       " ('was there anything else in this video \\\\?', 0.3571822, 1),\n",
       " ('burning man became terrible exactly the year after i went that one time',\n",
       "  0.35728908,\n",
       "  1),\n",
       " ('what a whiny little prick on the left', 0.35746264, 1),\n",
       " (\"i 've been thinking about this all day\", 0.35759634, 1),\n",
       " ('can i request one for my school', 0.35782492, 1),\n",
       " ('i think you are confusing with', 0.35787094, 1),\n",
       " ('is there a difference between them \\\\?', 0.35826674, 1),\n",
       " ('right that almost the same thing', 0.35840473, 1),\n",
       " ('did this get deleted off the front page yet \\\\?', 0.35856345, 1),\n",
       " (\"easily the most fucked up thing i 've seen today\", 0.35866416, 1),\n",
       " ('this is going to the front page', 0.35923013, 1),\n",
       " ('can i log in using facebook \\\\?', 0.35942808, 1),\n",
       " ('does this qualify as a scary moment too \\\\?', 0.3595601, 1),\n",
       " ('hollywood need to make a movie on this', 0.35956013, 1),\n",
       " ('just trying 2 fit in but stand out', 0.35960123, 1),\n",
       " ('what do you do at that hour , if not this \\\\?', 0.35965958, 1),\n",
       " ('onlinebots living up to their name', 0.3604018, 1),\n",
       " ('now that looks like a president i could have a beer with', 0.3606794, 1),\n",
       " ('sounds like jesus himself said this', 0.3607124, 1),\n",
       " ('he might get that this year tbh', 0.36084092, 1),\n",
       " ('this isnt a repost of something that was front page today', 0.3612252, 1),\n",
       " ('i love reminiscing about that day myself', 0.36168668, 1),\n",
       " ('see what happens when you do spinning shit', 0.36211467, 1),\n",
       " ('is this guy rich or something \\\\?', 0.36289462, 1),\n",
       " ('your not supposed to mention that', 0.36335245, 1),\n",
       " ('a superior phone , like say , a galaxy would have been able to take that',\n",
       "  0.36363792,\n",
       "  1),\n",
       " ('i present the best friend of the year', 0.36383536, 1),\n",
       " ('the war on christmas is getting out of hand', 0.363868, 1),\n",
       " ('why are you posting stuff from back in january \\\\?', 0.36397707, 1),\n",
       " ('also , if you have just a little bit of ketchup left pour in some water and shake it up',\n",
       "  0.36414933,\n",
       "  1),\n",
       " ('south park has been any good since the fifth season of the simpsons',\n",
       "  0.36521426,\n",
       "  1),\n",
       " ('anybody got a link to the video \\\\?', 0.36533156, 1),\n",
       " ('blame the west works every time', 0.36574072, 1),\n",
       " (\"funniest thing i 've seen in a while\", 0.36575007, 1),\n",
       " ('clinton will be done if this happens', 0.36631563, 1),\n",
       " ('just the fucking way i like it', 0.3665198, 1),\n",
       " ('how did they get the picture \\\\?', 0.36662766, 1),\n",
       " (\"you go first and then i 'll think about it\", 0.36763626, 1),\n",
       " ('everything happens for a reason', 0.3676815, 1),\n",
       " ('is it a five or ten page book \\\\?', 0.3678158, 1)]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_prototype[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "1841c2b6-7aaf-4df0-a6bf-e7706550a187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shrek , especially the first one', 0.5935609, 0),\n",
       " (\"holy shit it 's already been a year \\\\?\", 0.6024625, 0),\n",
       " ('brazilian in britain , probably both', 0.6050657, 0),\n",
       " ('the rifle from a regular store and my sister painted it', 0.60792977, 0),\n",
       " ('do you mind giving me the demo of that \\\\?', 0.60851675, 0),\n",
       " ('none of them can stop the time', 0.6088037, 0),\n",
       " ('anyone have a video of the incident \\\\?', 0.60930187, 0),\n",
       " ('one of the names is visible towards the bottom', 0.6107298, 0),\n",
       " ('give portland some love for once', 0.61119914, 0),\n",
       " ('make it twice as thick with a battery that lasts twice as long',\n",
       "  0.6117877,\n",
       "  0),\n",
       " ('he just got on a list by searching for that', 0.61233556, 0),\n",
       " ('16 is a worryingly high number', 0.6130593, 0),\n",
       " (\"what 's the source for this \\\\?\", 0.61373526, 0),\n",
       " ('hope you enjoy it other people are paying for it', 0.61425763, 0),\n",
       " ('did you even watch the video \\\\?', 0.6157763, 0),\n",
       " ('they were not going to gain anything anyway', 0.6159876, 0),\n",
       " ('the us could learn a thing or two from this', 0.6166027, 0),\n",
       " ('does this not load on mobile for others \\\\?', 0.6172237, 0),\n",
       " ('side to side or front to back \\\\?', 0.6201905, 0),\n",
       " ('and im dancing d i kinda like that', 0.620812, 0),\n",
       " ('are we not doing phrasing anymore \\\\?', 0.62093306, 0),\n",
       " ('do i have to play a single match to get these \\\\?', 0.62313, 0),\n",
       " ('people are taking this very seriously', 0.62326515, 0),\n",
       " ('these extra large scissors are getting out of hand', 0.624424, 0),\n",
       " ('regretting my decision to go with each passing day', 0.6249399, 1),\n",
       " ('your character looks like shit', 0.624956, 0),\n",
       " ('you can get it on minions too i think', 0.6250879, 0),\n",
       " ('joan of arc rollin in her grave', 0.6258995, 0),\n",
       " ('blame the west works every time', 0.6265719, 1),\n",
       " ('also , if you have just a little bit of ketchup left pour in some water and shake it up',\n",
       "  0.6269192,\n",
       "  1),\n",
       " ('flags from other countries would be nice too', 0.62702686, 0),\n",
       " ('links to other videos anyone \\\\?', 0.62774837, 0),\n",
       " ('the members were too young to be on facebook \\\\?', 0.6281299, 0),\n",
       " ('do you want turd sandwich or a giant douche \\\\?', 0.6285826, 0),\n",
       " ('is that dodger for press heart to continue \\\\?', 0.62987214, 0),\n",
       " ('full metal jacket opened my eyes to this one', 0.6300228, 0),\n",
       " ('someone is not going to get a walk after donny gets home', 0.6301969, 0),\n",
       " ('are people still buying this stuff \\\\?', 0.6306597, 0),\n",
       " (\"i think you 're talking about the web \\\\?\", 0.63081646, 0),\n",
       " ('a sequel to the martian would be pretty cool i think', 0.6308886, 0),\n",
       " ('england algeria in the 2010 world cup', 0.63140756, 0),\n",
       " ('one eye poke made the fight \\\\) \\\\) \\\\)', 0.6320329, 1),\n",
       " ('unfortunately , i feel like bradford is next', 0.6328622, 0),\n",
       " (\"looks like shit but i 'd still eat it\", 0.6328915, 0),\n",
       " (\"that 's actually kind of sad in a way\", 0.6333719, 0),\n",
       " ('freshman year , high school or college \\\\?', 0.6334113, 1),\n",
       " ('for real though , i kinda want a hamburger now', 0.6342192, 0),\n",
       " ('are wwe rings stiffer than others \\\\?', 0.6349757, 0),\n",
       " ('hello phillip schofield , i fuck lobsters for money', 0.63667554, 0),\n",
       " ('does this really need to be posted week after week \\\\?', 0.63672155, 0),\n",
       " ('did he pull up to the wrong side of the pump \\\\?', 0.63681144, 0),\n",
       " (\"i 'd love this , i hate that fucker\", 0.63688725, 0),\n",
       " ('i think you are confusing with', 0.63728064, 1),\n",
       " ('oce challenger looking good this year', 0.63760686, 0),\n",
       " ('the same old story unfortunately', 0.63812655, 0),\n",
       " ('too early to tell by the looks of it', 0.6381723, 0),\n",
       " ('i was wondering when it was going to happen', 0.63826644, 0),\n",
       " (\"this is simply one of the most retarded articles i 've read in a long while\",\n",
       "  0.6385116,\n",
       "  0),\n",
       " ('well there is a lot of pink on it', 0.639449, 1),\n",
       " ('classes start next week , looking forward to this feeling again',\n",
       "  0.63948315,\n",
       "  1),\n",
       " ('but seriously , what actually happened \\\\?', 0.6397859, 0),\n",
       " ('is it me or is that freddy in the corner getting closer \\\\?',\n",
       "  0.64014393,\n",
       "  0),\n",
       " ('until the clutch shits the bed', 0.64027137, 0),\n",
       " ('literally never had this happen to me', 0.6403277, 0),\n",
       " ('tim meadows needs to be the next colonel', 0.64034045, 0),\n",
       " ('shut up and take my money already', 0.640674, 1),\n",
       " ('onlinebots living up to their name', 0.6413125, 1),\n",
       " ('is that a puffin in a bear suit \\\\?', 0.64151627, 0),\n",
       " ('i think this is the kind of shit we can do without here', 0.64157754, 0),\n",
       " ('she is winning , what polls are they looking at \\\\?', 0.642666, 0),\n",
       " (\"i'm live in roanoke and just learning of this\", 0.64278626, 0),\n",
       " ('more articles about this subject please', 0.64295685, 1),\n",
       " ('roadhog cosplay on point though', 0.64314085, 0),\n",
       " ('haha is this a joke , i actually laughed', 0.6437672, 0),\n",
       " ('is that from land of the rising sun \\\\?', 0.64441746, 0),\n",
       " ('anything that makes noise and or mess', 0.6446741, 0),\n",
       " ('is this out in the us already \\\\?', 0.6453868, 0),\n",
       " ('something that will sit on the website for months labeled coming soon',\n",
       "  0.6454906,\n",
       "  0),\n",
       " (\"you could n't pay me to watch a game at an awkward angle like that\",\n",
       "  0.64553314,\n",
       "  0),\n",
       " ('the oceans grow stronger with each passing day', 0.64600027, 0),\n",
       " (\"stickin' up for the little guy ' \\\\)\", 0.646011, 0),\n",
       " ('how does a man run for public office with a face that is that punchable \\\\?',\n",
       "  0.6461115,\n",
       "  0),\n",
       " ('can someone write that out so i can copy and paste it onto a friends profile picture \\\\?',\n",
       "  0.6469502,\n",
       "  0),\n",
       " ('writings was on the wall with the amount pt nephew gets', 0.6478189, 0),\n",
       " ('are you serious get out of here with this nonsense', 0.64805365, 0),\n",
       " ('that intros incredibly long considering it leads to nothing', 0.6483552, 0),\n",
       " ('welcome to yesterday i guess \\\\?', 0.64849085, 0),\n",
       " ('thought this was from the onion', 0.64878327, 0),\n",
       " ('wtf are these governments doing \\\\?', 0.6498942, 0),\n",
       " ('does anyone listen to the un \\\\?', 0.6501581, 0),\n",
       " ('judging by the downvotes on imgur there are a lot of jealous people on there',\n",
       "  0.6507733,\n",
       "  0),\n",
       " ('except it was san bernardino pd', 0.65157425, 0),\n",
       " ('should i just mail her my testicles \\\\?', 0.65248674, 0),\n",
       " (\"reddit 's a dating site now \\\\?\", 0.65369195, 0),\n",
       " ('the soviets start cheering for rocky at the end of the fourth one',\n",
       "  0.65382624,\n",
       "  0),\n",
       " ('do you really want me to just list every single film \\\\?', 0.653862, 0),\n",
       " ('eugh i accidentally clicked on a link to the mirror', 0.6541268, 0),\n",
       " ('try looking in some fortified house in abbottabad maybe \\\\?',\n",
       "  0.65431523,\n",
       "  0),\n",
       " ('everything happens for a reason', 0.6543567, 1),\n",
       " ('it looks it looks like someone put underwear on their head', 0.65444565, 0)]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_prototype[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d8d00d3-52b8-422e-95ad-c5464bc568b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c2a1c0e-0519-496c-bae7-6b9b75eeb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototype_class_vec[:2,1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56ba4474-d777-435c-9ac1-f4dcf7beceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototype_class_vec[2:,0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92e61af1-bac7-40d9-82eb-6cd926d6482c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototype_class_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4731bde8-16c3-4943-8148-a9630673ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1: labels with valid indices, but K > N\n",
    "labels = torch.tensor([0, 0, 0, 1, 0, 0, 1])  # 7 indices, all within range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff31a33f-8f22-44f2-850b-07c54726aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_prototypes = prototype_class_vec[:, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5728a6ee-6e41-460a-8681-43950133af04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 0., 1.],\n",
       "        [1., 1., 1., 0., 1., 1., 0.],\n",
       "        [1., 1., 1., 0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ca5fec1-4960-4572-9872-ad9011a0deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototypes_of_correct_class = tf.gather(prototype_class_vec, labels, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78af9d96-7bfa-4194-976c-6f7645dcb6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float64, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 1.],\n",
       "       [1., 1., 1., 0., 1., 1., 0.],\n",
       "       [1., 1., 1., 0., 1., 1., 0.]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototypes_of_correct_class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e4856-051f-441a-a43d-6cbafe8614f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototypes_of_correct_class = tf.transpose(prototypes_of_correct_class)\n",
    "\n",
    "# Step 3: Calculate prototypes of wrong class\n",
    "prototypes_of_wrong_class = 1 - prototypes_of_correct_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "518ff1d9-6cd5-43f7-b8e6-6e4c2d57a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = torch.rand(4, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e0d7dd1-80b1-4475-aec9-9f6cc9544b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9815, 0.3509, 0.6898, 0.0900, 0.0014, 0.8479, 0.1243],\n",
       "        [0.7572, 0.7420, 0.4903, 0.2274, 0.6909, 0.9754, 0.2643],\n",
       "        [0.6819, 0.6446, 0.6939, 0.3473, 0.2511, 0.8586, 0.8949],\n",
       "        [0.2355, 0.7581, 0.0550, 0.3438, 0.3973, 0.6611, 0.3795]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e766dd5-f6f1-47f6-9c6d-21e6d24f00df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float64, numpy=\n",
       "array([[0.        , 0.        , 0.        , 0.09001052, 0.        ,\n",
       "        0.        , 0.12433195],\n",
       "       [0.        , 0.        , 0.        , 0.22741288, 0.        ,\n",
       "        0.        , 0.26425809],\n",
       "       [0.68193752, 0.64455527, 0.69392854, 0.        , 0.25112051,\n",
       "        0.85856164, 0.        ],\n",
       "       [0.2355209 , 0.75813454, 0.0550034 , 0.        , 0.39734125,\n",
       "        0.66105431, 0.        ]])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototypes_of_correct_class * distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3c498-ded2-4ed0-830f-09d9b1076f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
