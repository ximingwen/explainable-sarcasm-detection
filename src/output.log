979it [06:11,  2.81it/s]Epoch: 13, Loss: 0.4172834995814732 58800/139232 train accuracy:0.8079081773757935
1049it [06:36,  2.82it/s]Epoch: 13, Loss: 0.41481465657552086 63000/139232 train accuracy:0.8080475926399231
1119it [07:01,  2.81it/s]Epoch: 13, Loss: 0.4249587867373512 67200/139232 train accuracy:0.8079166412353516
1189it [07:26,  2.81it/s]Epoch: 13, Loss: 0.4251922607421875 71400/139232 train accuracy:0.8075349926948547
1259it [07:51,  2.82it/s]Epoch: 13, Loss: 0.4226034691220238 75600/139232 train accuracy:0.8075529336929321
1329it [08:16,  2.78it/s]Epoch: 13, Loss: 0.4335521589006696 79800/139232 train accuracy:0.8071679472923279
1399it [08:47,  1.47it/s]Epoch: 13, Loss: 0.43537022181919643 84000/139232 train accuracy:0.8069047331809998
1469it [09:26,  2.79it/s]Epoch: 13, Loss: 0.42392453148251485 88200/139232 train accuracy:0.8068027496337891
1539it [09:51,  2.81it/s]Epoch: 13, Loss: 0.4392998976934524 92400/139232 train accuracy:0.8060822486877441
1609it [10:16,  2.80it/s]Epoch: 13, Loss: 0.430126459030878 96600/139232 train accuracy:0.8056728839874268
1679it [10:41,  2.78it/s]Epoch: 13, Loss: 0.43763142903645835 100800/139232 train accuracy:0.805446445941925
1749it [11:06,  2.76it/s]Epoch: 13, Loss: 0.42088236490885417 105000/139232 train accuracy:0.8054190278053284
1819it [11:41,  1.44it/s]Epoch: 13, Loss: 0.42704171316964284 109200/139232 train accuracy:0.8053205013275146
1889it [12:17,  2.80it/s]Epoch: 13, Loss: 0.4239497884114583 113400/139232 train accuracy:0.8054585456848145
1959it [12:42,  2.81it/s]Epoch: 13, Loss: 0.42182445707775296 117600/139232 train accuracy:0.8053486347198486
2029it [13:07,  2.80it/s]Epoch: 13, Loss: 0.42466346377418157 121800/139232 train accuracy:0.8054269552230835
2081it [13:26,  2.78it/s]
2099it [13:32,  2.79it/s]Epoch: 13, Loss: 0.41749319893973214 126000/139232 train accuracy:0.8054364919662476
2100it [13:32,  2.79it/s]
2151it [13:51,  2.79it/s]
2153it [13:51,  2.79it/s]
2169it [13:57,  2.78it/s]Epoch: 13, Loss: 0.4140550595238095 130200/139232 train accuracy:0.80549156665802
2239it [14:22,  2.76it/s]Epoch: 13, Loss: 0.41958156040736605 134400/139232 train accuracy:0.8055580258369446
2309it [14:48,  2.77it/s]Epoch: 13, Loss: 0.4123294212704613 138600/139232 train accuracy:0.8056060671806335
2321it [14:52,  2.60it/s]
Epoch: 13, epoch Loss: 58893.40625  train accuracy:0.8055906891822815

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.09it/s]
Epoch: 13, Valid Loss: 6535.734375  valid accuracy:0.807692289352417
find better loss
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:08<00:00,  8.38it/s]
Epoch: 13,   test accuracy:0.8072711825370789
37it [00:13,  2.79it/s]Epoch: 14, Loss: 0.22527938116164434 2280/139232 train accuracy:0.8109649419784546
69it [00:25,  2.81it/s]Epoch: 14, Loss: 0.19272474016462054 4200/139232 train accuracy:0.8111904859542847
139it [00:50,  2.80it/s]Epoch: 14, Loss: 0.41524632045200893 8400/139232 train accuracy:0.8128571510314941
209it [01:15,  2.80it/s]Epoch: 14, Loss: 0.4178834461030506 12600/139232 train accuracy:0.8103968501091003
274it [01:38,  2.78it/s]^C
Traceback (most recent call last):
  File "/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/train_bert_proto_cascade_add_loss.py", line 565, in <module>
    gradients = tape.gradient(loss, ProtoCNN.trainable_weights)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py", line 1113, in gradient
    flat_grad = imperative_grad.imperative_grad(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py", line 67, in imperative_grad
    return pywrap_tfe.TFE_Py_TapeGradient(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py", line 160, in _gradient_function
    return grad_fn(mock_op, *out_grads)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py", line 256, in _MeanGrad
    factor = constant_op.constant(factor, dtype=sum_grad.dtype)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 267, in constant
    return _constant_impl(value, dtype, shape, name, verify_shape=False,
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 279, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 304, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 102, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
KeyboardInterrupt
^C
(BERT) xw384@cci-bvm74:/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src$ python train_bert_proto_cascade_add_loss.py
2024-01-01 03:58:39.244130: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perf
ormance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-01 03:58:39.380346: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-01 03:58:39.929538: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such fil
e or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:
2024-01-01 03:58:39.929619: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object fil
e: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:
2024-01-01 03:58:39.929628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the
missing libraries mentioned above are installed properly.
loading data...
data loaded!
loading wgcca embeddings...
wgcca embeddings loaded
topic emb size:  100
Train/Dev split: 139232/15470
2024-01-01 03:58:47.429326: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perf
ormance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-01 03:58:47.543752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22203 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090
, pci bus id: 0000:41:00.0, compute capability: 8.6
2024-01-01 03:58:47.725599: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']
- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForP
reTraining model).
- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassif
ication model).
All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.
2024-01-01 03:58:50.217769: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8700
69it [00:25,  3.52it/s]Epoch: 1, Loss: 1.1129985700334821 1400/139232 train accuracy:0.4035714268684387
139it [00:45,  3.53it/s]Epoch: 1, Loss: 1.0834376743861607 2800/139232 train accuracy:0.4003571569919586
209it [01:05,  3.53it/s]Epoch: 1, Loss: 1.0334819684709822 4200/139232 train accuracy:0.40761905908584595
279it [01:25,  2.46it/s]Epoch: 1, Loss: 0.9976223318917411 5600/139232 train accuracy:0.416607141494751
347it [01:44,  3.51it/s]Epoch: 1, Loss: 0.9469515555245536 6960/139232 train accuracy:0.42298850417137146
349it [01:45,  3.50it/s]Epoch: 1, Loss: 0.028980560302734375 7000/139232 train accuracy:0.42242857813835144
419it [02:05,  3.51it/s]Epoch: 1, Loss: 0.8640849958147322 8400/139232 train accuracy:0.43690475821495056
454it [02:15,  3.35it/s]^C
Traceback (most recent call last):
  File "/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/train_bert_proto_cascade_add_loss.py", line 550, in <module>
    predictions,  full_distances, protos= ProtoCNN([x_batch, author_batch, topic_batch], training=True)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/training.py", line 557, in __call__
    return super().__call__(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/train_bert_proto_cascade_add_loss.py", line 166, in call
    x = self.embedding(input_ids = x["input_ids"], attention_mask = x["attention_mask"], output_hidden_states =True)[0]
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/training.py", line 557, in __call__
    return super().__call__(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/modeling_tf_utils.py", line 383, in run_call_with_unpacked_inputs
    return func(self, **unpacked_inputs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 1090, in call
    outputs = self.bert(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/modeling_tf_utils.py", line 383, in run_call_with_unpacked_inputs
    return func(self, **unpacked_inputs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 850, in call
    encoder_outputs = self.encoder(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 541, in call
    layer_outputs = layer_module(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 451, in call
    self_attention_outputs = self.attention(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 367, in call
    self_outputs = self.self_attention(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 258, in call
    mixed_query_layer = self.query(inputs=hidden_states)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/layers/core/dense.py", line 244, in call
    outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py", line 1176, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py", line 5122, in tensordot
    a_reshape, a_free_dims, a_free_dims_static = _tensordot_reshape(a, a_axes)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py", line 5048, in _tensordot_reshape
    reshaped_a = array_ops.reshape(a_trans, new_shape)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py", line 1176, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py", line 199, in reshape
    result = gen_array_ops.reshape(tensor, shape, name)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py", line 8546, in reshape
    return reshape_eager_fallback(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py", line 8568, in reshape_eager_fallback
    _attr_Tshape, (shape,) = _execute.args_to_matching_eager([shape], ctx, [_dtypes.int32, _dtypes.int64, ], _dtypes.int32)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/eager/execute.py", line 256, in args_to_matching_eager
    tensor = ops.convert_to_tensor(t, ctx=ctx)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py", line 183, in wrapped
    return func(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 1638, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 343, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 267, in constant
    return _constant_impl(value, dtype, shape, name, verify_shape=False,
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 279, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 304, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py", line 102, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
KeyboardInterrupt

(BERT) xw384@cci-bvm74:/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src$ nvidia-smi
Mon Jan  1 04:01:48 2024
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:25:00.0 Off |                  N/A |
| 30%   31C    P8              23W / 350W |  22747MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce RTX 3090        On  | 00000000:41:00.0 Off |                  N/A |
| 56%   49C    P5             130W / 350W |    263MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce RTX 3090        On  | 00000000:61:00.0 Off |                  N/A |
| 30%   25C    P8              27W / 350W |    263MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce RTX 3090        On  | 00000000:A1:00.0 Off |                  N/A |
| 30%   25C    P8              20W / 350W |    263MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce RTX 3090        On  | 00000000:C1:00.0 Off |                  N/A |
| 30%   24C    P8              19W / 350W |    263MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A   4164035      C   /big/xw384/venvs/BERT/bin/python          22738MiB |
|    1   N/A  N/A   4164035      C   /big/xw384/venvs/BERT/bin/python            254MiB |
|    2   N/A  N/A   4164035      C   /big/xw384/venvs/BERT/bin/python            254MiB |
|    3   N/A  N/A   4164035      C   /big/xw384/venvs/BERT/bin/python            254MiB |
|    4   N/A  N/A   4164035      C   /big/xw384/venvs/BERT/bin/python            254MiB |
+---------------------------------------------------------------------------------------+
(BERT) xw384@cci-bvm74:/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src$ nvidia-smi
Mon Jan  1 04:02:38 2024
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3090        On  | 00000000:25:00.0 Off |                  N/A |
| 30%   30C    P8              23W / 350W |  22747MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce RTX 3090        On  | 00000000:41:00.0 Off |                  N/A |
| 35%   35C    P8              15W / 350W |    263MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce RTX 3090        On  | 00000000:61:00.0 Off |                  N/A |
| 30%   25C    P8              27W / 350W |    263MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce RTX 3090        On  | 00000000:A1:00.0 Off |                  N/A |
| 30%   25C    P8              20W / 350W |    263MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA GeForce RTX 3090        On  | 00000000:C1:00.0 Off |                  N/A |
| 30%   24C    P8              20W / 350W |    263MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A   4164035      C   /big/xw384/venvs/BERT/bin/python          22738MiB |
|    1   N/A  N/A   4164035      C   /big/xw384/venvs/BERT/bin/python            254MiB |
|    2   N/A  N/A   4164035      C   /big/xw384/venvs/BERT/bin/python            254MiB |
|    3   N/A  N/A   4164035      C   /big/xw384/venvs/BERT/bin/python            254MiB |
|    4   N/A  N/A   4164035      C   /big/xw384/venvs/BERT/bin/python            254MiB |
+---------------------------------------------------------------------------------------+
(BERT) xw384@cci-bvm74:/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src$ python train_bert_proto_cascade_add_loss.py
2024-01-01 04:02:39.889909: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perf
ormance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-01 04:02:40.027119: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-01 04:02:40.578341: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such fil
e or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:
2024-01-01 04:02:40.578424: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object fil
e: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:
2024-01-01 04:02:40.578434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the
missing libraries mentioned above are installed properly.
loading data...
data loaded!
loading wgcca embeddings...
wgcca embeddings loaded
topic emb size:  100
Train/Dev split: 139232/15470
2024-01-01 04:02:47.824954: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perf
ormance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-01 04:02:47.929228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22203 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090
, pci bus id: 0000:41:00.0, compute capability: 8.6
2024-01-01 04:02:48.111321: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']
- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForP
reTraining model).
- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassif
ication model).
All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.
2024-01-01 04:02:50.510173: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8700
37it [00:27,  2.87it/s]Epoch: 1, Loss: 0.5651678176153274 2280/139232 train accuracy:0.5175438523292542
69it [00:39,  2.86it/s]Epoch: 1, Loss: 0.45277750651041665 4200/139232 train accuracy:0.5195237994194031
139it [01:03,  2.87it/s]Epoch: 1, Loss: 0.9439590308779762 8400/139232 train accuracy:0.5265476107597351
209it [01:27,  2.86it/s]Epoch: 1, Loss: 0.8695386904761905 12600/139232 train accuracy:0.5361111164093018
279it [01:52,  2.84it/s]Epoch: 1, Loss: 0.8393111746651786 16800/139232 train accuracy:0.5427380800247192
349it [02:17,  2.85it/s]Epoch: 1, Loss: 0.8068997628348215 21000/139232 train accuracy:0.5518571138381958
419it [02:41,  2.86it/s]Epoch: 1, Loss: 0.7742562430245535 25200/139232 train accuracy:0.5602777600288391
489it [03:06,  2.85it/s]Epoch: 1, Loss: 0.7433100818452381 29400/139232 train accuracy:0.5687755346298218
559it [03:31,  2.84it/s]Epoch: 1, Loss: 0.72724365234375 33600/139232 train accuracy:0.576369047164917
629it [03:55,  2.84it/s]Epoch: 1, Loss: 0.7158395531063988 37800/139232 train accuracy:0.5833597779273987
699it [04:20,  2.85it/s]Epoch: 1, Loss: 0.6932763090587798 42000/139232 train accuracy:0.5903809666633606
769it [04:44,  2.84it/s]Epoch: 1, Loss: 0.6777130417596726 46200/139232 train accuracy:0.597359299659729
839it [05:09,  2.84it/s]Epoch: 1, Loss: 0.6960048711867559 50400/139232 train accuracy:0.6033135056495667
909it [05:34,  2.85it/s]Epoch: 1, Loss: 0.6687235514322917 54600/139232 train accuracy:0.6089010834693909
979it [05:58,  2.85it/s]Epoch: 1, Loss: 0.6619423130580357 58800/139232 train accuracy:0.6141666769981384
1049it [06:23,  2.84it/s]Epoch: 1, Loss: 0.6677206566220238 63000/139232 train accuracy:0.6187777519226074
1119it [06:47,  2.84it/s]Epoch: 1, Loss: 0.6773283458891369 67200/139232 train accuracy:0.6228422522544861
1189it [07:12,  2.84it/s]Epoch: 1, Loss: 0.6598479352678571 71400/139232 train accuracy:0.627465009689331
1259it [07:37,  2.85it/s]Epoch: 1, Loss: 0.6596567499069941 75600/139232 train accuracy:0.6311772465705872
1329it [08:01,  2.85it/s]Epoch: 1, Loss: 0.6293829055059523 79800/139232 train accuracy:0.635776937007904
1399it [08:26,  2.83it/s]Epoch: 1, Loss: 0.630250011625744 84000/139232 train accuracy:0.6400238275527954
1469it [08:51,  2.85it/s]Epoch: 1, Loss: 0.6086083403087797 88200/139232 train accuracy:0.6438888907432556
1539it [09:16,  2.83it/s]Epoch: 1, Loss: 0.6151611328125 92400/139232 train accuracy:0.6477272510528564
1609it [09:40,  2.84it/s]Epoch: 1, Loss: 0.6208450753348215 96600/139232 train accuracy:0.6515010595321655
1679it [10:05,  2.85it/s]Epoch: 1, Loss: 0.6158112444196429 100800/139232 train accuracy:0.6549999713897705
1749it [10:30,  2.84it/s]Epoch: 1, Loss: 0.6085539899553571 105000/139232 train accuracy:0.658466637134552
1819it [10:54,  2.84it/s]Epoch: 1, Loss: 0.6327428036644345 109200/139232 train accuracy:0.6614377498626709
1889it [11:19,  2.83it/s]Epoch: 1, Loss: 0.6088767787388393 113400/139232 train accuracy:0.6643386483192444
1959it [11:44,  2.84it/s]Epoch: 1, Loss: 0.6484098888578869 117600/139232 train accuracy:0.6669132709503174
2029it [12:09,  2.84it/s]Epoch: 1, Loss: 0.621045154389881 121800/139232 train accuracy:0.6694006323814392
2099it [12:33,  2.83it/s]Epoch: 1, Loss: 0.6279278273809524 126000/139232 train accuracy:0.6718968152999878
2169it [12:58,  2.84it/s]Epoch: 1, Loss: 0.6352088564918155 130200/139232 train accuracy:0.6742550134658813
2239it [13:23,  2.83it/s]Epoch: 1, Loss: 0.6065435500372024 134400/139232 train accuracy:0.676383912563324
2309it [13:47,  2.84it/s]Epoch: 1, Loss: 0.6422813197544642 138600/139232 train accuracy:0.6779437065124512
2321it [13:59,  2.76it/s]
Epoch: 1, epoch Loss: 96360.5546875  train accuracy:0.6782923340797424

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.16it/s]
Epoch: 1, Valid Loss: 8085.19921875  valid accuracy:0.7882999181747437
find better loss
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:07<00:00,  8.47it/s]
Epoch: 1,   test accuracy:0.7893792986869812
37it [00:13,  2.87it/s]Epoch: 2, Loss: 0.3389757428850446 2280/139232 train accuracy:0.7425438761711121
69it [00:24,  2.86it/s]Epoch: 2, Loss: 0.2936126127697173 4200/139232 train accuracy:0.7402380704879761
139it [00:49,  2.86it/s]Epoch: 2, Loss: 0.6202947707403274 8400/139232 train accuracy:0.7382143139839172
209it [01:13,  2.86it/s]Epoch: 2, Loss: 0.6149340239025297 12600/139232 train accuracy:0.7407143115997314
279it [01:38,  2.86it/s]Epoch: 2, Loss: 0.6153741745721726 16800/139232 train accuracy:0.7391071319580078
349it [02:03,  2.86it/s]Epoch: 2, Loss: 0.6182515462239583 21000/139232 train accuracy:0.7382380962371826
419it [02:27,  2.85it/s]Epoch: 2, Loss: 0.6142447335379464 25200/139232 train accuracy:0.7385714054107666
489it [02:52,  2.85it/s]Epoch: 2, Loss: 0.6209585425967262 29400/139232 train accuracy:0.7386734485626221
559it [03:16,  2.85it/s]Epoch: 2, Loss: 0.5975230771019345 33600/139232 train accuracy:0.7398809790611267
629it [03:41,  2.85it/s]Epoch: 2, Loss: 0.6028093029203869 37800/139232 train accuracy:0.7401852011680603
699it [04:05,  2.85it/s]Epoch: 2, Loss: 0.5859429059709822 42000/139232 train accuracy:0.7416428327560425
769it [04:30,  2.85it/s]Epoch: 2, Loss: 0.6177367001488095 46200/139232 train accuracy:0.741233766078949
839it [04:54,  2.85it/s]Epoch: 2, Loss: 0.6195713588169642 50400/139232 train accuracy:0.7399404644966125
909it [05:19,  2.84it/s]Epoch: 2, Loss: 0.6098844401041666 54600/139232 train accuracy:0.7398900985717773
979it [05:44,  2.85it/s]Epoch: 2, Loss: 0.6079181780133929 58800/139232 train accuracy:0.7397618889808655
1049it [06:08,  2.84it/s]Epoch: 2, Loss: 0.6181879534040179 63000/139232 train accuracy:0.74015873670578
1119it [06:33,  2.85it/s]Epoch: 2, Loss: 0.5957184128534226 67200/139232 train accuracy:0.7403273582458496
1189it [06:57,  2.85it/s]Epoch: 2, Loss: 0.6098380533854166 71400/139232 train accuracy:0.7403221130371094
1259it [07:22,  2.84it/s]Epoch: 2, Loss: 0.5917657761346726 75600/139232 train accuracy:0.7404232621192932
1329it [07:47,  2.84it/s]Epoch: 2, Loss: 0.5986173502604166 79800/139232 train accuracy:0.7405012249946594
1399it [08:12,  2.84it/s]Epoch: 2, Loss: 0.599796375093006 84000/139232 train accuracy:0.7401905059814453
1469it [08:36,  2.85it/s]Epoch: 2, Loss: 0.6198420061383929 88200/139232 train accuracy:0.7400907278060913
1539it [09:01,  2.84it/s]Epoch: 2, Loss: 0.5884617978050595 92400/139232 train accuracy:0.7402272820472717
1609it [09:25,  2.85it/s]Epoch: 2, Loss: 0.5828272646949405 96600/139232 train accuracy:0.7405693531036377
1679it [09:50,  2.85it/s]Epoch: 2, Loss: 0.620296398344494 100800/139232 train accuracy:0.7401091456413269
1749it [10:15,  2.84it/s]Epoch: 2, Loss: 0.5995367140997023 105000/139232 train accuracy:0.7402571439743042
1819it [10:39,  2.85it/s]Epoch: 2, Loss: 0.5858578055245536 109200/139232 train accuracy:0.7401831746101379
1889it [11:04,  2.85it/s]Epoch: 2, Loss: 0.596810302734375 113400/139232 train accuracy:0.7403174638748169
1959it [11:29,  2.85it/s]Epoch: 2, Loss: 0.5773370651971726 117600/139232 train accuracy:0.7407398223876953
2029it [11:53,  2.85it/s]Epoch: 2, Loss: 0.6108517020089286 121800/139232 train accuracy:0.7407717704772949
2099it [12:18,  2.86it/s]Epoch: 2, Loss: 0.5921803501674107 126000/139232 train accuracy:0.7408809661865234
2169it [12:42,  2.85it/s]Epoch: 2, Loss: 0.5885136486235119 130200/139232 train accuracy:0.7408064603805542
2239it [13:07,  2.84it/s]Epoch: 2, Loss: 0.6068917410714286 134400/139232 train accuracy:0.7404389977455139
2309it [13:31,  2.84it/s]Epoch: 2, Loss: 0.5927648344494048 138600/139232 train accuracy:0.7403463125228882
2321it [13:36,  2.84it/s]
Epoch: 2, epoch Loss: 84150.21875  train accuracy:0.7404188513755798

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.20it/s]
Epoch: 2, Valid Loss: 7804.0107421875  valid accuracy:0.7891402840614319
find better loss
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:07<00:00,  8.47it/s]
Epoch: 2,   test accuracy:0.7908174395561218
37it [00:13,  2.85it/s]Epoch: 3, Loss: 0.30702686128162204 2280/139232 train accuracy:0.753947377204895
69it [00:24,  2.85it/s]Epoch: 3, Loss: 0.2739099702380952 4200/139232 train accuracy:0.7473809719085693
139it [00:49,  2.84it/s]Epoch: 3, Loss: 0.5846603538876488 8400/139232 train accuracy:0.7440476417541504
209it [01:14,  2.82it/s]Epoch: 3, Loss: 0.5813799758184524 12600/139232 train accuracy:0.7436507940292358
279it [01:39,  2.85it/s]Epoch: 3, Loss: 0.5885357956659226 16800/139232 train accuracy:0.7455952167510986
349it [02:03,  2.85it/s]Epoch: 3, Loss: 0.5940486072358631 21000/139232 train accuracy:0.7437618970870972
419it [02:28,  2.84it/s]Epoch: 3, Loss: 0.586321033296131 25200/139232 train accuracy:0.7434523701667786
489it [02:53,  2.83it/s]Epoch: 3, Loss: 0.5790146600632441 29400/139232 train accuracy:0.743741512298584
559it [03:17,  2.84it/s]Epoch: 3, Loss: 0.5735037086123512 33600/139232 train accuracy:0.7447916865348816
629it [03:42,  2.83it/s]Epoch: 3, Loss: 0.5965622093563988 37800/139232 train accuracy:0.7446560859680176
699it [04:07,  2.83it/s]Epoch: 3, Loss: 0.5923656063988095 42000/139232 train accuracy:0.7443333268165588
769it [04:31,  2.85it/s]Epoch: 3, Loss: 0.5726635160900297 46200/139232 train accuracy:0.7456926703453064
839it [04:56,  2.83it/s]Epoch: 3, Loss: 0.5962837727864584 50400/139232 train accuracy:0.7451388835906982
909it [05:21,  2.84it/s]Epoch: 3, Loss: 0.5678725469680059 54600/139232 train accuracy:0.7460805773735046
979it [05:45,  2.84it/s]Epoch: 3, Loss: 0.5825324358258929 58800/139232 train accuracy:0.7459353804588318
1008it [05:56,  2.83it/s]^C
Traceback (most recent call last):
  File "/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/train_bert_proto_cascade_add_loss.py", line 550, in <module>
    predictions,  full_distances, protos= ProtoCNN([x_batch, author_batch, topic_batch], training=True)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/training.py", line 557, in __call__
    return super().__call__(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/train_bert_proto_cascade_add_loss.py", line 166, in call
    x = self.embedding(input_ids = x["input_ids"], attention_mask = x["attention_mask"], output_hidden_states =True)[0]
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/training.py", line 557, in __call__
    return super().__call__(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/modeling_tf_utils.py", line 383, in run_call_with_unpacked_inputs
    return func(self, **unpacked_inputs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 1090, in call
    outputs = self.bert(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/modeling_tf_utils.py", line 383, in run_call_with_unpacked_inputs
    return func(self, **unpacked_inputs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 850, in call
    encoder_outputs = self.encoder(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 541, in call
    layer_outputs = layer_module(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 498, in call
    layer_output = self.bert_output(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py", line 419, in call
    hidden_states = self.LayerNorm(inputs=hidden_states + input_tensor)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/engine/base_layer.py", line 1097, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 96, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/keras/layers/normalization/layer_normalization.py", line 296, in call
    outputs = tf.nn.batch_normalization(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py", line 1176, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/nn_impl.py", line 1588, in batch_normalization
    inv = math_ops.rsqrt(variance + variance_epsilon)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py", line 1407, in binary_op_wrapper
    return func(x, y, name=name)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py", line 1176, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py", line 1751, in _add_dispatch
    if not isinstance(y, ops.Tensor) and not isinstance(
  File "/usr/lib/python3.10/abc.py", line 117, in __instancecheck__
    def __instancecheck__(cls, instance):
KeyboardInterrupt

(BERT) xw384@cci-bvm74:/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src$ python train_bert_proto_cascade_add_loss.py
2024-01-01 04:43:51.135968: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perf
ormance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-01 04:43:51.272427: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-01 04:43:51.822945: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such fil
e or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:
2024-01-01 04:43:51.823027: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object fil
e: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:
2024-01-01 04:43:51.823037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the
missing libraries mentioned above are installed properly.
loading data...
data loaded!
loading wgcca embeddings...
wgcca embeddings loaded
topic emb size:  100
Train/Dev split: 139232/15470
2024-01-01 04:43:59.097134: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perf
ormance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-01 04:43:59.217604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22203 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090
, pci bus id: 0000:41:00.0, compute capability: 8.6
2024-01-01 04:43:59.399390: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']
- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForP
reTraining model).
- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassif
ication model).
All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.
2024-01-01 04:44:01.863377: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8700
37it [00:27,  2.86it/s]Epoch: 1, Loss: 0.7035576520647322 2280/139232 train accuracy:0.5175438523292542
69it [00:39,  2.86it/s]Epoch: 1, Loss: 0.5607022530691964 4200/139232 train accuracy:0.5171428322792053
139it [01:03,  2.86it/s]Epoch: 1, Loss: 1.1292408389136905 8400/139232 train accuracy:0.5196428298950195
209it [01:28,  2.85it/s]Epoch: 1, Loss: 1.063635021391369 12600/139232 train accuracy:0.5229365229606628
279it [01:53,  2.84it/s]Epoch: 1, Loss: 0.9916014462425595 16800/139232 train accuracy:0.5266071557998657
349it [02:17,  2.84it/s]Epoch: 1, Loss: 0.9356356375558036 21000/139232 train accuracy:0.5297142863273621
419it [02:42,  2.85it/s]Epoch: 1, Loss: 0.8941356840587797 25200/139232 train accuracy:0.5324206352233887
489it [03:06,  2.85it/s]Epoch: 1, Loss: 0.8410223098028273 29400/139232 train accuracy:0.5372108817100525
559it [03:31,  2.85it/s]Epoch: 1, Loss: 0.785946509951637 33600/139232 train accuracy:0.5437202453613281
629it [03:55,  2.85it/s]Epoch: 1, Loss: 0.7798391578311011 37800/139232 train accuracy:0.549391508102417
699it [04:20,  2.85it/s]Epoch: 1, Loss: 0.7442015438988095 42000/139232 train accuracy:0.555904746055603
769it [04:45,  2.85it/s]Epoch: 1, Loss: 0.7541295224144345 46200/139232 train accuracy:0.5611904859542847
839it [05:09,  2.84it/s]Epoch: 1, Loss: 0.7104600888206846 50400/139232 train accuracy:0.5660912990570068
909it [05:34,  2.84it/s]Epoch: 1, Loss: 0.6940295991443453 54600/139232 train accuracy:0.5717765688896179
979it [05:59,  2.85it/s]Epoch: 1, Loss: 0.6715973191034226 58800/139232 train accuracy:0.5779421925544739
1049it [06:23,  2.84it/s]Epoch: 1, Loss: 0.6717488025483631 63000/139232 train accuracy:0.5836825370788574
1119it [06:48,  2.85it/s]Epoch: 1, Loss: 0.6511838495163691 67200/139232 train accuracy:0.5900148749351501
1189it [07:12,  2.84it/s]Epoch: 1, Loss: 0.6528416806175595 71400/139232 train accuracy:0.5954622030258179
1259it [07:37,  2.84it/s]Epoch: 1, Loss: 0.6547679501488095 75600/139232 train accuracy:0.6009523868560791
1329it [08:02,  2.85it/s]Epoch: 1, Loss: 0.6155512927827381 79800/139232 train accuracy:0.6069548726081848
1399it [08:26,  2.83it/s]Epoch: 1, Loss: 0.6177365838913691 84000/139232 train accuracy:0.6128095388412476
1469it [09:05,  1.45it/s]Epoch: 1, Loss: 0.5940806942894346 88200/139232 train accuracy:0.6184467077255249
1539it [09:37,  2.81it/s]Epoch: 1, Loss: 0.614073486328125 92400/139232 train accuracy:0.6236580014228821
1609it [10:01,  2.85it/s]Epoch: 1, Loss: 0.6171369280133928 96600/139232 train accuracy:0.6284368634223938
1679it [10:26,  2.84it/s]Epoch: 1, Loss: 0.5988469587053571 100800/139232 train accuracy:0.6331150531768799
1749it [10:50,  2.84it/s]Epoch: 1, Loss: 0.5910949125744047 105000/139232 train accuracy:0.6377618908882141
1819it [11:25,  1.46it/s]Epoch: 1, Loss: 0.6117714727492559 109200/139232 train accuracy:0.6420604586601257
1889it [12:00,  2.85it/s]Epoch: 1, Loss: 0.6028379603794642 113400/139232 train accuracy:0.6460229158401489
1959it [12:25,  2.85it/s]Epoch: 1, Loss: 0.6396758161272321 117600/139232 train accuracy:0.6491581797599792
2029it [12:49,  2.85it/s]Epoch: 1, Loss: 0.601852794828869 121800/139232 train accuracy:0.652668297290802
2099it [13:14,  2.84it/s]Epoch: 1, Loss: 0.610909656343006 126000/139232 train accuracy:0.6557857394218445
2169it [13:39,  2.85it/s]Epoch: 1, Loss: 0.6167120651971726 130200/139232 train accuracy:0.6586789488792419
2239it [14:03,  2.81it/s]Epoch: 1, Loss: 0.6143819173177083 134400/139232 train accuracy:0.661703884601593
2309it [14:28,  2.81it/s]Epoch: 1, Loss: 0.6270737420944941 138600/139232 train accuracy:0.6642352342605591
2321it [14:40,  2.63it/s]
Epoch: 1, epoch Loss: 101454.59375  train accuracy:0.6646245121955872

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.12it/s]
Epoch: 1, Valid Loss: 8182.47509765625  valid accuracy:0.7860375046730042
find better loss
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:23<00:00,  7.52it/s]
Epoch: 1,   test accuracy:0.7875235676765442
37it [00:13,  2.87it/s]Epoch: 2, Loss: 0.3244468470982143 2280/139232 train accuracy:0.7521929740905762
69it [00:24,  2.86it/s]Epoch: 2, Loss: 0.28236796061197916 4200/139232 train accuracy:0.7457143068313599
139it [00:49,  2.87it/s]Epoch: 2, Loss: 0.6085489327566964 8400/139232 train accuracy:0.7489285469055176
209it [01:17,  1.47it/s]Epoch: 2, Loss: 0.6159791782924107 12600/139232 train accuracy:0.7484126687049866
279it [01:58,  2.85it/s]Epoch: 2, Loss: 0.611949462890625 16800/139232 train accuracy:0.7485119104385376
349it [02:22,  2.86it/s]Epoch: 2, Loss: 0.5964850725446429 21000/139232 train accuracy:0.7497143149375916
419it [02:47,  2.85it/s]Epoch: 2, Loss: 0.5948017229352679 25200/139232 train accuracy:0.7503571510314941
489it [03:11,  2.85it/s]Epoch: 2, Loss: 0.6011917550223215 29400/139232 train accuracy:0.7509523630142212
559it [03:39,  1.51it/s]Epoch: 2, Loss: 0.593638916015625 33600/139232 train accuracy:0.7512500286102295
629it [04:21,  2.81it/s]Epoch: 2, Loss: 0.5976540992373512 37800/139232 train accuracy:0.7523545026779175
699it [04:49,  1.48it/s]Epoch: 2, Loss: 0.6000521414620535 42000/139232 train accuracy:0.753166675567627
769it [05:30,  2.86it/s]Epoch: 2, Loss: 0.6145259602864583 46200/139232 train accuracy:0.7525973916053772
839it [05:55,  2.80it/s]Epoch: 2, Loss: 0.60773681640625 50400/139232 train accuracy:0.7523015737533569
909it [06:20,  2.84it/s]Epoch: 2, Loss: 0.6141871861049107 54600/139232 train accuracy:0.7513919472694397
979it [06:44,  2.85it/s]Epoch: 2, Loss: 0.6004273042224703 58800/139232 train accuracy:0.7514966130256653
1049it [07:09,  2.84it/s]Epoch: 2, Loss: 0.6104873511904761 63000/139232 train accuracy:0.7509365081787109
1119it [07:34,  2.84it/s]Epoch: 2, Loss: 0.6222689383370535 67200/139232 train accuracy:0.7501785755157471
1189it [07:58,  2.85it/s]Epoch: 2, Loss: 0.6087686011904762 71400/139232 train accuracy:0.7498599290847778
1259it [08:23,  2.84it/s]Epoch: 2, Loss: 0.6007238188244047 75600/139232 train accuracy:0.7496825456619263
1329it [08:47,  2.84it/s]Epoch: 2, Loss: 0.5944016810825893 79800/139232 train accuracy:0.7493483424186707
1399it [09:13,  2.84it/s]Epoch: 2, Loss: 0.5971060035342262 84000/139232 train accuracy:0.7492499947547913
1469it [09:37,  2.84it/s]Epoch: 2, Loss: 0.6090754045758928 88200/139232 train accuracy:0.7488548755645752
1539it [10:02,  2.84it/s]Epoch: 2, Loss: 0.5914016578311012 92400/139232 train accuracy:0.7488203644752502
1609it [10:27,  2.84it/s]Epoch: 2, Loss: 0.5884713890438988 96600/139232 train accuracy:0.7486335635185242
1679it [10:51,  2.83it/s]Epoch: 2, Loss: 0.6109440104166667 100800/139232 train accuracy:0.7480158805847168
1707it [11:01,  2.83it/s]
1749it [11:16,  2.84it/s]Epoch: 2, Loss: 0.6028180222284226 105000/139232 train accuracy:0.7478952407836914
1819it [11:41,  2.84it/s]Epoch: 2, Loss: 0.5889124697730654 109200/139232 train accuracy:0.7476831674575806
1889it [12:05,  2.84it/s]Epoch: 2, Loss: 0.5678263927641369 113400/139232 train accuracy:0.7480158805847168
1959it [12:30,  2.83it/s]Epoch: 2, Loss: 0.5901979282924107 117600/139232 train accuracy:0.7481207251548767
2029it [12:55,  2.85it/s]Epoch: 2, Loss: 0.5927399553571429 121800/139232 train accuracy:0.7479802966117859
2099it [13:19,  2.83it/s]Epoch: 2, Loss: 0.5870263090587797 126000/139232 train accuracy:0.7480714321136475
2128it [13:30,  2.83it/s]
2169it [13:44,  2.83it/s]Epoch: 2, Loss: 0.5815490141369047 130200/139232 train accuracy:0.7479646801948547
2239it [14:09,  2.83it/s]Epoch: 2, Loss: 0.5959451148623512 134400/139232 train accuracy:0.7476562261581421
2309it [14:34,  2.83it/s]Epoch: 2, Loss: 0.5835542224702381 138600/139232 train accuracy:0.7477056384086609
2321it [14:38,  2.64it/s]
Epoch: 2, epoch Loss: 83460.25  train accuracy:0.7477663159370422

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.18it/s]
Epoch: 2, Valid Loss: 7854.31005859375  valid accuracy:0.7863606810569763
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:07<00:00,  8.45it/s]
Epoch: 2,   test accuracy:0.7883895635604858
37it [00:13,  2.84it/s]Epoch: 3, Loss: 0.2981318882533482 2280/139232 train accuracy:0.7543859481811523
69it [00:24,  2.83it/s]Epoch: 3, Loss: 0.2603672572544643 4200/139232 train accuracy:0.7569047808647156
139it [00:49,  2.83it/s]Epoch: 3, Loss: 0.600848156156994 8400/139232 train accuracy:0.7423809766769409
209it [01:14,  2.80it/s]Epoch: 3, Loss: 0.5855598958333333 12600/139232 train accuracy:0.7407936453819275
279it [01:39,  2.84it/s]Epoch: 3, Loss: 0.5888265555245535 16800/139232 train accuracy:0.7412499785423279
326it [01:56,  2.83it/s]^[
349it [02:04,  2.83it/s]Epoch: 3, Loss: 0.5813691638764881 21000/139232 train accuracy:0.7424761652946472
419it [02:29,  2.83it/s]Epoch: 3, Loss: 0.593656005859375 25200/139232 train accuracy:0.7411507964134216
489it [02:53,  2.84it/s]Epoch: 3, Loss: 0.5968636648995536 29400/139232 train accuracy:0.7411224246025085
559it [03:18,  2.84it/s]Epoch: 3, Loss: 0.5822269694010417 33600/139232 train accuracy:0.7417559623718262
629it [03:43,  2.83it/s]Epoch: 3, Loss: 0.5721656436011905 37800/139232 train accuracy:0.742460310459137
699it [04:08,  2.82it/s]Epoch: 3, Loss: 0.593934093656994 42000/139232 train accuracy:0.742976188659668
769it [04:32,  2.83it/s]Epoch: 3, Loss: 0.5947176688058036 46200/139232 train accuracy:0.7425541281700134
839it [04:57,  2.82it/s]Epoch: 3, Loss: 0.5821734328497024 50400/139232 train accuracy:0.7424801588058472
909it [05:22,  2.83it/s]Epoch: 3, Loss: 0.575868908110119 54600/139232 train accuracy:0.7429670095443726
979it [05:47,  2.82it/s]Epoch: 3, Loss: 0.569773181733631 58800/139232 train accuracy:0.7434013485908508
1049it [06:12,  2.82it/s]Epoch: 3, Loss: 0.5953387160528274 63000/139232 train accuracy:0.742904782295227
1119it [06:36,  2.82it/s]Epoch: 3, Loss: 0.6009132021949405 67200/139232 train accuracy:0.7425297498703003
1189it [07:01,  2.83it/s]Epoch: 3, Loss: 0.5686742001488095 71400/139232 train accuracy:0.742955207824707
1259it [07:26,  2.83it/s]Epoch: 3, Loss: 0.5677698335193453 75600/139232 train accuracy:0.7436243295669556
1329it [07:51,  2.82it/s]Epoch: 3, Loss: 0.5848690941220238 79800/139232 train accuracy:0.7431579232215881
1399it [08:16,  2.82it/s]Epoch: 3, Loss: 0.5626657249813988 84000/139232 train accuracy:0.7436428666114807
1469it [08:41,  2.83it/s]Epoch: 3, Loss: 0.5713552129836309 88200/139232 train accuracy:0.7439569234848022
1539it [09:06,  2.82it/s]Epoch: 3, Loss: 0.5795093354724702 92400/139232 train accuracy:0.7442532181739807
1609it [09:30,  2.82it/s]Epoch: 3, Loss: 0.5916130719866072 96600/139232 train accuracy:0.7443685531616211
1679it [09:55,  2.82it/s]Epoch: 3, Loss: 0.5731668526785715 100800/139232 train accuracy:0.744394838809967
1749it [10:20,  2.83it/s]Epoch: 3, Loss: 0.5759787132626488 105000/139232 train accuracy:0.7444761991500854
1819it [10:45,  2.82it/s]Epoch: 3, Loss: 0.5671853492373512 109200/139232 train accuracy:0.744450569152832
1889it [11:09,  2.83it/s]Epoch: 3, Loss: 0.5749406505766369 113400/139232 train accuracy:0.7444091439247131
1959it [11:34,  2.82it/s]Epoch: 3, Loss: 0.5738012114025297 117600/139232 train accuracy:0.7444302439689636
2029it [11:59,  2.82it/s]Epoch: 3, Loss: 0.5722416759672619 121800/139232 train accuracy:0.7444745302200317
2099it [12:24,  2.82it/s]Epoch: 3, Loss: 0.5809011695498512 126000/139232 train accuracy:0.7444603443145752
2169it [12:49,  2.82it/s]Epoch: 3, Loss: 0.5647712053571429 130200/139232 train accuracy:0.7447388768196106
2239it [13:13,  2.82it/s]Epoch: 3, Loss: 0.5675911458333334 134400/139232 train accuracy:0.7449702620506287
2309it [13:38,  2.82it/s]Epoch: 3, Loss: 0.5730119396391369 138600/139232 train accuracy:0.7449855804443359
2321it [13:43,  2.82it/s]
Epoch: 3, epoch Loss: 80667.0  train accuracy:0.7450011372566223

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.18it/s]
Epoch: 3, Valid Loss: 7796.83349609375  valid accuracy:0.7882353067398071
find better loss
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:07<00:00,  8.45it/s]
Epoch: 3,   test accuracy:0.790136992931366
37it [00:13,  2.79it/s]Epoch: 4, Loss: 0.3097915794735863 2280/139232 train accuracy:0.7381578683853149
69it [00:25,  2.85it/s]Epoch: 4, Loss: 0.2495077369326637 4200/139232 train accuracy:0.7495238184928894
139it [00:49,  2.83it/s]Epoch: 4, Loss: 0.576068115234375 8400/139232 train accuracy:0.7472618818283081
209it [01:14,  2.83it/s]Epoch: 4, Loss: 0.5894774809337797 12600/139232 train accuracy:0.7437301874160767
279it [01:39,  2.82it/s]Epoch: 4, Loss: 0.5377989560081845 16800/139232 train accuracy:0.7490476369857788
349it [02:04,  2.81it/s]Epoch: 4, Loss: 0.5746376255580358 21000/139232 train accuracy:0.7485714554786682
419it [02:29,  2.83it/s]Epoch: 4, Loss: 0.5854861886160714 25200/139232 train accuracy:0.7470238208770752
489it [02:53,  2.84it/s]Epoch: 4, Loss: 0.5857903180803572 29400/139232 train accuracy:0.7454761862754822
559it [03:18,  2.84it/s]Epoch: 4, Loss: 0.575492408389137 33600/139232 train accuracy:0.7456547617912292
629it [03:43,  2.84it/s]Epoch: 4, Loss: 0.5633600144159226 37800/139232 train accuracy:0.7460052967071533
699it [04:07,  2.84it/s]Epoch: 4, Loss: 0.5723655482700892 42000/139232 train accuracy:0.7471666932106018
769it [04:32,  2.83it/s]Epoch: 4, Loss: 0.5661736188616071 46200/139232 train accuracy:0.7473593354225159
839it [04:57,  2.82it/s]Epoch: 4, Loss: 0.5517336309523809 50400/139232 train accuracy:0.7486706376075745
909it [05:22,  2.82it/s]Epoch: 4, Loss: 0.5780560593377976 54600/139232 train accuracy:0.7486263513565063
979it [05:47,  2.84it/s]Epoch: 4, Loss: 0.5540777297247024 58800/139232 train accuracy:0.7491326332092285
1049it [06:12,  2.82it/s]Epoch: 4, Loss: 0.5722770763578869 63000/139232 train accuracy:0.7486031651496887
1119it [06:37,  2.80it/s]Epoch: 4, Loss: 0.5620653715587798 67200/139232 train accuracy:0.749419629573822
1189it [07:02,  2.80it/s]Epoch: 4, Loss: 0.5589513578869048 71400/139232 train accuracy:0.7494817972183228
1259it [07:27,  2.83it/s]Epoch: 4, Loss: 0.5536722237723214 75600/139232 train accuracy:0.7497090101242065
1329it [07:52,  2.79it/s]Epoch: 4, Loss: 0.5618318684895833 79800/139232 train accuracy:0.749498724937439
1399it [08:17,  2.81it/s]Epoch: 4, Loss: 0.5574750627790178 84000/139232 train accuracy:0.7498809695243835
1469it [08:42,  2.82it/s]Epoch: 4, Loss: 0.5589561244419643 88200/139232 train accuracy:0.7501133680343628
1539it [09:07,  2.83it/s]Epoch: 4, Loss: 0.5573567127046131 92400/139232 train accuracy:0.7502056360244751
1609it [09:31,  2.84it/s]Epoch: 4, Loss: 0.5448585728236607 96600/139232 train accuracy:0.7507246136665344
1679it [09:56,  2.83it/s]Epoch: 4, Loss: 0.5469757952008929 100800/139232 train accuracy:0.7514682412147522
1749it [10:21,  2.83it/s]Epoch: 4, Loss: 0.5631859770275298 105000/139232 train accuracy:0.7513238191604614
1819it [10:46,  2.84it/s]Epoch: 4, Loss: 0.5511286272321428 109200/139232 train accuracy:0.7515109777450562
1889it [11:10,  2.84it/s]Epoch: 4, Loss: 0.5730529203869048 113400/139232 train accuracy:0.7515255808830261
1959it [11:35,  2.83it/s]Epoch: 4, Loss: 0.5409707496279762 117600/139232 train accuracy:0.751751720905304
2029it [12:00,  2.82it/s]Epoch: 4, Loss: 0.5707584635416667 121800/139232 train accuracy:0.751469612121582
2099it [12:25,  2.82it/s]Epoch: 4, Loss: 0.5772723098028274 126000/139232 train accuracy:0.7510952353477478
2169it [12:50,  2.79it/s]Epoch: 4, Loss: 0.5622735886346726 130200/139232 train accuracy:0.7510906457901001
2239it [13:15,  2.80it/s]Epoch: 4, Loss: 0.5707918294270833 134400/139232 train accuracy:0.7510342001914978
2309it [13:39,  2.81it/s]Epoch: 4, Loss: 0.5416044108072917 138600/139232 train accuracy:0.7512915134429932
2321it [13:44,  2.82it/s]
Epoch: 4, epoch Loss: 78485.28125  train accuracy:0.7511419653892517

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.15it/s]
Epoch: 4, Valid Loss: 7749.0263671875  valid accuracy:0.7889463305473328
find better loss
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:07<00:00,  8.43it/s]
Epoch: 4,   test accuracy:0.7911267280578613
37it [00:13,  2.82it/s]Epoch: 5, Loss: 0.3071710205078125 2280/139232 train accuracy:0.7530701756477356
69it [00:25,  2.82it/s]Epoch: 5, Loss: 0.2571663992745536 4200/139232 train accuracy:0.7483333349227905
139it [00:49,  2.81it/s]Epoch: 5, Loss: 0.5638704427083333 8400/139232 train accuracy:0.7480952143669128
209it [01:15,  2.82it/s]Epoch: 5, Loss: 0.5415166945684524 12600/139232 train accuracy:0.751031756401062
279it [01:40,  2.82it/s]Epoch: 5, Loss: 0.5491271391369048 16800/139232 train accuracy:0.7517856955528259
349it [02:04,  2.81it/s]Epoch: 5, Loss: 0.5527247837611607 21000/139232 train accuracy:0.7522380948066711
419it [02:29,  2.82it/s]Epoch: 5, Loss: 0.5573197428385417 25200/139232 train accuracy:0.7534127235412598
420it [02:30,  2.79it/s]^C
Traceback (most recent call last):
  File "/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/train_bert_proto_cascade_add_loss.py", line 565, in <module>
    gradients = tape.gradient(loss, ProtoCNN.trainable_weights)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py", line 1113, in gradient
    flat_grad = imperative_grad.imperative_grad(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py", line 67, in imperative_grad
    return pywrap_tfe.TFE_Py_TapeGradient(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py", line 130, in _gradient_function
    def _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs,
KeyboardInterrupt
^C
(BERT) xw384@cci-bvm74:/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src$ python train_bert_proto_cascade_add_loss.py
2024-01-01 05:55:10.878467: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perf
ormance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-01 05:55:11.015695: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-01 05:55:11.565454: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such fil
e or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:
2024-01-01 05:55:11.565534: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object fil
e: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:/usr/local/cuda-11.8/lib64:/usr/local/cuda-11.3/lib64:
2024-01-01 05:55:11.565543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the
missing libraries mentioned above are installed properly.
loading data...
data loaded!
loading wgcca embeddings...
wgcca embeddings loaded
topic emb size:  100
Train/Dev split: 139232/15470
2024-01-01 05:55:18.851549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in perf
ormance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-01 05:55:18.964964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22203 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090
, pci bus id: 0000:41:00.0, compute capability: 8.6
2024-01-01 05:55:19.148793: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']
- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForP
reTraining model).
- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassif
ication model).
All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.
2024-01-01 05:55:21.616696: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8700
37it [00:28,  2.85it/s]Epoch: 1, Loss: 0.49789864676339285 2280/139232 train accuracy:0.4934210479259491
69it [00:39,  2.85it/s]Epoch: 1, Loss: 0.420301746186756 4200/139232 train accuracy:0.49119046330451965
139it [01:03,  2.85it/s]Epoch: 1, Loss: 0.8570324125744048 8400/139232 train accuracy:0.5080952644348145
209it [01:28,  2.83it/s]Epoch: 1, Loss: 0.8345927501860119 12600/139232 train accuracy:0.5198412537574768
279it [01:53,  2.83it/s]Epoch: 1, Loss: 0.8052587890625 16800/139232 train accuracy:0.5313690304756165
349it [02:18,  2.84it/s]Epoch: 1, Loss: 0.7858393205915178 21000/139232 train accuracy:0.5423809289932251
419it [02:42,  2.84it/s]Epoch: 1, Loss: 0.7602389671688988 25200/139232 train accuracy:0.5520634651184082
489it [03:07,  2.84it/s]Epoch: 1, Loss: 0.7128997512090773 29400/139232 train accuracy:0.5632312893867493
559it [03:32,  2.83it/s]Epoch: 1, Loss: 0.7161536807105655 33600/139232 train accuracy:0.5723809599876404
629it [03:56,  2.83it/s]Epoch: 1, Loss: 0.6860809035528274 37800/139232 train accuracy:0.5806878209114075
699it [04:21,  2.84it/s]Epoch: 1, Loss: 0.6842202613467262 42000/139232 train accuracy:0.5888809561729431
769it [04:46,  2.82it/s]Epoch: 1, Loss: 0.673707740420387 46200/139232 train accuracy:0.5965584516525269
839it [05:10,  2.84it/s]Epoch: 1, Loss: 0.6666288248697917 50400/139232 train accuracy:0.6032142639160156
909it [05:35,  2.84it/s]Epoch: 1, Loss: 0.6353713262648809 54600/139232 train accuracy:0.6102014780044556
979it [06:00,  2.83it/s]Epoch: 1, Loss: 0.6160305640811012 58800/139232 train accuracy:0.6175000071525574
1049it [06:25,  2.83it/s]Epoch: 1, Loss: 0.6566300455729167 63000/139232 train accuracy:0.6230793595314026
1119it [06:50,  2.82it/s]Epoch: 1, Loss: 0.637257312593006 67200/139232 train accuracy:0.6286607384681702
1189it [07:14,  2.83it/s]Epoch: 1, Loss: 0.6291981143043155 71400/139232 train accuracy:0.6335994601249695
1255it [07:38,  2.83it/s]
1259it [07:39,  2.83it/s]Epoch: 1, Loss: 0.6417992001488095 75600/139232 train accuracy:0.6382407546043396
1329it [08:04,  2.81it/s]Epoch: 1, Loss: 0.6022603934151786 79800/139232 train accuracy:0.6430326104164124
1399it [08:29,  2.82it/s]Epoch: 1, Loss: 0.6060926455543155 84000/139232 train accuracy:0.6475595235824585
1469it [08:54,  2.81it/s]Epoch: 1, Loss: 0.5798392740885416 88200/139232 train accuracy:0.6522449254989624
1539it [09:19,  2.81it/s]Epoch: 1, Loss: 0.5922450474330357 92400/139232 train accuracy:0.6561039090156555
1609it [09:44,  2.81it/s]Epoch: 1, Loss: 0.601539306640625 96600/139232 train accuracy:0.6600724458694458
1679it [10:09,  2.80it/s]Epoch: 1, Loss: 0.5961504255022322 100800/139232 train accuracy:0.6634920835494995
1749it [10:34,  2.82it/s]Epoch: 1, Loss: 0.5892420014880952 105000/139232 train accuracy:0.6665999889373779
1819it [10:59,  2.82it/s]Epoch: 1, Loss: 0.639885021391369 109200/139232 train accuracy:0.6692765355110168
1889it [11:23,  2.82it/s]Epoch: 1, Loss: 0.5972379557291667 113400/139232 train accuracy:0.6719576716423035
1959it [11:48,  2.83it/s]Epoch: 1, Loss: 0.6118640718005952 117600/139232 train accuracy:0.6742516756057739
2029it [12:13,  2.83it/s]Epoch: 1, Loss: 0.5980882045200893 121800/139232 train accuracy:0.6767487525939941
2099it [12:38,  2.82it/s]Epoch: 1, Loss: 0.6044502766927083 126000/139232 train accuracy:0.6788968443870544
2169it [13:03,  2.83it/s]Epoch: 1, Loss: 0.5938575962611607 130200/139232 train accuracy:0.681029200553894
2239it [13:27,  2.82it/s]Epoch: 1, Loss: 0.5841140601748512 134400/139232 train accuracy:0.6831770539283752
2309it [13:52,  2.83it/s]Epoch: 1, Loss: 0.6072513834635417 138600/139232 train accuracy:0.6845526695251465
2321it [14:04,  2.75it/s]
Epoch: 1, epoch Loss: 92450.7265625  train accuracy:0.6848282217979431

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.12it/s]
Epoch: 1, Valid Loss: 7947.3154296875  valid accuracy:0.7861021161079407
find better loss
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:07<00:00,  8.43it/s]
Epoch: 1,   test accuracy:0.7871833443641663
37it [00:13,  2.86it/s]Epoch: 2, Loss: 0.3160429164341518 2280/139232 train accuracy:0.7412280440330505
69it [00:24,  2.85it/s]Epoch: 2, Loss: 0.27100888206845236 4200/139232 train accuracy:0.7421428561210632
139it [00:49,  2.85it/s]Epoch: 2, Loss: 0.59273193359375 8400/139232 train accuracy:0.7434523701667786
209it [01:13,  2.85it/s]Epoch: 2, Loss: 0.6086812337239583 12600/139232 train accuracy:0.7415079474449158
279it [01:38,  2.84it/s]Epoch: 2, Loss: 0.5924593680245536 16800/139232 train accuracy:0.7408333420753479
349it [02:03,  2.83it/s]Epoch: 2, Loss: 0.5868715122767857 21000/139232 train accuracy:0.7419047355651855
419it [02:28,  2.84it/s]Epoch: 2, Loss: 0.5928228469122023 25200/139232 train accuracy:0.7441269755363464
489it [02:52,  2.84it/s]Epoch: 2, Loss: 0.5741878836495535 29400/139232 train accuracy:0.7449659705162048
559it [03:17,  2.84it/s]Epoch: 2, Loss: 0.5767300269717262 33600/139232 train accuracy:0.7462499737739563
629it [03:42,  2.82it/s]Epoch: 2, Loss: 0.5721125720796131 37800/139232 train accuracy:0.747592568397522
699it [04:07,  2.84it/s]Epoch: 2, Loss: 0.577043689546131 42000/139232 train accuracy:0.7486666440963745
769it [04:31,  2.84it/s]Epoch: 2, Loss: 0.5989073544456845 46200/139232 train accuracy:0.748354971408844
839it [04:56,  2.83it/s]Epoch: 2, Loss: 0.5884370930989583 50400/139232 train accuracy:0.748630940914154
909it [05:21,  2.82it/s]Epoch: 2, Loss: 0.584442138671875 54600/139232 train accuracy:0.7489743828773499
979it [05:46,  2.83it/s]Epoch: 2, Loss: 0.5847605678013393 58800/139232 train accuracy:0.749217689037323
1049it [06:10,  2.83it/s]Epoch: 2, Loss: 0.5956216866629465 63000/139232 train accuracy:0.7489206194877625
1119it [06:35,  2.83it/s]Epoch: 2, Loss: 0.5821497163318452 67200/139232 train accuracy:0.7488690614700317
1189it [07:00,  2.84it/s]Epoch: 2, Loss: 0.5764311872209822 71400/139232 train accuracy:0.7486834526062012
1259it [07:24,  2.83it/s]Epoch: 2, Loss: 0.5822025553385417 75600/139232 train accuracy:0.7485185265541077
1329it [07:49,  2.83it/s]Epoch: 2, Loss: 0.5853193591889881 79800/139232 train accuracy:0.7482957243919373
1399it [08:14,  2.82it/s]Epoch: 2, Loss: 0.567943115234375 84000/139232 train accuracy:0.7482976317405701
1469it [08:39,  2.84it/s]Epoch: 2, Loss: 0.5933621651785714 88200/139232 train accuracy:0.7478571534156799
1539it [09:04,  2.80it/s]Epoch: 2, Loss: 0.5543715122767857 92400/139232 train accuracy:0.747965395450592
1609it [09:29,  2.83it/s]Epoch: 2, Loss: 0.5545174734933036 96600/139232 train accuracy:0.7480849027633667
1679it [09:53,  2.83it/s]Epoch: 2, Loss: 0.5858791968936012 100800/139232 train accuracy:0.7478868961334229
1749it [10:18,  2.84it/s]Epoch: 2, Loss: 0.5719782366071429 105000/139232 train accuracy:0.7477428317070007
1819it [10:43,  2.83it/s]Epoch: 2, Loss: 0.5655235072544643 109200/139232 train accuracy:0.7478204965591431
1889it [11:08,  2.82it/s]Epoch: 2, Loss: 0.5674693080357143 113400/139232 train accuracy:0.7480247020721436
1959it [11:32,  2.82it/s]Epoch: 2, Loss: 0.5517559523809524 117600/139232 train accuracy:0.7482993006706238
2029it [11:57,  2.83it/s]Epoch: 2, Loss: 0.5996171061197917 121800/139232 train accuracy:0.7480542063713074
2099it [12:22,  2.83it/s]Epoch: 2, Loss: 0.565035400390625 126000/139232 train accuracy:0.7478253841400146
2169it [12:47,  2.83it/s]Epoch: 2, Loss: 0.5675527808779762 130200/139232 train accuracy:0.7480414509773254
2239it [13:11,  2.83it/s]Epoch: 2, Loss: 0.5590382603236607 134400/139232 train accuracy:0.7482068538665771
2309it [13:36,  2.84it/s]Epoch: 2, Loss: 0.5539613560267858 138600/139232 train accuracy:0.7484054565429688
2321it [13:40,  2.83it/s]
Epoch: 2, epoch Loss: 80563.46875  train accuracy:0.7483839988708496

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.15it/s]
Epoch: 2, Valid Loss: 7723.37353515625  valid accuracy:0.7887524366378784
find better loss
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:08<00:00,  8.41it/s]
Epoch: 2,   test accuracy:0.7904308438301086
37it [00:13,  2.83it/s]Epoch: 3, Loss: 0.2857293991815476 2280/139232 train accuracy:0.7736842036247253
69it [00:25,  2.83it/s]Epoch: 3, Loss: 0.25569399879092264 4200/139232 train accuracy:0.7690476179122925
139it [00:49,  2.83it/s]Epoch: 3, Loss: 0.5622403971354166 8400/139232 train accuracy:0.7607142925262451
209it [01:14,  2.80it/s]Epoch: 3, Loss: 0.566005626860119 12600/139232 train accuracy:0.754444420337677
279it [01:39,  2.82it/s]Epoch: 3, Loss: 0.5524390229724703 16800/139232 train accuracy:0.7556547522544861
349it [02:04,  2.82it/s]Epoch: 3, Loss: 0.549267810639881 21000/139232 train accuracy:0.7556190490722656
419it [02:29,  2.82it/s]Epoch: 3, Loss: 0.5671048990885417 25200/139232 train accuracy:0.753928542137146
489it [02:54,  2.83it/s]Epoch: 3, Loss: 0.5601002720424108 29400/139232 train accuracy:0.7532992959022522
559it [03:18,  2.83it/s]Epoch: 3, Loss: 0.5494373139880953 33600/139232 train accuracy:0.7535714507102966
629it [03:43,  2.82it/s]Epoch: 3, Loss: 0.5533718726748512 37800/139232 train accuracy:0.7533068656921387
699it [04:08,  2.83it/s]Epoch: 3, Loss: 0.5576854306175595 42000/139232 train accuracy:0.7531190514564514
769it [04:33,  2.82it/s]Epoch: 3, Loss: 0.5561947777157739 46200/139232 train accuracy:0.7531169056892395
839it [04:58,  2.83it/s]Epoch: 3, Loss: 0.5709740048363096 50400/139232 train accuracy:0.7533134818077087
909it [05:23,  2.83it/s]Epoch: 3, Loss: 0.5405147879464286 54600/139232 train accuracy:0.7537362575531006
979it [05:47,  2.82it/s]Epoch: 3, Loss: 0.5413581775483631 58800/139232 train accuracy:0.753894567489624
1049it [06:12,  2.81it/s]Epoch: 3, Loss: 0.5594680640811012 63000/139232 train accuracy:0.7537936568260193
1119it [06:37,  2.80it/s]Epoch: 3, Loss: 0.5637645903087798 67200/139232 train accuracy:0.7530059814453125
1189it [07:02,  2.82it/s]Epoch: 3, Loss: 0.5497596958705357 71400/139232 train accuracy:0.7530952095985413
1259it [07:27,  2.81it/s]Epoch: 3, Loss: 0.5300147646949405 75600/139232 train accuracy:0.7535582184791565
1329it [07:52,  2.83it/s]Epoch: 3, Loss: 0.5500384230840774 79800/139232 train accuracy:0.7532330751419067
1399it [08:17,  2.82it/s]Epoch: 3, Loss: 0.5534510439918154 84000/139232 train accuracy:0.7534047365188599
1469it [08:42,  2.81it/s]Epoch: 3, Loss: 0.5335135323660715 88200/139232 train accuracy:0.7536961436271667
1539it [09:07,  2.82it/s]Epoch: 3, Loss: 0.5313511439732143 92400/139232 train accuracy:0.7538744807243347
1609it [09:31,  2.81it/s]Epoch: 3, Loss: 0.5583503650483631 96600/139232 train accuracy:0.7538923621177673
1679it [09:56,  2.81it/s]Epoch: 3, Loss: 0.5394667271205357 100800/139232 train accuracy:0.7543253898620605
1749it [10:21,  2.82it/s]Epoch: 3, Loss: 0.5331407528831845 105000/139232 train accuracy:0.7545333504676819
1819it [10:46,  2.82it/s]Epoch: 3, Loss: 0.5302932593936012 109200/139232 train accuracy:0.754899263381958
1889it [11:11,  2.83it/s]Epoch: 3, Loss: 0.5475703357514881 113400/139232 train accuracy:0.7547971606254578
1959it [11:36,  2.82it/s]Epoch: 3, Loss: 0.5435709635416667 117600/139232 train accuracy:0.7549830079078674
2014it [11:55,  2.82it/s]

2029it [12:00,  2.80it/s]Epoch: 3, Loss: 0.5309219796316964 121800/139232 train accuracy:0.7551805973052979
2064it [12:13,  2.81it/s]
2099it [12:25,  2.81it/s]Epoch: 3, Loss: 0.55328125 126000/139232 train accuracy:0.7549841403961182
2169it [12:50,  2.82it/s]Epoch: 3, Loss: 0.5221017601376489 130200/139232 train accuracy:0.7551152110099792
2239it [13:15,  2.82it/s]Epoch: 3, Loss: 0.5255572219122023 134400/139232 train accuracy:0.7555282711982727
2309it [13:40,  2.81it/s]Epoch: 3, Loss: 0.5307270159040178 138600/139232 train accuracy:0.7555050253868103
2321it [13:44,  2.81it/s]
Epoch: 3, epoch Loss: 76149.84375  train accuracy:0.7555087804794312

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.13it/s]
Epoch: 3, Valid Loss: 7507.029296875  valid accuracy:0.7900452613830566
find better loss
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:08<00:00,  8.41it/s]
Epoch: 3,   test accuracy:0.791204035282135
37it [00:13,  2.81it/s]Epoch: 4, Loss: 0.29856863839285713 2280/139232 train accuracy:0.7530701756477356
69it [00:25,  2.83it/s]Epoch: 4, Loss: 0.2377891322544643 4200/139232 train accuracy:0.760952353477478
139it [00:49,  2.82it/s]Epoch: 4, Loss: 0.5302823311941964 8400/139232 train accuracy:0.7636904716491699
209it [01:15,  2.80it/s]Epoch: 4, Loss: 0.5467498488653274 12600/139232 train accuracy:0.7623015642166138
279it [01:40,  2.81it/s]Epoch: 4, Loss: 0.5225964936755952 16800/139232 train accuracy:0.7651190757751465
349it [02:05,  2.81it/s]Epoch: 4, Loss: 0.5324474516369048 21000/139232 train accuracy:0.764380931854248
419it [02:30,  2.81it/s]Epoch: 4, Loss: 0.5542674618675595 25200/139232 train accuracy:0.7620238065719604
489it [02:54,  2.82it/s]Epoch: 4, Loss: 0.5392170061383929 29400/139232 train accuracy:0.7608843445777893
559it [03:19,  2.81it/s]Epoch: 4, Loss: 0.535989002046131 33600/139232 train accuracy:0.760535717010498
629it [03:44,  2.81it/s]Epoch: 4, Loss: 0.5158537365141369 37800/139232 train accuracy:0.7616137862205505
699it [04:09,  2.82it/s]Epoch: 4, Loss: 0.5304033551897321 42000/139232 train accuracy:0.7612380981445312
769it [04:34,  2.81it/s]Epoch: 4, Loss: 0.5269556245349702 46200/139232 train accuracy:0.7620129585266113
839it [04:59,  2.81it/s]Epoch: 4, Loss: 0.5134456380208333 50400/139232 train accuracy:0.7633730173110962
909it [05:24,  2.80it/s]Epoch: 4, Loss: 0.5265204729352678 54600/139232 train accuracy:0.7641575336456299
979it [05:49,  2.82it/s]Epoch: 4, Loss: 0.5121307082403274 58800/139232 train accuracy:0.7645748257637024
1049it [06:14,  2.81it/s]Epoch: 4, Loss: 0.5366676548549107 63000/139232 train accuracy:0.7639047503471375
1119it [06:39,  2.81it/s]Epoch: 4, Loss: 0.5110532924107143 67200/139232 train accuracy:0.7646130919456482
1189it [07:03,  2.81it/s]Epoch: 4, Loss: 0.513709716796875 71400/139232 train accuracy:0.7649019360542297
1259it [07:28,  2.81it/s]Epoch: 4, Loss: 0.5154771786644345 75600/139232 train accuracy:0.7648147940635681
1329it [07:53,  2.81it/s]Epoch: 4, Loss: 0.5275015694754465 79800/139232 train accuracy:0.764786958694458
1399it [08:19,  2.81it/s]Epoch: 4, Loss: 0.5077337355840774 84000/139232 train accuracy:0.7650476098060608
1469it [08:44,  2.81it/s]Epoch: 4, Loss: 0.5175305757068452 88200/139232 train accuracy:0.7653061151504517
1539it [09:08,  2.81it/s]Epoch: 4, Loss: 0.5109730166480655 92400/139232 train accuracy:0.7654653787612915
1609it [09:33,  2.81it/s]Epoch: 4, Loss: 0.48630975632440476 96600/139232 train accuracy:0.7667598128318787
1679it [09:58,  2.80it/s]Epoch: 4, Loss: 0.5025208100818452 100800/139232 train accuracy:0.767380952835083
1749it [10:23,  2.81it/s]Epoch: 4, Loss: 0.5128943452380952 105000/139232 train accuracy:0.7677618861198425
1819it [10:48,  2.81it/s]Epoch: 4, Loss: 0.5045576985677084 109200/139232 train accuracy:0.7682600617408752
1889it [11:13,  2.81it/s]Epoch: 4, Loss: 0.5145490373883929 113400/139232 train accuracy:0.7682804465293884
1959it [11:38,  2.82it/s]Epoch: 4, Loss: 0.4898302060081845 117600/139232 train accuracy:0.7688520550727844
2029it [12:03,  2.81it/s]Epoch: 4, Loss: 0.519480968656994 121800/139232 train accuracy:0.7686617374420166
2099it [12:28,  2.81it/s]Epoch: 4, Loss: 0.5222881208147322 126000/139232 train accuracy:0.7685714364051819
2169it [12:53,  2.80it/s]Epoch: 4, Loss: 0.5109495907738095 130200/139232 train accuracy:0.768855631351471
2239it [13:18,  2.82it/s]Epoch: 4, Loss: 0.5132517787388393 134400/139232 train accuracy:0.7686383724212646
2309it [13:42,  2.82it/s]Epoch: 4, Loss: 0.4926365443638393 138600/139232 train accuracy:0.7689971327781677
2321it [13:47,  2.81it/s]
Epoch: 4, epoch Loss: 72293.9765625  train accuracy:0.7689683437347412

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:31<00:00,  8.16it/s]
Epoch: 4, Valid Loss: 7235.91748046875  valid accuracy:0.7904977202415466
find better loss
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/1078 [02:08<00:00,  8.40it/s]
Epoch: 4,   test accuracy:0.791776180267334
37it [00:13,  2.80it/s]Epoch: 5, Loss: 0.2624809919084821 2280/139232 train accuracy:0.780701756477356
69it [00:25,  2.81it/s]Epoch: 5, Loss: 0.23048495338076636 4200/139232 train accuracy:0.7776190638542175
139it [00:50,  2.81it/s]Epoch: 5, Loss: 0.5168248349144345 8400/139232 train accuracy:0.7734524011611938
209it [01:15,  2.81it/s]Epoch: 5, Loss: 0.4923148600260417 12600/139232 train accuracy:0.7756349444389343
279it [01:40,  2.83it/s]Epoch: 5, Loss: 0.5111294991629465 16800/139232 train accuracy:0.7755952477455139
349it [02:05,  2.82it/s]Epoch: 5, Loss: 0.49878609793526785 21000/139232 train accuracy:0.7759523987770081
419it [02:30,  2.81it/s]Epoch: 5, Loss: 0.5038887532552083 25200/139232 train accuracy:0.7769444584846497
489it [02:54,  2.81it/s]Epoch: 5, Loss: 0.5008147902715774 29400/139232 train accuracy:0.7772789001464844
559it [03:19,  2.82it/s]Epoch: 5, Loss: 0.4830938139415923 33600/139232 train accuracy:0.7785714268684387
629it [03:44,  2.81it/s]Epoch: 5, Loss: 0.5001087588355655 37800/139232 train accuracy:0.7780423164367676
699it [04:09,  2.81it/s]Epoch: 5, Loss: 0.489521251860119 42000/139232 train accuracy:0.7777618765830994
769it [04:34,  2.80it/s]Epoch: 5, Loss: 0.47337024507068454 46200/139232 train accuracy:0.7788960933685303
839it [04:59,  2.81it/s]Epoch: 5, Loss: 0.4889111328125 50400/139232 train accuracy:0.7784523963928223
909it [05:24,  2.82it/s]Epoch: 5, Loss: 0.49347749255952383 54600/139232 train accuracy:0.7789193987846375
979it [05:49,  2.81it/s]Epoch: 5, Loss: 0.5052601841517858 58800/139232 train accuracy:0.7787755131721497
1049it [06:14,  2.80it/s]Epoch: 5, Loss: 0.49776559012276783 63000/139232 train accuracy:0.7788730263710022
1119it [06:39,  2.81it/s]Epoch: 5, Loss: 0.4881816755022321 67200/139232 train accuracy:0.7790922522544861
1189it [07:04,  2.80it/s]Epoch: 5, Loss: 0.5131549362909226 71400/139232 train accuracy:0.7783753275871277
1259it [07:29,  2.81it/s]Epoch: 5, Loss: 0.5093282645089285 75600/139232 train accuracy:0.7779629826545715
1329it [07:54,  2.81it/s]Epoch: 5, Loss: 0.4966103980654762 79800/139232 train accuracy:0.7776190638542175
1399it [08:19,  2.79it/s]Epoch: 5, Loss: 0.5004350353422619 84000/139232 train accuracy:0.7772619128227234
1469it [08:44,  2.82it/s]Epoch: 5, Loss: 0.5084763881138393 88200/139232 train accuracy:0.7767347097396851
1539it [09:09,  2.82it/s]Epoch: 5, Loss: 0.49177222842261903 92400/139232 train accuracy:0.7769263982772827
1609it [09:34,  2.81it/s]Epoch: 5, Loss: 0.49825340634300597 96600/139232 train accuracy:0.7768840789794922
1679it [09:59,  2.81it/s]Epoch: 5, Loss: 0.4845518566313244 100800/139232 train accuracy:0.7770337462425232
1749it [10:24,  2.81it/s]Epoch: 5, Loss: 0.5011451939174107 105000/139232 train accuracy:0.7771809697151184
1819it [10:49,  2.81it/s]Epoch: 5, Loss: 0.48883882068452383 109200/139232 train accuracy:0.7773443460464478
1889it [11:14,  2.81it/s]Epoch: 5, Loss: 0.4935657319568452 113400/139232 train accuracy:0.7776807546615601
1959it [11:38,  2.81it/s]Epoch: 5, Loss: 0.4971162341889881 117600/139232 train accuracy:0.7778316140174866
2029it [12:03,  2.82it/s]Epoch: 5, Loss: 0.4993458193824405 121800/139232 train accuracy:0.7777339816093445
2099it [12:28,  2.81it/s]Epoch: 5, Loss: 0.5028347051711309 126000/139232 train accuracy:0.7772936224937439
2169it [12:53,  2.80it/s]Epoch: 5, Loss: 0.4938046409970238 130200/139232 train accuracy:0.7771812677383423
2239it [13:18,  2.81it/s]Epoch: 5, Loss: 0.5003889392671131 134400/139232 train accuracy:0.7768378257751465
2309it [13:43,  2.80it/s]Epoch: 5, Loss: 0.4779611060732887 138600/139232 train accuracy:0.7770707011222839
2321it [13:47,  2.80it/s]
Epoch: 5, epoch Loss: 69189.875  train accuracy:0.7769693732261658

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.14it/s]
Epoch: 5, Valid Loss: 7053.66015625  valid accuracy:0.791661262512207
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.41it/s]
Epoch: 5,   test accuracy:0.7928277850151062
37it [00:13,  2.81it/s]Epoch: 6, Loss: 0.26196722121465776 2280/139232 train accuracy:0.7780701518058777
69it [00:25,  2.82it/s]Epoch: 6, Loss: 0.22327282133556547 4200/139232 train accuracy:0.7830952405929565
139it [00:50,  2.80it/s]Epoch: 6, Loss: 0.4815753173828125 8400/139232 train accuracy:0.7855952382087708
209it [01:15,  2.82it/s]Epoch: 6, Loss: 0.4906738862537202 12600/139232 train accuracy:0.7850000262260437
279it [01:40,  2.81it/s]Epoch: 6, Loss: 0.48434317452566966 16800/139232 train accuracy:0.7839285731315613
349it [02:05,  2.82it/s]Epoch: 6, Loss: 0.48415820893787204 21000/139232 train accuracy:0.7837619185447693
419it [02:29,  2.82it/s]Epoch: 6, Loss: 0.49177065894717265 25200/139232 train accuracy:0.7823016047477722
489it [02:54,  2.82it/s]Epoch: 6, Loss: 0.48570533389136905 29400/139232 train accuracy:0.7814285755157471
559it [03:19,  2.79it/s]Epoch: 6, Loss: 0.48957589285714287 33600/139232 train accuracy:0.7806249856948853
629it [03:44,  2.81it/s]Epoch: 6, Loss: 0.4922857375372024 37800/139232 train accuracy:0.7794973254203796
699it [04:09,  2.82it/s]Epoch: 6, Loss: 0.47126743861607145 42000/139232 train accuracy:0.7801666855812073
769it [04:34,  2.81it/s]Epoch: 6, Loss: 0.4806760951450893 46200/139232 train accuracy:0.780779242515564
839it [04:59,  2.81it/s]Epoch: 6, Loss: 0.4729132080078125 50400/139232 train accuracy:0.7809722423553467
909it [05:24,  2.82it/s]Epoch: 6, Loss: 0.480248296828497 54600/139232 train accuracy:0.7808241844177246
979it [05:49,  2.82it/s]Epoch: 6, Loss: 0.47639439174107145 58800/139232 train accuracy:0.7809013724327087
1049it [06:14,  2.78it/s]Epoch: 6, Loss: 0.4737191336495536 63000/139232 train accuracy:0.7810476422309875
1119it [06:39,  2.79it/s]Epoch: 6, Loss: 0.4689717029389881 67200/139232 train accuracy:0.7812202572822571
1189it [07:04,  2.82it/s]Epoch: 6, Loss: 0.4891740490141369 71400/139232 train accuracy:0.7809944152832031
1259it [07:29,  2.81it/s]Epoch: 6, Loss: 0.4738081287202381 75600/139232 train accuracy:0.7812830805778503
1329it [07:54,  2.79it/s]Epoch: 6, Loss: 0.4885287620907738 79800/139232 train accuracy:0.781378448009491
1399it [08:19,  2.82it/s]Epoch: 6, Loss: 0.46875581287202384 84000/139232 train accuracy:0.781761884689331
1469it [08:44,  2.78it/s]Epoch: 6, Loss: 0.47557149251302083 88200/139232 train accuracy:0.7823469638824463
1539it [09:09,  2.82it/s]Epoch: 6, Loss: 0.48589846656436014 92400/139232 train accuracy:0.7820346355438232
1609it [09:34,  2.81it/s]Epoch: 6, Loss: 0.4784184047154018 96600/139232 train accuracy:0.7824016809463501
1679it [09:59,  2.78it/s]Epoch: 6, Loss: 0.4720755150204613 100800/139232 train accuracy:0.7828273773193359
1749it [10:24,  2.78it/s]Epoch: 6, Loss: 0.4876491001674107 105000/139232 train accuracy:0.7826666831970215
1819it [10:49,  2.81it/s]Epoch: 6, Loss: 0.4634410458519345 109200/139232 train accuracy:0.7830585837364197
1889it [11:14,  2.79it/s]Epoch: 6, Loss: 0.48163492838541666 113400/139232 train accuracy:0.7829541563987732
1959it [11:39,  2.82it/s]Epoch: 6, Loss: 0.4675016566685268 117600/139232 train accuracy:0.7830612063407898
2029it [12:04,  2.80it/s]Epoch: 6, Loss: 0.47383754185267857 121800/139232 train accuracy:0.783169150352478
2099it [12:29,  2.82it/s]Epoch: 6, Loss: 0.47845482235863096 126000/139232 train accuracy:0.783301591873169
2169it [12:54,  2.82it/s]Epoch: 6, Loss: 0.4807564290364583 130200/139232 train accuracy:0.7831259369850159
2239it [13:19,  2.82it/s]Epoch: 6, Loss: 0.4768592761811756 134400/139232 train accuracy:0.7830952405929565
2309it [13:43,  2.82it/s]Epoch: 6, Loss: 0.47075279599144343 138600/139232 train accuracy:0.7831818461418152
2321it [13:48,  2.80it/s]
Epoch: 6, epoch Loss: 66753.953125  train accuracy:0.7831532955169678

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.14it/s]
Epoch: 6, Valid Loss: 6933.9482421875  valid accuracy:0.7935358881950378
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.40it/s]
Epoch: 6,   test accuracy:0.7945906519889832
37it [00:14,  2.28it/s]Epoch: 7, Loss: 0.2680785260881696 2280/139232 train accuracy:0.7736842036247253
69it [00:25,  2.80it/s]Epoch: 7, Loss: 0.22349712553478424 4200/139232 train accuracy:0.7716666460037231
139it [00:50,  2.80it/s]Epoch: 7, Loss: 0.4756089855375744 8400/139232 train accuracy:0.7766666412353516
209it [01:15,  2.81it/s]Epoch: 7, Loss: 0.46596153622581843 12600/139232 train accuracy:0.7795237898826599
279it [01:40,  2.80it/s]Epoch: 7, Loss: 0.46388448079427086 16800/139232 train accuracy:0.7829762101173401
349it [02:05,  2.80it/s]Epoch: 7, Loss: 0.47162920270647324 21000/139232 train accuracy:0.7829523682594299
419it [02:30,  2.81it/s]Epoch: 7, Loss: 0.4619169108072917 25200/139232 train accuracy:0.7828571200370789
489it [02:55,  2.81it/s]Epoch: 7, Loss: 0.47703421456473216 29400/139232 train accuracy:0.7825170159339905
559it [03:20,  2.81it/s]Epoch: 7, Loss: 0.4815507289341518 33600/139232 train accuracy:0.7816666960716248
629it [03:45,  2.81it/s]Epoch: 7, Loss: 0.49135806129092263 37800/139232 train accuracy:0.7810317277908325
699it [04:10,  2.82it/s]Epoch: 7, Loss: 0.48814505440848216 42000/139232 train accuracy:0.7801666855812073
769it [04:35,  2.80it/s]Epoch: 7, Loss: 0.44198053269159226 46200/139232 train accuracy:0.7811471819877625
839it [04:59,  2.80it/s]Epoch: 7, Loss: 0.4597561790829613 50400/139232 train accuracy:0.7820436358451843
909it [05:24,  2.81it/s]Epoch: 7, Loss: 0.4690742420014881 54600/139232 train accuracy:0.7823259830474854
979it [05:49,  2.80it/s]Epoch: 7, Loss: 0.467000732421875 58800/139232 train accuracy:0.7827040553092957
1049it [06:14,  2.81it/s]Epoch: 7, Loss: 0.47308826264880954 63000/139232 train accuracy:0.7829841375350952
1119it [06:39,  2.81it/s]Epoch: 7, Loss: 0.4596165248325893 67200/139232 train accuracy:0.7836011648178101
1189it [07:04,  2.80it/s]Epoch: 7, Loss: 0.4643905203683036 71400/139232 train accuracy:0.7837955355644226
1259it [07:30,  2.82it/s]Epoch: 7, Loss: 0.4697811163039435 75600/139232 train accuracy:0.7838360071182251
1329it [07:54,  2.81it/s]Epoch: 7, Loss: 0.46953639439174105 79800/139232 train accuracy:0.7842355966567993
1399it [08:19,  2.81it/s]Epoch: 7, Loss: 0.45738194056919645 84000/139232 train accuracy:0.7845714092254639
1469it [08:44,  2.81it/s]Epoch: 7, Loss: 0.4637791806175595 88200/139232 train accuracy:0.7848526239395142
1539it [09:09,  2.78it/s]Epoch: 7, Loss: 0.4666287086123512 92400/139232 train accuracy:0.7853354811668396
1609it [09:34,  2.80it/s]Epoch: 7, Loss: 0.4615790085565476 96600/139232 train accuracy:0.7854037284851074
1679it [09:59,  2.81it/s]Epoch: 7, Loss: 0.475518798828125 100800/139232 train accuracy:0.7854563593864441
1749it [10:24,  2.80it/s]Epoch: 7, Loss: 0.4645745849609375 105000/139232 train accuracy:0.7855333089828491
1819it [10:49,  2.80it/s]Epoch: 7, Loss: 0.47638006301153274 109200/139232 train accuracy:0.7853571176528931
1889it [11:14,  2.81it/s]Epoch: 7, Loss: 0.4617374965122768 113400/139232 train accuracy:0.7854056358337402
1959it [11:39,  2.81it/s]Epoch: 7, Loss: 0.45569333031063985 117600/139232 train accuracy:0.7857823371887207
2029it [12:04,  2.79it/s]Epoch: 7, Loss: 0.47058122907366073 121800/139232 train accuracy:0.7858292460441589
2099it [12:29,  2.80it/s]Epoch: 7, Loss: 0.46241995675223213 126000/139232 train accuracy:0.7861825227737427
2169it [12:54,  2.80it/s]Epoch: 7, Loss: 0.47706781296502976 130200/139232 train accuracy:0.7861290574073792
2239it [13:19,  2.80it/s]Epoch: 7, Loss: 0.4716019984654018 134400/139232 train accuracy:0.7860119342803955
2309it [13:44,  2.81it/s]Epoch: 7, Loss: 0.46304254441034226 138600/139232 train accuracy:0.7859740257263184
2321it [13:48,  2.80it/s]
Epoch: 7, epoch Loss: 65273.1953125  train accuracy:0.7859687209129333

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.11it/s]
Epoch: 7, Valid Loss: 6869.66748046875  valid accuracy:0.7952165603637695
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.38it/s]
Epoch: 7,   test accuracy:0.797250509262085
37it [00:14,  2.81it/s]Epoch: 8, Loss: 0.2481874011811756 2280/139232 train accuracy:0.8008772134780884
69it [00:25,  2.80it/s]Epoch: 8, Loss: 0.21108790806361608 4200/139232 train accuracy:0.7959523797035217
139it [00:50,  2.80it/s]Epoch: 8, Loss: 0.4497579520089286 8400/139232 train accuracy:0.7961905002593994
209it [01:15,  2.80it/s]Epoch: 8, Loss: 0.4697090076264881 12600/139232 train accuracy:0.791190505027771
279it [01:40,  2.79it/s]Epoch: 8, Loss: 0.4566820998418899 16800/139232 train accuracy:0.7914285659790039
349it [02:05,  2.81it/s]Epoch: 8, Loss: 0.4694404529389881 21000/139232 train accuracy:0.7903333306312561
419it [02:30,  2.82it/s]Epoch: 8, Loss: 0.4465255591982887 25200/139232 train accuracy:0.789642870426178
489it [02:55,  2.80it/s]Epoch: 8, Loss: 0.4731083461216518 29400/139232 train accuracy:0.7896258234977722
559it [03:20,  2.81it/s]Epoch: 8, Loss: 0.4644580078125 33600/139232 train accuracy:0.7899702191352844
629it [03:45,  2.80it/s]Epoch: 8, Loss: 0.45527855282738094 37800/139232 train accuracy:0.7896296381950378
699it [04:10,  2.81it/s]Epoch: 8, Loss: 0.47779578799293154 42000/139232 train accuracy:0.7885714173316956
769it [04:35,  2.81it/s]Epoch: 8, Loss: 0.4661306908017113 46200/139232 train accuracy:0.7882900238037109
839it [05:00,  2.81it/s]Epoch: 8, Loss: 0.4709007335844494 50400/139232 train accuracy:0.7881150841712952
909it [05:25,  2.82it/s]Epoch: 8, Loss: 0.4493893868582589 54600/139232 train accuracy:0.7891208529472351
979it [05:49,  2.81it/s]Epoch: 8, Loss: 0.4742911783854167 58800/139232 train accuracy:0.7885714173316956
1049it [06:14,  2.81it/s]Epoch: 8, Loss: 0.4848857189360119 63000/139232 train accuracy:0.787492036819458
1119it [06:39,  2.81it/s]Epoch: 8, Loss: 0.4573388671875 67200/139232 train accuracy:0.7879762053489685
1189it [07:05,  2.80it/s]Epoch: 8, Loss: 0.4609988548642113 71400/139232 train accuracy:0.7878851294517517
1259it [07:30,  2.80it/s]Epoch: 8, Loss: 0.4575705392020089 75600/139232 train accuracy:0.7879100441932678
1329it [07:55,  2.81it/s]Epoch: 8, Loss: 0.46185892740885415 79800/139232 train accuracy:0.788032591342926
1399it [08:20,  2.81it/s]Epoch: 8, Loss: 0.46896155947730656 84000/139232 train accuracy:0.7879642844200134
1469it [08:44,  2.80it/s]Epoch: 8, Loss: 0.4477304222470238 88200/139232 train accuracy:0.7881972789764404
1539it [09:09,  2.81it/s]Epoch: 8, Loss: 0.4750030226934524 92400/139232 train accuracy:0.7883225083351135
1609it [09:34,  2.80it/s]Epoch: 8, Loss: 0.45550290062313986 96600/139232 train accuracy:0.7885714173316956
1679it [09:59,  2.80it/s]Epoch: 8, Loss: 0.4621526227678571 100800/139232 train accuracy:0.7884325385093689
1749it [10:24,  2.81it/s]Epoch: 8, Loss: 0.45556649344308037 105000/139232 train accuracy:0.7885333299636841
1819it [10:49,  2.80it/s]Epoch: 8, Loss: 0.4586788795107887 109200/139232 train accuracy:0.7885348200798035
1889it [11:14,  2.81it/s]Epoch: 8, Loss: 0.4699119640531994 113400/139232 train accuracy:0.7883950471878052
1959it [11:39,  2.81it/s]Epoch: 8, Loss: 0.4531431070963542 117600/139232 train accuracy:0.7886224389076233
2029it [12:04,  2.80it/s]Epoch: 8, Loss: 0.452684326171875 121800/139232 train accuracy:0.7888587713241577
2099it [12:29,  2.82it/s]Epoch: 8, Loss: 0.4499177478608631 126000/139232 train accuracy:0.7889364957809448
2169it [12:54,  2.81it/s]Epoch: 8, Loss: 0.45655253092447917 130200/139232 train accuracy:0.7891244292259216
2239it [13:19,  2.81it/s]Epoch: 8, Loss: 0.44310308547247024 134400/139232 train accuracy:0.7892931699752808
2309it [13:44,  2.81it/s]Epoch: 8, Loss: 0.4585470435732887 138600/139232 train accuracy:0.7893722653388977
2321it [13:48,  2.80it/s]
Epoch: 8, epoch Loss: 64169.0234375  train accuracy:0.7894737124443054

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.14it/s]
Epoch: 8, Valid Loss: 6802.51171875  valid accuracy:0.7985779047012329
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.41it/s]
Epoch: 8,   test accuracy:0.7983639240264893
37it [00:13,  2.81it/s]Epoch: 9, Loss: 0.25048037574404763 2280/139232 train accuracy:0.7877193093299866
69it [00:25,  2.82it/s]Epoch: 9, Loss: 0.20102446056547618 4200/139232 train accuracy:0.7959523797035217
139it [00:49,  2.82it/s]Epoch: 9, Loss: 0.4630312965029762 8400/139232 train accuracy:0.7903571724891663
209it [01:14,  2.81it/s]Epoch: 9, Loss: 0.45548011416480655 12600/139232 train accuracy:0.7913492321968079
279it [01:39,  2.82it/s]Epoch: 9, Loss: 0.4360630289713542 16800/139232 train accuracy:0.7949404716491699
349it [02:04,  2.81it/s]Epoch: 9, Loss: 0.4484161667596726 21000/139232 train accuracy:0.7951428294181824
419it [02:29,  2.81it/s]Epoch: 9, Loss: 0.45048179989769344 25200/139232 train accuracy:0.796150803565979
489it [02:54,  2.80it/s]Epoch: 9, Loss: 0.467618408203125 29400/139232 train accuracy:0.7956122159957886
559it [03:19,  2.80it/s]Epoch: 9, Loss: 0.4525610060918899 33600/139232 train accuracy:0.7946428656578064
629it [03:44,  2.81it/s]Epoch: 9, Loss: 0.4476699683779762 37800/139232 train accuracy:0.7947618961334229
699it [04:09,  2.81it/s]Epoch: 9, Loss: 0.44727425711495533 42000/139232 train accuracy:0.7940714359283447
769it [04:34,  2.82it/s]Epoch: 9, Loss: 0.4410113816034226 46200/139232 train accuracy:0.7940475940704346
839it [04:59,  2.81it/s]Epoch: 9, Loss: 0.43860095796130955 50400/139232 train accuracy:0.7948015928268433
909it [05:24,  2.80it/s]Epoch: 9, Loss: 0.43992039271763395 54600/139232 train accuracy:0.7953296899795532
979it [05:49,  2.81it/s]Epoch: 9, Loss: 0.46429655529203867 58800/139232 train accuracy:0.7946258783340454
1049it [06:14,  2.81it/s]Epoch: 9, Loss: 0.45571556454613094 63000/139232 train accuracy:0.7943174839019775
1119it [06:39,  2.80it/s]Epoch: 9, Loss: 0.45846804664248514 67200/139232 train accuracy:0.7938392758369446
1189it [07:04,  2.73it/s]Epoch: 9, Loss: 0.46382298060825894 71400/139232 train accuracy:0.7936134338378906
1259it [07:29,  2.80it/s]Epoch: 9, Loss: 0.4798879859561012 75600/139232 train accuracy:0.7925264835357666
1329it [07:54,  2.80it/s]Epoch: 9, Loss: 0.45451974051339283 79800/139232 train accuracy:0.7923057675361633
1399it [08:19,  2.79it/s]Epoch: 9, Loss: 0.46096319289434523 84000/139232 train accuracy:0.7920476198196411
1469it [08:44,  2.81it/s]Epoch: 9, Loss: 0.44750616164434526 88200/139232 train accuracy:0.7924376130104065
1539it [09:09,  2.81it/s]Epoch: 9, Loss: 0.476163330078125 92400/139232 train accuracy:0.7919372320175171
1609it [09:34,  2.81it/s]Epoch: 9, Loss: 0.4599002511160714 96600/139232 train accuracy:0.7917805314064026
1679it [09:59,  2.80it/s]Epoch: 9, Loss: 0.4507210867745536 100800/139232 train accuracy:0.791914701461792
1749it [10:24,  2.80it/s]Epoch: 9, Loss: 0.46140401204427084 105000/139232 train accuracy:0.7918000221252441
1819it [10:49,  2.81it/s]Epoch: 9, Loss: 0.4435011509486607 109200/139232 train accuracy:0.7921336889266968
1889it [11:14,  2.82it/s]Epoch: 9, Loss: 0.45373738606770836 113400/139232 train accuracy:0.7920017838478088
1959it [11:39,  2.80it/s]Epoch: 9, Loss: 0.4568783133370536 117600/139232 train accuracy:0.7919473052024841
2029it [12:04,  2.81it/s]Epoch: 9, Loss: 0.46595816476004465 121800/139232 train accuracy:0.7915188670158386
2099it [12:29,  2.81it/s]Epoch: 9, Loss: 0.45348051525297617 126000/139232 train accuracy:0.7913095355033875
2169it [12:54,  2.80it/s]Epoch: 9, Loss: 0.4544328090122768 130200/139232 train accuracy:0.7910599112510681
2239it [13:19,  2.81it/s]Epoch: 9, Loss: 0.44776468912760414 134400/139232 train accuracy:0.7910788655281067
2309it [13:44,  2.81it/s]Epoch: 9, Loss: 0.4580995105561756 138600/139232 train accuracy:0.7912121415138245
2321it [13:48,  2.80it/s]
Epoch: 9, epoch Loss: 63333.76953125  train accuracy:0.7910322546958923

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.12it/s]
Epoch: 9, Valid Loss: 6768.33837890625  valid accuracy:0.7985779047012329
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.40it/s]
Epoch: 9,   test accuracy:0.7999257445335388
37it [00:13,  2.81it/s]Epoch: 10, Loss: 0.2504920596168155 2280/139232 train accuracy:0.7881578803062439
69it [00:25,  2.82it/s]Epoch: 10, Loss: 0.20033534458705357 4200/139232 train accuracy:0.7938095331192017
139it [00:50,  2.79it/s]Epoch: 10, Loss: 0.45311939057849704 8400/139232 train accuracy:0.7933333516120911
209it [01:14,  2.81it/s]Epoch: 10, Loss: 0.44448843819754463 12600/139232 train accuracy:0.7949206233024597
279it [01:39,  2.82it/s]Epoch: 10, Loss: 0.4555268787202381 16800/139232 train accuracy:0.7940475940704346
349it [02:04,  2.78it/s]Epoch: 10, Loss: 0.4620988537016369 21000/139232 train accuracy:0.7921904921531677
419it [02:29,  2.77it/s]Epoch: 10, Loss: 0.43216866629464284 25200/139232 train accuracy:0.794087290763855
489it [02:55,  2.81it/s]Epoch: 10, Loss: 0.43729820614769344 29400/139232 train accuracy:0.7948979735374451
559it [03:20,  2.77it/s]Epoch: 10, Loss: 0.4434958031063988 33600/139232 train accuracy:0.7954166531562805
629it [03:45,  2.82it/s]Epoch: 10, Loss: 0.4426043991815476 37800/139232 train accuracy:0.7956084609031677
699it [04:10,  2.82it/s]Epoch: 10, Loss: 0.44404116675967265 42000/139232 train accuracy:0.7960714101791382
769it [04:35,  2.78it/s]Epoch: 10, Loss: 0.453193359375 46200/139232 train accuracy:0.7959091067314148
839it [05:00,  2.78it/s]Epoch: 10, Loss: 0.44099464053199405 50400/139232 train accuracy:0.7961905002593994
909it [05:25,  2.78it/s]Epoch: 10, Loss: 0.4491742234002976 54600/139232 train accuracy:0.7959706783294678
979it [05:50,  2.81it/s]Epoch: 10, Loss: 0.4388491094680059 58800/139232 train accuracy:0.7962925434112549
1049it [06:15,  2.81it/s]Epoch: 10, Loss: 0.44839605422247025 63000/139232 train accuracy:0.7957936525344849
1119it [06:40,  2.82it/s]Epoch: 10, Loss: 0.4662969970703125 67200/139232 train accuracy:0.7953125238418579
1189it [07:05,  2.79it/s]Epoch: 10, Loss: 0.4417392985026042 71400/139232 train accuracy:0.7955602407455444
1259it [07:30,  2.81it/s]Epoch: 10, Loss: 0.4391256568545387 75600/139232 train accuracy:0.7956746220588684
1329it [07:55,  2.81it/s]Epoch: 10, Loss: 0.461275140671503 79800/139232 train accuracy:0.795250654220581
1399it [08:20,  2.82it/s]Epoch: 10, Loss: 0.4485211472284226 84000/139232 train accuracy:0.7950118780136108
1469it [08:45,  2.82it/s]Epoch: 10, Loss: 0.45866173153831846 88200/139232 train accuracy:0.7945805191993713
1539it [09:10,  2.79it/s]Epoch: 10, Loss: 0.4431839134579613 92400/139232 train accuracy:0.7948809266090393
1609it [09:35,  2.81it/s]Epoch: 10, Loss: 0.44889290945870536 96600/139232 train accuracy:0.794658362865448
1679it [10:00,  2.80it/s]Epoch: 10, Loss: 0.45706153506324404 100800/139232 train accuracy:0.7946825623512268
1749it [10:25,  2.82it/s]Epoch: 10, Loss: 0.4607452392578125 105000/139232 train accuracy:0.7945238351821899
1819it [10:50,  2.76it/s]Epoch: 10, Loss: 0.45335873558407735 109200/139232 train accuracy:0.7944139242172241
1889it [11:15,  2.82it/s]Epoch: 10, Loss: 0.4418913922991071 113400/139232 train accuracy:0.7944709062576294
1959it [11:40,  2.82it/s]Epoch: 10, Loss: 0.443633539109003 117600/139232 train accuracy:0.7945833206176758
2029it [12:05,  2.80it/s]Epoch: 10, Loss: 0.4381582205636161 121800/139232 train accuracy:0.7949425578117371
2099it [12:30,  2.82it/s]Epoch: 10, Loss: 0.43800769624255953 126000/139232 train accuracy:0.7951904535293579
2169it [12:55,  2.82it/s]Epoch: 10, Loss: 0.45745372953869046 130200/139232 train accuracy:0.7949231863021851
2239it [13:20,  2.82it/s]Epoch: 10, Loss: 0.4362087867373512 134400/139232 train accuracy:0.7952455282211304
2309it [13:44,  2.81it/s]Epoch: 10, Loss: 0.4419209216889881 138600/139232 train accuracy:0.7954617738723755
2321it [13:49,  2.80it/s]
Epoch: 10, epoch Loss: 62356.75  train accuracy:0.79537034034729

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.13it/s]
Epoch: 10, Valid Loss: 6709.240234375  valid accuracy:0.801422119140625
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.41it/s]
Epoch: 10,   test accuracy:0.8014876246452332
37it [00:13,  2.82it/s]Epoch: 11, Loss: 0.2415917242140997 2280/139232 train accuracy:0.7942982316017151
69it [00:25,  2.82it/s]Epoch: 11, Loss: 0.18727464948381697 4200/139232 train accuracy:0.8052380681037903
139it [00:50,  2.82it/s]Epoch: 11, Loss: 0.4581803385416667 8400/139232 train accuracy:0.7964285612106323
209it [01:14,  2.81it/s]Epoch: 11, Loss: 0.4530270240420387 12600/139232 train accuracy:0.796746015548706
279it [01:39,  2.81it/s]Epoch: 11, Loss: 0.4456910632905506 16800/139232 train accuracy:0.7968452572822571
349it [02:04,  2.79it/s]Epoch: 11, Loss: 0.4476930745442708 21000/139232 train accuracy:0.797428548336029
419it [02:29,  2.81it/s]Epoch: 11, Loss: 0.4494304838634673 25200/139232 train accuracy:0.7966269850730896
489it [02:54,  2.82it/s]Epoch: 11, Loss: 0.4462435767764137 29400/139232 train accuracy:0.7952721118927002
559it [03:19,  2.81it/s]Epoch: 11, Loss: 0.43080999465215775 33600/139232 train accuracy:0.7962499856948853
629it [03:44,  2.80it/s]Epoch: 11, Loss: 0.4474469866071429 37800/139232 train accuracy:0.7957671880722046
699it [04:09,  2.81it/s]Epoch: 11, Loss: 0.45432094029017855 42000/139232 train accuracy:0.7955238223075867
769it [04:34,  2.81it/s]Epoch: 11, Loss: 0.45035734630766366 46200/139232 train accuracy:0.7956926226615906
839it [04:59,  2.79it/s]Epoch: 11, Loss: 0.4465900530133929 50400/139232 train accuracy:0.7959523797035217
909it [05:24,  2.80it/s]Epoch: 11, Loss: 0.4551753452845982 54600/139232 train accuracy:0.7961905002593994
979it [05:49,  2.80it/s]Epoch: 11, Loss: 0.4465187000093006 58800/139232 train accuracy:0.7959353923797607
1049it [06:14,  2.82it/s]Epoch: 11, Loss: 0.4425730387369792 63000/139232 train accuracy:0.7961587309837341
1119it [06:39,  2.81it/s]Epoch: 11, Loss: 0.4369825381324405 67200/139232 train accuracy:0.7964137196540833
1189it [07:04,  2.81it/s]Epoch: 11, Loss: 0.42584001813616074 71400/139232 train accuracy:0.7968207001686096
1259it [07:29,  2.82it/s]Epoch: 11, Loss: 0.44959083193824406 75600/139232 train accuracy:0.797010600566864
1329it [07:54,  2.82it/s]Epoch: 11, Loss: 0.4457989501953125 79800/139232 train accuracy:0.7967919707298279
1399it [08:19,  2.81it/s]Epoch: 11, Loss: 0.4346612839471726 84000/139232 train accuracy:0.7969523668289185
1469it [08:44,  2.81it/s]Epoch: 11, Loss: 0.43029302687872023 88200/139232 train accuracy:0.7971315383911133
1539it [09:09,  2.82it/s]Epoch: 11, Loss: 0.4337284923735119 92400/139232 train accuracy:0.7970238327980042
1609it [09:33,  2.82it/s]Epoch: 11, Loss: 0.4268064953031994 96600/139232 train accuracy:0.7973809242248535
1679it [09:58,  2.82it/s]Epoch: 11, Loss: 0.44929710751488094 100800/139232 train accuracy:0.7974107265472412
1749it [10:23,  2.81it/s]Epoch: 11, Loss: 0.442884521484375 105000/139232 train accuracy:0.7972095012664795
1819it [10:49,  2.77it/s]Epoch: 11, Loss: 0.4409254092261905 109200/139232 train accuracy:0.7974175810813904
1889it [11:14,  2.82it/s]Epoch: 11, Loss: 0.4283835274832589 113400/139232 train accuracy:0.7976896166801453
1959it [11:38,  2.82it/s]Epoch: 11, Loss: 0.4319644310360863 117600/139232 train accuracy:0.7979251742362976
2029it [12:03,  2.80it/s]Epoch: 11, Loss: 0.4357984851655506 121800/139232 train accuracy:0.7980952262878418
2099it [12:28,  2.80it/s]Epoch: 11, Loss: 0.44344386509486605 126000/139232 train accuracy:0.7982380986213684
2169it [12:53,  2.81it/s]Epoch: 11, Loss: 0.4435289655412946 130200/139232 train accuracy:0.7983563542366028
2239it [13:18,  2.80it/s]Epoch: 11, Loss: 0.439434320359003 134400/139232 train accuracy:0.7982142567634583
2309it [13:43,  2.82it/s]Epoch: 11, Loss: 0.44313270205543154 138600/139232 train accuracy:0.7982106804847717
2321it [13:47,  2.80it/s]
Epoch: 11, epoch Loss: 61532.58203125  train accuracy:0.798264741897583

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.14it/s]
Epoch: 11, Valid Loss: 6683.6044921875  valid accuracy:0.8026502728462219
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.41it/s]
Epoch: 11,   test accuracy:0.8018278479576111
37it [00:13,  2.81it/s]Epoch: 12, Loss: 0.23733334495907737 2280/139232 train accuracy:0.8074561357498169
69it [00:25,  2.81it/s]Epoch: 12, Loss: 0.19329309372674852 4200/139232 train accuracy:0.8071428537368774
139it [00:50,  2.81it/s]Epoch: 12, Loss: 0.4409753708612351 8400/139232 train accuracy:0.803928554058075
209it [01:14,  2.81it/s]Epoch: 12, Loss: 0.42887930733816965 12600/139232 train accuracy:0.8051587343215942
279it [01:39,  2.81it/s]Epoch: 12, Loss: 0.43648501441592263 16800/139232 train accuracy:0.8023214340209961
349it [02:04,  2.81it/s]Epoch: 12, Loss: 0.4333347574869792 21000/139232 train accuracy:0.801809549331665
419it [02:29,  2.81it/s]Epoch: 12, Loss: 0.4367840576171875 25200/139232 train accuracy:0.801031768321991
489it [02:54,  2.81it/s]Epoch: 12, Loss: 0.4194059244791667 29400/139232 train accuracy:0.8020067811012268
559it [03:19,  2.81it/s]Epoch: 12, Loss: 0.4405511474609375 33600/139232 train accuracy:0.8013690710067749
629it [03:44,  2.80it/s]Epoch: 12, Loss: 0.44700035458519344 37800/139232 train accuracy:0.8004497289657593
699it [04:09,  2.81it/s]Epoch: 12, Loss: 0.42795256115141367 42000/139232 train accuracy:0.8005238175392151
769it [04:34,  2.80it/s]Epoch: 12, Loss: 0.436928943452381 46200/139232 train accuracy:0.8007792234420776
839it [04:59,  2.81it/s]Epoch: 12, Loss: 0.43352411179315475 50400/139232 train accuracy:0.8006150722503662
909it [05:24,  2.82it/s]Epoch: 12, Loss: 0.42825340634300596 54600/139232 train accuracy:0.8004761934280396
979it [05:49,  2.81it/s]Epoch: 12, Loss: 0.43076142810639884 58800/139232 train accuracy:0.8003401160240173
1049it [06:14,  2.79it/s]Epoch: 12, Loss: 0.43789559500558034 63000/139232 train accuracy:0.8006190657615662
1119it [06:39,  2.80it/s]Epoch: 12, Loss: 0.4439856828962054 67200/139232 train accuracy:0.8005654811859131
1189it [07:04,  2.81it/s]Epoch: 12, Loss: 0.4391214715866815 71400/139232 train accuracy:0.8003641366958618
1259it [07:29,  2.80it/s]Epoch: 12, Loss: 0.42520118350074404 75600/139232 train accuracy:0.8005423545837402
1329it [07:54,  2.80it/s]Epoch: 12, Loss: 0.4408140927269345 79800/139232 train accuracy:0.7998371124267578
1399it [08:19,  2.80it/s]Epoch: 12, Loss: 0.44231134323846727 84000/139232 train accuracy:0.7994880676269531
1469it [08:44,  2.79it/s]Epoch: 12, Loss: 0.4343385532924107 88200/139232 train accuracy:0.799795925617218
1539it [09:09,  2.80it/s]Epoch: 12, Loss: 0.4437436930338542 92400/139232 train accuracy:0.7997186183929443
1609it [09:34,  2.80it/s]Epoch: 12, Loss: 0.4360606747581845 96600/139232 train accuracy:0.7998343706130981
1679it [09:59,  2.80it/s]Epoch: 12, Loss: 0.43821512858072914 100800/139232 train accuracy:0.8000496029853821
1749it [10:24,  2.80it/s]Epoch: 12, Loss: 0.4446559361049107 105000/139232 train accuracy:0.7998095154762268
1819it [10:50,  2.80it/s]Epoch: 12, Loss: 0.4321328880673363 109200/139232 train accuracy:0.800000011920929
1889it [11:15,  2.80it/s]Epoch: 12, Loss: 0.44562744140625 113400/139232 train accuracy:0.7998412847518921
1959it [11:40,  2.80it/s]Epoch: 12, Loss: 0.4313505045572917 117600/139232 train accuracy:0.7998384237289429
2029it [12:05,  2.81it/s]Epoch: 12, Loss: 0.4371600051153274 121800/139232 train accuracy:0.7997126579284668
2099it [12:30,  2.80it/s]Epoch: 12, Loss: 0.43869620186941966 126000/139232 train accuracy:0.7996666431427002
2169it [12:55,  2.78it/s]Epoch: 12, Loss: 0.432313232421875 130200/139232 train accuracy:0.7997618913650513
2239it [13:20,  2.81it/s]Epoch: 12, Loss: 0.4288622756231399 134400/139232 train accuracy:0.8001934289932251
2309it [13:45,  2.80it/s]Epoch: 12, Loss: 0.4317871384393601 138600/139232 train accuracy:0.8001082539558411
2321it [13:49,  2.80it/s]
Epoch: 12, epoch Loss: 60665.0625  train accuracy:0.7999957203865051

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.13it/s]
Epoch: 12, Valid Loss: 6646.21533203125  valid accuracy:0.8042016625404358
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.40it/s]
Epoch: 12,   test accuracy:0.8032041788101196
37it [00:13,  2.80it/s]Epoch: 13, Loss: 0.23506251743861606 2280/139232 train accuracy:0.7991228103637695
69it [00:25,  2.80it/s]Epoch: 13, Loss: 0.1931025623139881 4200/139232 train accuracy:0.8057143092155457
139it [00:50,  2.81it/s]Epoch: 13, Loss: 0.4303030540829613 8400/139232 train accuracy:0.8040476441383362
209it [01:15,  2.80it/s]Epoch: 13, Loss: 0.42622735886346724 12600/139232 train accuracy:0.8042857050895691
279it [01:39,  2.81it/s]Epoch: 13, Loss: 0.4244129580543155 16800/139232 train accuracy:0.8047618865966797
349it [02:04,  2.80it/s]Epoch: 13, Loss: 0.43399065290178573 21000/139232 train accuracy:0.8042857050895691
419it [02:29,  2.81it/s]Epoch: 13, Loss: 0.42708824521019345 25200/139232 train accuracy:0.8048015832901001
489it [02:54,  2.80it/s]Epoch: 13, Loss: 0.43493259974888393 29400/139232 train accuracy:0.8042517304420471
559it [03:19,  2.81it/s]Epoch: 13, Loss: 0.4379207066127232 33600/139232 train accuracy:0.8033630847930908
629it [03:45,  2.81it/s]Epoch: 13, Loss: 0.43244716099330355 37800/139232 train accuracy:0.8037830591201782
699it [04:10,  2.81it/s]Epoch: 13, Loss: 0.43509486607142855 42000/139232 train accuracy:0.8029524087905884
769it [04:35,  2.81it/s]Epoch: 13, Loss: 0.4171979341052827 46200/139232 train accuracy:0.8036796450614929
839it [05:00,  2.80it/s]Epoch: 13, Loss: 0.4411761183965774 50400/139232 train accuracy:0.8031547665596008
909it [05:24,  2.82it/s]Epoch: 13, Loss: 0.4355919538225446 54600/139232 train accuracy:0.8028205037117004
979it [05:49,  2.78it/s]Epoch: 13, Loss: 0.4239600190662202 58800/139232 train accuracy:0.8028231263160706
1049it [06:14,  2.80it/s]Epoch: 13, Loss: 0.4297956775483631 63000/139232 train accuracy:0.803158700466156
1119it [06:39,  2.80it/s]Epoch: 13, Loss: 0.4314207531156994 67200/139232 train accuracy:0.8031250238418579
1189it [07:04,  2.81it/s]Epoch: 13, Loss: 0.4350988478887649 71400/139232 train accuracy:0.8028431534767151
1259it [07:29,  2.80it/s]Epoch: 13, Loss: 0.4298542712983631 75600/139232 train accuracy:0.8021825551986694
1329it [07:54,  2.81it/s]Epoch: 13, Loss: 0.4370546468098958 79800/139232 train accuracy:0.8021678924560547
1399it [08:19,  2.79it/s]Epoch: 13, Loss: 0.4452895100911458 84000/139232 train accuracy:0.8020119071006775
1469it [08:44,  2.82it/s]Epoch: 13, Loss: 0.43583981468563987 88200/139232 train accuracy:0.802097499370575
1539it [09:09,  2.82it/s]Epoch: 13, Loss: 0.4445503162202381 92400/139232 train accuracy:0.801742434501648
1609it [09:34,  2.82it/s]Epoch: 13, Loss: 0.43805980864025296 96600/139232 train accuracy:0.8016252517700195
1679it [09:59,  2.82it/s]Epoch: 13, Loss: 0.43846441359747024 100800/139232 train accuracy:0.8013988137245178
1749it [10:24,  2.82it/s]Epoch: 13, Loss: 0.4309674072265625 105000/139232 train accuracy:0.8012666702270508
1819it [10:49,  2.81it/s]Epoch: 13, Loss: 0.43182044619605653 109200/139232 train accuracy:0.8012545704841614
1889it [11:14,  2.82it/s]Epoch: 13, Loss: 0.43851643880208335 113400/139232 train accuracy:0.8012081384658813
1959it [11:39,  2.82it/s]Epoch: 13, Loss: 0.4311030796595982 117600/139232 train accuracy:0.8011054396629333
2029it [12:04,  2.77it/s]Epoch: 13, Loss: 0.42924051920572914 121800/139232 train accuracy:0.8010262846946716
2099it [12:29,  2.81it/s]Epoch: 13, Loss: 0.42768592471168154 126000/139232 train accuracy:0.801277756690979
2169it [12:53,  2.82it/s]Epoch: 13, Loss: 0.4187850516183036 130200/139232 train accuracy:0.8014593124389648
2239it [13:18,  2.81it/s]Epoch: 13, Loss: 0.4259734816778274 134400/139232 train accuracy:0.801547646522522
2309it [13:43,  2.79it/s]Epoch: 13, Loss: 0.4213001069568452 138600/139232 train accuracy:0.8017171621322632
2321it [13:47,  2.80it/s]
Epoch: 13, epoch Loss: 60112.69921875  train accuracy:0.8017481565475464

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.13it/s]
Epoch: 13, Valid Loss: 6624.474609375  valid accuracy:0.8025856614112854
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.39it/s]
Epoch: 13,   test accuracy:0.8032814860343933
37it [00:13,  2.80it/s]Epoch: 14, Loss: 0.2378023710704985 2280/139232 train accuracy:0.7982456088066101
69it [00:25,  2.82it/s]Epoch: 14, Loss: 0.2014830816359747 4200/139232 train accuracy:0.8004761934280396
139it [00:50,  2.81it/s]Epoch: 14, Loss: 0.4286259533110119 8400/139232 train accuracy:0.8028571605682373
209it [01:15,  2.80it/s]Epoch: 14, Loss: 0.43215143112909227 12600/139232 train accuracy:0.8023809790611267
279it [01:40,  2.81it/s]Epoch: 14, Loss: 0.4168074253627232 16800/139232 train accuracy:0.8045833110809326
349it [02:05,  2.80it/s]Epoch: 14, Loss: 0.4198437790643601 21000/139232 train accuracy:0.8048095107078552
419it [02:30,  2.80it/s]Epoch: 14, Loss: 0.4291013299851191 25200/139232 train accuracy:0.8059523701667786
489it [02:54,  2.81it/s]Epoch: 14, Loss: 0.4254958670479911 29400/139232 train accuracy:0.8057823181152344
559it [03:19,  2.82it/s]Epoch: 14, Loss: 0.42094912574404764 33600/139232 train accuracy:0.8053869009017944
629it [03:45,  2.81it/s]Epoch: 14, Loss: 0.4320190139043899 37800/139232 train accuracy:0.8046296238899231
699it [04:10,  2.81it/s]Epoch: 14, Loss: 0.4249639892578125 42000/139232 train accuracy:0.8041666746139526
769it [04:35,  2.80it/s]Epoch: 14, Loss: 0.43682195754278275 46200/139232 train accuracy:0.8032251000404358
839it [05:00,  2.80it/s]Epoch: 14, Loss: 0.4299310012090774 50400/139232 train accuracy:0.8032936453819275
909it [05:25,  2.80it/s]Epoch: 14, Loss: 0.42772760300409224 54600/139232 train accuracy:0.803260087966919
979it [05:50,  2.80it/s]Epoch: 14, Loss: 0.44039027622767857 58800/139232 train accuracy:0.8029592037200928
1049it [06:15,  2.79it/s]Epoch: 14, Loss: 0.42008768717447914 63000/139232 train accuracy:0.8032857179641724
1119it [06:40,  2.80it/s]Epoch: 14, Loss: 0.41941734677269343 67200/139232 train accuracy:0.8036309480667114
1189it [07:05,  2.80it/s]Epoch: 14, Loss: 0.4347673107328869 71400/139232 train accuracy:0.8037394881248474
1259it [07:30,  2.80it/s]Epoch: 14, Loss: 0.41162818545386903 75600/139232 train accuracy:0.8044576644897461
1329it [07:55,  2.79it/s]Epoch: 14, Loss: 0.4356564476376488 79800/139232 train accuracy:0.8043358325958252
1399it [08:20,  2.80it/s]Epoch: 14, Loss: 0.42767662411644347 84000/139232 train accuracy:0.8044642806053162
1469it [08:45,  2.80it/s]Epoch: 14, Loss: 0.4273509288969494 88200/139232 train accuracy:0.8044784665107727
1539it [09:10,  2.80it/s]Epoch: 14, Loss: 0.4289429001581101 92400/139232 train accuracy:0.8044264316558838
1609it [09:35,  2.80it/s]Epoch: 14, Loss: 0.43014133998325893 96600/139232 train accuracy:0.8044513463973999
1679it [10:00,  2.79it/s]Epoch: 14, Loss: 0.41538992745535713 100800/139232 train accuracy:0.804930567741394
1749it [10:25,  2.80it/s]Epoch: 14, Loss: 0.41952965146019344 105000/139232 train accuracy:0.8049904704093933
1819it [10:50,  2.79it/s]Epoch: 14, Loss: 0.4211627197265625 109200/139232 train accuracy:0.8050366044044495
1889it [11:15,  2.81it/s]Epoch: 14, Loss: 0.4382332066127232 113400/139232 train accuracy:0.8047178387641907
1959it [11:40,  2.80it/s]Epoch: 14, Loss: 0.4236380440848214 117600/139232 train accuracy:0.8049234747886658
2029it [12:05,  2.81it/s]Epoch: 14, Loss: 0.422082025437128 121800/139232 train accuracy:0.8050574660301208
2099it [12:30,  2.81it/s]Epoch: 14, Loss: 0.42459783644903276 126000/139232 train accuracy:0.8049761652946472
2169it [12:56,  2.79it/s]Epoch: 14, Loss: 0.43147678920200894 130200/139232 train accuracy:0.8050307035446167
2239it [13:21,  2.80it/s]Epoch: 14, Loss: 0.42153204055059523 134400/139232 train accuracy:0.8051934242248535
2309it [13:46,  2.80it/s]Epoch: 14, Loss: 0.4189623151506696 138600/139232 train accuracy:0.8052525520324707
2321it [13:50,  2.80it/s]
Epoch: 14, epoch Loss: 59411.265625  train accuracy:0.8051741123199463

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.13it/s]
Epoch: 14, Valid Loss: 6601.962890625  valid accuracy:0.8034906387329102
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.39it/s]
Epoch: 14,   test accuracy:0.8033742904663086
37it [00:13,  2.79it/s]Epoch: 15, Loss: 0.23105058942522322 2280/139232 train accuracy:0.8114035129547119
69it [00:25,  2.81it/s]Epoch: 15, Loss: 0.20324339367094493 4200/139232 train accuracy:0.8035714030265808
139it [00:50,  2.81it/s]Epoch: 15, Loss: 0.42715018136160715 8400/139232 train accuracy:0.8040476441383362
209it [01:15,  2.81it/s]Epoch: 15, Loss: 0.4165260532924107 12600/139232 train accuracy:0.8050793409347534
279it [01:40,  2.80it/s]Epoch: 15, Loss: 0.4240592447916667 16800/139232 train accuracy:0.8051190376281738
349it [02:05,  2.81it/s]Epoch: 15, Loss: 0.43384620303199406 21000/139232 train accuracy:0.805571436882019
419it [02:30,  2.80it/s]Epoch: 15, Loss: 0.42563790457589284 25200/139232 train accuracy:0.8056746125221252
489it [02:55,  2.80it/s]Epoch: 15, Loss: 0.42933003743489584 29400/139232 train accuracy:0.8047618865966797
559it [03:20,  2.81it/s]Epoch: 15, Loss: 0.4135052199590774 33600/139232 train accuracy:0.8061309456825256
629it [03:45,  2.79it/s]Epoch: 15, Loss: 0.40773919968377975 37800/139232 train accuracy:0.8074867725372314
699it [04:10,  2.80it/s]Epoch: 15, Loss: 0.4142468552362351 42000/139232 train accuracy:0.8081428408622742
769it [04:35,  2.80it/s]Epoch: 15, Loss: 0.42404549734933034 46200/139232 train accuracy:0.8080519437789917
839it [05:00,  2.80it/s]Epoch: 15, Loss: 0.40307364327566964 50400/139232 train accuracy:0.8087896704673767
909it [05:25,  2.81it/s]Epoch: 15, Loss: 0.41806591215587796 54600/139232 train accuracy:0.808681309223175
979it [05:50,  2.81it/s]Epoch: 15, Loss: 0.4225914655412946 58800/139232 train accuracy:0.8088435530662537
1049it [06:15,  2.82it/s]Epoch: 15, Loss: 0.42283025832403276 63000/139232 train accuracy:0.8086190223693848
1119it [06:40,  2.79it/s]Epoch: 15, Loss: 0.4214855666387649 67200/139232 train accuracy:0.8084226250648499
1189it [07:05,  2.81it/s]Epoch: 15, Loss: 0.4131321498325893 71400/139232 train accuracy:0.8083333373069763
1259it [07:30,  2.81it/s]Epoch: 15, Loss: 0.417747802734375 75600/139232 train accuracy:0.8085317611694336
1329it [07:55,  2.80it/s]Epoch: 15, Loss: 0.4162438092912946 79800/139232 train accuracy:0.808859646320343
1399it [08:20,  2.81it/s]Epoch: 15, Loss: 0.41228876023065475 84000/139232 train accuracy:0.8090237975120544
1469it [08:45,  2.80it/s]Epoch: 15, Loss: 0.40207365490141367 88200/139232 train accuracy:0.8095351457595825
1539it [09:10,  2.79it/s]Epoch: 15, Loss: 0.4228787086123512 92400/139232 train accuracy:0.8095129728317261
1609it [09:35,  2.81it/s]Epoch: 15, Loss: 0.42093136742001486 96600/139232 train accuracy:0.809720516204834
1679it [10:00,  2.82it/s]Epoch: 15, Loss: 0.4321979050409226 100800/139232 train accuracy:0.8093551397323608
1749it [10:25,  2.78it/s]Epoch: 15, Loss: 0.4231828380766369 105000/139232 train accuracy:0.8093428611755371
1819it [10:50,  2.80it/s]Epoch: 15, Loss: 0.4322417922247024 109200/139232 train accuracy:0.809166669845581
1889it [11:15,  2.81it/s]Epoch: 15, Loss: 0.4193065824962798 113400/139232 train accuracy:0.8090211749076843
1959it [11:40,  2.81it/s]Epoch: 15, Loss: 0.4177953810918899 117600/139232 train accuracy:0.8091071248054504
2029it [12:05,  2.80it/s]Epoch: 15, Loss: 0.42909641810825894 121800/139232 train accuracy:0.8088012933731079
2099it [12:30,  2.81it/s]Epoch: 15, Loss: 0.4296918015252976 126000/139232 train accuracy:0.8086190223693848
2169it [12:55,  2.81it/s]Epoch: 15, Loss: 0.42376057942708334 130200/139232 train accuracy:0.8083333373069763
2239it [13:20,  2.82it/s]Epoch: 15, Loss: 0.4116904994419643 134400/139232 train accuracy:0.8085862994194031
2309it [13:45,  2.82it/s]Epoch: 15, Loss: 0.44043445405505954 138600/139232 train accuracy:0.8081890344619751
2321it [13:49,  2.80it/s]
Epoch: 15, epoch Loss: 58658.30859375  train accuracy:0.8082337379455566

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.13it/s]
Epoch: 15, Valid Loss: 6589.1875  valid accuracy:0.8042016625404358
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.41it/s]
Epoch: 15,   test accuracy:0.8026629090309143
37it [00:13,  2.81it/s]Epoch: 16, Loss: 0.22989148821149555 2280/139232 train accuracy:0.8135964870452881
69it [00:25,  2.80it/s]Epoch: 16, Loss: 0.19170013427734375 4200/139232 train accuracy:0.8102381229400635
139it [00:50,  2.80it/s]Epoch: 16, Loss: 0.42001668294270833 8400/139232 train accuracy:0.8089285492897034
209it [01:15,  2.81it/s]Epoch: 16, Loss: 0.41665274483816966 12600/139232 train accuracy:0.8088095188140869
279it [01:40,  2.81it/s]Epoch: 16, Loss: 0.41063496907552083 16800/139232 train accuracy:0.8098214268684387
349it [02:05,  2.80it/s]Epoch: 16, Loss: 0.41027980259486607 21000/139232 train accuracy:0.8109047412872314
419it [02:29,  2.80it/s]Epoch: 16, Loss: 0.41169517880394346 25200/139232 train accuracy:0.8112698197364807
489it [02:54,  2.80it/s]Epoch: 16, Loss: 0.422077404203869 29400/139232 train accuracy:0.8115986585617065
559it [03:20,  2.27it/s]Epoch: 16, Loss: 0.4258627755301339 33600/139232 train accuracy:0.8099702596664429
629it [03:45,  2.80it/s]Epoch: 16, Loss: 0.41486915225074406 37800/139232 train accuracy:0.8095502853393555
699it [04:10,  2.80it/s]Epoch: 16, Loss: 0.41067850748697915 42000/139232 train accuracy:0.8100000023841858
769it [04:35,  2.81it/s]Epoch: 16, Loss: 0.4145285470145089 46200/139232 train accuracy:0.8103679418563843
839it [05:00,  2.80it/s]Epoch: 16, Loss: 0.3985791306268601 50400/139232 train accuracy:0.8114880919456482
909it [05:25,  2.81it/s]Epoch: 16, Loss: 0.4289030238560268 54600/139232 train accuracy:0.8109340667724609
979it [05:50,  2.80it/s]Epoch: 16, Loss: 0.4161163039434524 58800/139232 train accuracy:0.810952365398407
1049it [06:15,  2.80it/s]Epoch: 16, Loss: 0.4135221644810268 63000/139232 train accuracy:0.8106825351715088
1119it [06:40,  2.82it/s]Epoch: 16, Loss: 0.41922706240699403 67200/139232 train accuracy:0.8104910850524902
1189it [07:05,  2.81it/s]Epoch: 16, Loss: 0.41693368094308036 71400/139232 train accuracy:0.8106162548065186
1259it [07:30,  2.81it/s]Epoch: 16, Loss: 0.4148286655970982 75600/139232 train accuracy:0.8107936382293701
1329it [07:54,  2.81it/s]Epoch: 16, Loss: 0.40114865257626486 79800/139232 train accuracy:0.8112656474113464
1399it [08:19,  2.80it/s]Epoch: 16, Loss: 0.42673450288318454 84000/139232 train accuracy:0.8107261657714844
1469it [08:44,  2.80it/s]Epoch: 16, Loss: 0.41718819754464287 88200/139232 train accuracy:0.810748279094696
1539it [09:09,  2.80it/s]Epoch: 16, Loss: 0.4149702962239583 92400/139232 train accuracy:0.8107900619506836
1609it [09:34,  2.80it/s]Epoch: 16, Loss: 0.4147462390718006 96600/139232 train accuracy:0.8108488321304321
1679it [09:59,  2.79it/s]Epoch: 16, Loss: 0.40622413271949404 100800/139232 train accuracy:0.8113591074943542
1749it [10:25,  2.81it/s]Epoch: 16, Loss: 0.4168142264229911 105000/139232 train accuracy:0.811380922794342
1819it [10:50,  2.80it/s]Epoch: 16, Loss: 0.4257299514043899 109200/139232 train accuracy:0.8111538290977478
1889it [11:15,  2.80it/s]Epoch: 16, Loss: 0.4090325927734375 113400/139232 train accuracy:0.8112786412239075
1959it [11:40,  2.81it/s]Epoch: 16, Loss: 0.41577968052455355 117600/139232 train accuracy:0.8112754821777344
2029it [12:05,  2.80it/s]Epoch: 16, Loss: 0.40851056780133926 121800/139232 train accuracy:0.8112972378730774
2099it [12:30,  2.80it/s]Epoch: 16, Loss: 0.4065098644438244 126000/139232 train accuracy:0.8112381100654602
2169it [12:55,  2.80it/s]Epoch: 16, Loss: 0.4207667759486607 130200/139232 train accuracy:0.8111751079559326
2239it [13:20,  2.81it/s]Epoch: 16, Loss: 0.4339209275018601 134400/139232 train accuracy:0.8110862970352173
2309it [13:45,  2.79it/s]Epoch: 16, Loss: 0.41388750348772324 138600/139232 train accuracy:0.8112337589263916
2321it [13:49,  2.80it/s]
Epoch: 16, epoch Loss: 57873.203125  train accuracy:0.8112502694129944

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.13it/s]
Epoch: 16, Valid Loss: 6567.8095703125  valid accuracy:0.8061408996582031
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.39it/s]
Epoch: 16,   test accuracy:0.8050907850265503
37it [00:13,  2.81it/s]Epoch: 17, Loss: 0.22119732084728422 2280/139232 train accuracy:0.8065789341926575
69it [00:25,  2.80it/s]Epoch: 17, Loss: 0.19062978108723957 4200/139232 train accuracy:0.813095211982727
139it [00:50,  2.81it/s]Epoch: 17, Loss: 0.4042190406436012 8400/139232 train accuracy:0.8149999976158142
209it [01:15,  2.80it/s]Epoch: 17, Loss: 0.40513055710565476 12600/139232 train accuracy:0.8152381181716919
279it [01:40,  2.79it/s]Epoch: 17, Loss: 0.3976981898716518 16800/139232 train accuracy:0.8166666626930237
349it [02:05,  2.79it/s]Epoch: 17, Loss: 0.39876031784784227 21000/139232 train accuracy:0.817714273929596
419it [02:30,  2.82it/s]Epoch: 17, Loss: 0.41926231747581844 25200/139232 train accuracy:0.816428542137146
489it [02:55,  2.81it/s]Epoch: 17, Loss: 0.4077159191313244 29400/139232 train accuracy:0.816428542137146
559it [03:20,  2.79it/s]Epoch: 17, Loss: 0.39697870163690474 33600/139232 train accuracy:0.8170833587646484
629it [03:45,  2.81it/s]Epoch: 17, Loss: 0.4155006336030506 37800/139232 train accuracy:0.8168253898620605
699it [04:10,  2.81it/s]Epoch: 17, Loss: 0.4075043015252976 42000/139232 train accuracy:0.8165237903594971
769it [04:35,  2.77it/s]Epoch: 17, Loss: 0.4254461669921875 46200/139232 train accuracy:0.8150866031646729
839it [05:00,  2.81it/s]Epoch: 17, Loss: 0.4015789504278274 50400/139232 train accuracy:0.8156349062919617
909it [05:25,  2.82it/s]Epoch: 17, Loss: 0.40857105073474703 54600/139232 train accuracy:0.815183162689209
979it [05:50,  2.81it/s]Epoch: 17, Loss: 0.4334324428013393 58800/139232 train accuracy:0.8146768808364868
1049it [06:15,  2.81it/s]Epoch: 17, Loss: 0.41994099934895834 63000/139232 train accuracy:0.8138253688812256
1119it [06:40,  2.81it/s]Epoch: 17, Loss: 0.4138792492094494 67200/139232 train accuracy:0.8140029907226562
1189it [07:05,  2.80it/s]Epoch: 17, Loss: 0.4075256057012649 71400/139232 train accuracy:0.8139355778694153
1259it [07:30,  2.81it/s]Epoch: 17, Loss: 0.41833045596168156 75600/139232 train accuracy:0.8134788274765015
1329it [07:55,  2.82it/s]Epoch: 17, Loss: 0.4048795863560268 79800/139232 train accuracy:0.8137719035148621
1399it [08:20,  2.79it/s]Epoch: 17, Loss: 0.42023280552455355 84000/139232 train accuracy:0.8134762048721313
1469it [08:45,  2.80it/s]Epoch: 17, Loss: 0.4149609375 88200/139232 train accuracy:0.813299298286438
1539it [09:10,  2.81it/s]Epoch: 17, Loss: 0.40304417201450893 92400/139232 train accuracy:0.8134632110595703
1609it [09:35,  2.81it/s]Epoch: 17, Loss: 0.40122096470424107 96600/139232 train accuracy:0.8136646151542664
1679it [10:00,  2.80it/s]Epoch: 17, Loss: 0.4188766915457589 100800/139232 train accuracy:0.8133730292320251
1749it [10:25,  2.81it/s]Epoch: 17, Loss: 0.4196583484468006 105000/139232 train accuracy:0.8131999969482422
1819it [10:50,  2.81it/s]Epoch: 17, Loss: 0.40786873953683034 109200/139232 train accuracy:0.8133882880210876
1889it [11:15,  2.80it/s]Epoch: 17, Loss: 0.41184826078869047 113400/139232 train accuracy:0.8135273456573486
1959it [11:40,  2.82it/s]Epoch: 17, Loss: 0.4124142020089286 117600/139232 train accuracy:0.8133163452148438
2029it [12:05,  2.82it/s]Epoch: 17, Loss: 0.4055926223028274 121800/139232 train accuracy:0.8134729266166687
2099it [12:30,  2.80it/s]Epoch: 17, Loss: 0.41803484235491073 126000/139232 train accuracy:0.8131428360939026
2169it [12:55,  2.81it/s]Epoch: 17, Loss: 0.40091413225446426 130200/139232 train accuracy:0.813248872756958
2239it [13:20,  2.81it/s]Epoch: 17, Loss: 0.4033929443359375 134400/139232 train accuracy:0.8133779764175415
2309it [13:45,  2.79it/s]Epoch: 17, Loss: 0.4078029959542411 138600/139232 train accuracy:0.8133549690246582
2321it [13:49,  2.80it/s]
Epoch: 17, epoch Loss: 57148.984375  train accuracy:0.8133403062820435

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.12it/s]
Epoch: 17, Valid Loss: 6552.5947265625  valid accuracy:0.8069165945053101
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.39it/s]
Epoch: 17,   test accuracy:0.8056319952011108
37it [00:13,  2.79it/s]Epoch: 18, Loss: 0.22112899053664434 2280/139232 train accuracy:0.8184210658073425
69it [00:25,  2.80it/s]Epoch: 18, Loss: 0.18045680454799107 4200/139232 train accuracy:0.8169047832489014
139it [00:50,  2.80it/s]Epoch: 18, Loss: 0.4034879557291667 8400/139232 train accuracy:0.8169047832489014
209it [01:15,  2.79it/s]Epoch: 18, Loss: 0.4004580543154762 12600/139232 train accuracy:0.8178571462631226
279it [01:40,  2.80it/s]Epoch: 18, Loss: 0.39805919828869046 16800/139232 train accuracy:0.817380964756012
349it [02:05,  2.79it/s]Epoch: 18, Loss: 0.4216497512090774 21000/139232 train accuracy:0.8155714273452759
419it [02:30,  2.79it/s]Epoch: 18, Loss: 0.4064347040085565 25200/139232 train accuracy:0.8156349062919617
489it [02:55,  2.80it/s]Epoch: 18, Loss: 0.3909183175223214 29400/139232 train accuracy:0.8175850510597229
559it [03:20,  2.78it/s]Epoch: 18, Loss: 0.4064333961123512 33600/139232 train accuracy:0.8171131014823914
629it [03:45,  2.81it/s]Epoch: 18, Loss: 0.40854846772693454 37800/139232 train accuracy:0.8165873289108276
699it [04:10,  2.80it/s]Epoch: 18, Loss: 0.41552501860119045 42000/139232 train accuracy:0.8162857294082642
769it [04:36,  2.80it/s]Epoch: 18, Loss: 0.4057693336123512 46200/139232 train accuracy:0.8159307241439819
839it [05:01,  2.80it/s]Epoch: 18, Loss: 0.4127597191220238 50400/139232 train accuracy:0.8155754208564758
909it [05:26,  2.80it/s]Epoch: 18, Loss: 0.40327811104910716 54600/139232 train accuracy:0.81529301404953
979it [05:51,  2.79it/s]Epoch: 18, Loss: 0.3998066638764881 58800/139232 train accuracy:0.815612256526947
1049it [06:16,  2.80it/s]Epoch: 18, Loss: 0.4068047514415923 63000/139232 train accuracy:0.8156190514564514
1119it [06:41,  2.80it/s]Epoch: 18, Loss: 0.41028163364955356 67200/139232 train accuracy:0.8155654668807983
1189it [07:06,  2.80it/s]Epoch: 18, Loss: 0.4114774286179316 71400/139232 train accuracy:0.8152241110801697
1259it [07:31,  2.80it/s]Epoch: 18, Loss: 0.4098032052176339 75600/139232 train accuracy:0.8149603009223938
1329it [07:56,  2.80it/s]Epoch: 18, Loss: 0.39137898763020834 79800/139232 train accuracy:0.8154135346412659
1399it [08:21,  2.79it/s]Epoch: 18, Loss: 0.4075640578497024 84000/139232 train accuracy:0.8157261610031128
1469it [08:46,  2.78it/s]Epoch: 18, Loss: 0.42006815592447916 88200/139232 train accuracy:0.8152720928192139
1539it [09:11,  2.81it/s]Epoch: 18, Loss: 0.4062789771670387 92400/139232 train accuracy:0.8152489066123962
1609it [09:36,  2.80it/s]Epoch: 18, Loss: 0.4066662307012649 96600/139232 train accuracy:0.8151242136955261
1679it [10:01,  2.79it/s]Epoch: 18, Loss: 0.3993066987537202 100800/139232 train accuracy:0.8151488304138184
1749it [10:26,  2.80it/s]Epoch: 18, Loss: 0.3860525367373512 105000/139232 train accuracy:0.8158285617828369
1819it [10:51,  2.81it/s]Epoch: 18, Loss: 0.39793462844122024 109200/139232 train accuracy:0.8160256147384644
1889it [11:16,  2.80it/s]Epoch: 18, Loss: 0.3863897414434524 113400/139232 train accuracy:0.816428542137146
1959it [11:41,  2.80it/s]Epoch: 18, Loss: 0.40583295549665177 117600/139232 train accuracy:0.8164795637130737
2029it [12:06,  2.80it/s]Epoch: 18, Loss: 0.409346923828125 121800/139232 train accuracy:0.8165927529335022
2099it [12:31,  2.79it/s]Epoch: 18, Loss: 0.4103429013206845 126000/139232 train accuracy:0.8163889050483704
2169it [12:56,  2.80it/s]Epoch: 18, Loss: 0.3863233584449405 130200/139232 train accuracy:0.8165898323059082
2239it [13:21,  2.80it/s]Epoch: 18, Loss: 0.41533967517671133 134400/139232 train accuracy:0.8163987994194031
2309it [13:46,  2.79it/s]Epoch: 18, Loss: 0.4158810279482887 138600/139232 train accuracy:0.8162553906440735
2321it [13:50,  2.79it/s]
Epoch: 18, epoch Loss: 56349.43359375  train accuracy:0.8162634968757629

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.11it/s]
Epoch: 18, Valid Loss: 6539.0478515625  valid accuracy:0.8082094192504883
find better loss
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1078/107
8 [02:08<00:00,  8.37it/s]
Epoch: 18,   test accuracy:0.8069000840187073
37it [00:13,  2.80it/s]Epoch: 19, Loss: 0.22316391717819942 2280/139232 train accuracy:0.8131579160690308
69it [00:25,  2.79it/s]Epoch: 19, Loss: 0.189892578125 4200/139232 train accuracy:0.8050000071525574
139it [00:50,  2.78it/s]Epoch: 19, Loss: 0.39136085146949406 8400/139232 train accuracy:0.8157142996788025
209it [01:15,  2.79it/s]Epoch: 19, Loss: 0.404893798828125 12600/139232 train accuracy:0.8149206638336182
279it [01:40,  2.79it/s]Epoch: 19, Loss: 0.4069994245256696 16800/139232 train accuracy:0.8156547546386719
349it [02:05,  2.79it/s]Epoch: 19, Loss: 0.3937318057105655 21000/139232 train accuracy:0.8166666626930237
419it [02:30,  2.80it/s]Epoch: 19, Loss: 0.4059330531529018 25200/139232 train accuracy:0.8166666626930237
489it [02:55,  2.80it/s]Epoch: 19, Loss: 0.3928133428664434 29400/139232 train accuracy:0.817959189414978
559it [03:20,  2.79it/s]Epoch: 19, Loss: 0.391376226515997 33600/139232 train accuracy:0.8185714483261108
629it [03:45,  2.81it/s]Epoch: 19, Loss: 0.39252066476004466 37800/139232 train accuracy:0.8188095092773438
699it [04:10,  2.80it/s]Epoch: 19, Loss: 0.39905267624627977 42000/139232 train accuracy:0.8189523816108704
769it [04:35,  2.80it/s]Epoch: 19, Loss: 0.4068864222935268 46200/139232 train accuracy:0.8185498118400574
839it [05:01,  2.80it/s]Epoch: 19, Loss: 0.3995509847005208 50400/139232 train accuracy:0.8190873265266418
909it [05:26,  2.80it/s]Epoch: 19, Loss: 0.40211021786644346 54600/139232 train accuracy:0.8194139003753662
979it [05:51,  2.80it/s]Epoch: 19, Loss: 0.38908982049851193 58800/139232 train accuracy:0.819727897644043
1049it [06:16,  2.79it/s]Epoch: 19, Loss: 0.3977626255580357 63000/139232 train accuracy:0.8199047446250916
1119it [06:41,  2.81it/s]Epoch: 19, Loss: 0.39156729561941966 67200/139232 train accuracy:0.8200743794441223
1189it [07:06,  2.78it/s]Epoch: 19, Loss: 0.40022056942894346 71400/139232 train accuracy:0.8198179006576538
1259it [07:31,  2.79it/s]Epoch: 19, Loss: 0.38848211379278275 75600/139232 train accuracy:0.8201984167098999
1329it [07:56,  2.80it/s]Epoch: 19, Loss: 0.40258751278831845 79800/139232 train accuracy:0.8204511404037476
1399it [08:21,  2.79it/s]Epoch: 19, Loss: 0.3954932512555804 84000/139232 train accuracy:0.8203214406967163
1469it [08:46,  2.79it/s]Epoch: 19, Loss: 0.39559730166480656 88200/139232 train accuracy:0.8202381134033203
1539it [09:11,  2.80it/s]Epoch: 19, Loss: 0.39943173363095236 92400/139232 train accuracy:0.8201731443405151
1609it [09:36,  2.80it/s]Epoch: 19, Loss: 0.39579092843191965 96600/139232 train accuracy:0.8202587962150574
1679it [10:01,  2.79it/s]Epoch: 19, Loss: 0.3986955333891369 100800/139232 train accuracy:0.8202381134033203
1749it [10:26,  2.80it/s]Epoch: 19, Loss: 0.3859538051060268 105000/139232 train accuracy:0.820638120174408
1819it [10:51,  2.80it/s]Epoch: 19, Loss: 0.40411533900669644 109200/139232 train accuracy:0.8203388452529907
1889it [11:16,  2.81it/s]Epoch: 19, Loss: 0.39905450730096725 113400/139232 train accuracy:0.8199294805526733
1959it [11:41,  2.81it/s]Epoch: 19, Loss: 0.4052354503813244 117600/139232 train accuracy:0.81990647315979
2029it [12:06,  2.81it/s]Epoch: 19, Loss: 0.39633056640625 121800/139232 train accuracy:0.8199753761291504
2099it [12:31,  2.79it/s]Epoch: 19, Loss: 0.42008370535714284 126000/139232 train accuracy:0.8193888664245605
2169it [12:56,  2.82it/s]Epoch: 19, Loss: 0.3897758265904018 130200/139232 train accuracy:0.8194316625595093
2239it [13:21,  2.81it/s]Epoch: 19, Loss: 0.4050846644810268 134400/139232 train accuracy:0.8193303346633911
2309it [13:46,  2.80it/s]Epoch: 19, Loss: 0.3864160737537202 138600/139232 train accuracy:0.8196248412132263
2321it [13:50,  2.79it/s]
Epoch: 19, epoch Loss: 55460.2734375  train accuracy:0.8196966052055359

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.09it/s]
Epoch: 19, Valid Loss: 6548.8466796875  valid accuracy:0.8070458769798279
37it [00:13,  2.80it/s]Epoch: 20, Loss: 0.219341793968564 2280/139232 train accuracy:0.8166666626930237
69it [00:25,  2.80it/s]Epoch: 20, Loss: 0.18561915806361606 4200/139232 train accuracy:0.8190476298332214
139it [00:50,  2.79it/s]Epoch: 20, Loss: 0.4006482224237351 8400/139232 train accuracy:0.8171428442001343
209it [01:15,  2.78it/s]Epoch: 20, Loss: 0.40137061709449406 12600/139232 train accuracy:0.8175396919250488
279it [01:40,  2.81it/s]Epoch: 20, Loss: 0.40910557338169645 16800/139232 train accuracy:0.8168452382087708
349it [02:05,  2.79it/s]Epoch: 20, Loss: 0.38674903506324404 21000/139232 train accuracy:0.8183809518814087
419it [02:30,  2.81it/s]Epoch: 20, Loss: 0.39080793108258927 25200/139232 train accuracy:0.8193650841712952
489it [02:55,  2.81it/s]Epoch: 20, Loss: 0.3988652111235119 29400/139232 train accuracy:0.8192517161369324
559it [03:20,  2.80it/s]Epoch: 20, Loss: 0.39777099609375 33600/139232 train accuracy:0.8191071152687073
629it [03:45,  2.81it/s]Epoch: 20, Loss: 0.3809172712053571 37800/139232 train accuracy:0.8199735283851624
699it [04:10,  2.82it/s]Epoch: 20, Loss: 0.38538652692522324 42000/139232 train accuracy:0.8206190466880798
769it [04:35,  2.82it/s]Epoch: 20, Loss: 0.40058660598028273 46200/139232 train accuracy:0.8202381134033203
839it [05:00,  2.81it/s]Epoch: 20, Loss: 0.3908370245070685 50400/139232 train accuracy:0.8206745982170105
909it [05:25,  2.79it/s]Epoch: 20, Loss: 0.3953013102213542 54600/139232 train accuracy:0.8207875490188599
979it [05:50,  2.81it/s]Epoch: 20, Loss: 0.3934322974795387 58800/139232 train accuracy:0.8207823038101196
1049it [06:15,  2.81it/s]Epoch: 20, Loss: 0.3789125279017857 63000/139232 train accuracy:0.8212063312530518
1119it [06:40,  2.80it/s]Epoch: 20, Loss: 0.4004643322172619 67200/139232 train accuracy:0.8208482265472412
1189it [07:05,  2.82it/s]Epoch: 20, Loss: 0.3983090355282738 71400/139232 train accuracy:0.8206442594528198
1259it [07:30,  2.79it/s]Epoch: 20, Loss: 0.3953620837983631 75600/139232 train accuracy:0.8206613659858704
1329it [07:55,  2.80it/s]Epoch: 20, Loss: 0.38607918875558034 79800/139232 train accuracy:0.8209899663925171
1399it [08:20,  2.80it/s]Epoch: 20, Loss: 0.3995074172247024 84000/139232 train accuracy:0.8210476040840149
1469it [08:45,  2.81it/s]Epoch: 20, Loss: 0.3811613246372768 88200/139232 train accuracy:0.8214399218559265
1539it [09:10,  2.80it/s]Epoch: 20, Loss: 0.38763933454241073 92400/139232 train accuracy:0.8218614459037781
1609it [09:34,  2.81it/s]Epoch: 20, Loss: 0.3935737827845982 96600/139232 train accuracy:0.8216149210929871
1679it [10:00,  2.80it/s]Epoch: 20, Loss: 0.3910375395275298 100800/139232 train accuracy:0.8215079307556152
1749it [10:25,  2.80it/s]Epoch: 20, Loss: 0.4025892857142857 105000/139232 train accuracy:0.8214476108551025
1819it [10:50,  2.81it/s]Epoch: 20, Loss: 0.38870625813802084 109200/139232 train accuracy:0.8216117024421692
1889it [11:15,  2.80it/s]Epoch: 20, Loss: 0.3983585030691964 113400/139232 train accuracy:0.8215961456298828
1959it [11:40,  2.81it/s]Epoch: 20, Loss: 0.4055775378999256 117600/139232 train accuracy:0.8213945627212524
2029it [12:05,  2.81it/s]Epoch: 20, Loss: 0.3879460216703869 121800/139232 train accuracy:0.8216255903244019
2099it [12:30,  2.80it/s]Epoch: 20, Loss: 0.39611075265066964 126000/139232 train accuracy:0.8216349482536316
2169it [12:55,  2.79it/s]Epoch: 20, Loss: 0.39170192173549107 130200/139232 train accuracy:0.8216820359230042
2239it [13:20,  2.80it/s]Epoch: 20, Loss: 0.4018788655598958 134400/139232 train accuracy:0.8214806318283081
2309it [13:45,  2.80it/s]Epoch: 20, Loss: 0.3822578938802083 138600/139232 train accuracy:0.8215945363044739
2321it [13:49,  2.80it/s]
Epoch: 20, epoch Loss: 54886.6015625  train accuracy:0.8215209245681763

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.11it/s]
Epoch: 20, Valid Loss: 6570.3359375  valid accuracy:0.8066580295562744
37it [00:13,  2.81it/s]Epoch: 21, Loss: 0.21077896844773064 2280/139232 train accuracy:0.8214912414550781
69it [00:25,  2.81it/s]Epoch: 21, Loss: 0.17417400541759673 4200/139232 train accuracy:0.8219047784805298
139it [00:50,  2.81it/s]Epoch: 21, Loss: 0.3918252999441964 8400/139232 train accuracy:0.8207142949104309
209it [01:15,  2.80it/s]Epoch: 21, Loss: 0.38982427687872023 12600/139232 train accuracy:0.8211110830307007
279it [01:40,  2.79it/s]Epoch: 21, Loss: 0.38944147019159225 16800/139232 train accuracy:0.8207142949104309
349it [02:05,  2.80it/s]Epoch: 21, Loss: 0.3838627697172619 21000/139232 train accuracy:0.8224285840988159
419it [02:30,  2.78it/s]Epoch: 21, Loss: 0.38206226167224705 25200/139232 train accuracy:0.822857141494751
489it [02:55,  2.80it/s]Epoch: 21, Loss: 0.37520048595610117 29400/139232 train accuracy:0.8240135908126831
559it [03:20,  2.80it/s]Epoch: 21, Loss: 0.37744041806175593 33600/139232 train accuracy:0.8247321248054504
629it [03:45,  2.79it/s]Epoch: 21, Loss: 0.39380952380952383 37800/139232 train accuracy:0.8248412609100342
699it [04:10,  2.81it/s]Epoch: 21, Loss: 0.3765487816220238 42000/139232 train accuracy:0.8256190419197083
769it [04:35,  2.82it/s]Epoch: 21, Loss: 0.3816723342168899 46200/139232 train accuracy:0.8260389566421509
839it [05:00,  2.81it/s]Epoch: 21, Loss: 0.38210196358816967 50400/139232 train accuracy:0.8263293504714966
909it [05:25,  2.80it/s]Epoch: 21, Loss: 0.37735775902157737 54600/139232 train accuracy:0.8267216086387634
979it [05:50,  2.81it/s]Epoch: 21, Loss: 0.38051891508556546 58800/139232 train accuracy:0.8265306353569031
1049it [06:15,  2.79it/s]Epoch: 21, Loss: 0.3788438197544643 63000/139232 train accuracy:0.8270000219345093
1119it [06:40,  2.80it/s]Epoch: 21, Loss: 0.3957937476748512 67200/139232 train accuracy:0.8264136910438538
1189it [07:05,  2.80it/s]Epoch: 21, Loss: 0.3911190650576637 71400/139232 train accuracy:0.8263305425643921
1259it [07:30,  2.79it/s]Epoch: 21, Loss: 0.39620050339471724 75600/139232 train accuracy:0.8259920477867126
1329it [07:55,  2.78it/s]Epoch: 21, Loss: 0.3997377232142857 79800/139232 train accuracy:0.8255137801170349
1399it [08:20,  2.80it/s]Epoch: 21, Loss: 0.38370596749441965 84000/139232 train accuracy:0.8258809447288513
1469it [08:45,  2.79it/s]Epoch: 21, Loss: 0.40248677571614583 88200/139232 train accuracy:0.8256009221076965
1539it [09:10,  2.81it/s]Epoch: 21, Loss: 0.3996978759765625 92400/139232 train accuracy:0.8253571391105652
1609it [09:35,  2.80it/s]Epoch: 21, Loss: 0.3789064534505208 96600/139232 train accuracy:0.8256003856658936
1679it [10:01,  2.76it/s]Epoch: 21, Loss: 0.3868308512369792 100800/139232 train accuracy:0.8258234262466431
1749it [10:26,  2.81it/s]Epoch: 21, Loss: 0.3944493756975446 105000/139232 train accuracy:0.8258000016212463
1819it [10:51,  2.81it/s]Epoch: 21, Loss: 0.38637820289248515 109200/139232 train accuracy:0.8258150219917297
1889it [11:16,  2.79it/s]Epoch: 21, Loss: 0.39205784388950893 113400/139232 train accuracy:0.8255026340484619
1959it [11:41,  2.81it/s]Epoch: 21, Loss: 0.39062677292596726 117600/139232 train accuracy:0.8255016803741455
2029it [12:06,  2.79it/s]Epoch: 21, Loss: 0.3886864943731399 121800/139232 train accuracy:0.8255665302276611
2099it [12:31,  2.79it/s]Epoch: 21, Loss: 0.39578572591145833 126000/139232 train accuracy:0.825420618057251
2169it [12:56,  2.81it/s]Epoch: 21, Loss: 0.39137515113467264 130200/139232 train accuracy:0.8254531621932983
2239it [13:21,  2.80it/s]Epoch: 21, Loss: 0.38570905412946427 134400/139232 train accuracy:0.8254464268684387
2309it [13:46,  2.80it/s]Epoch: 21, Loss: 0.39712207612537204 138600/139232 train accuracy:0.825194776058197
2321it [13:50,  2.79it/s]
Epoch: 21, epoch Loss: 54005.609375  train accuracy:0.8252341151237488

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.11it/s]
Epoch: 21, Valid Loss: 6591.44921875  valid accuracy:0.8043309450149536
37it [00:13,  2.80it/s]Epoch: 22, Loss: 0.21113553001767113 2280/139232 train accuracy:0.8280701637268066
69it [00:25,  2.80it/s]Epoch: 22, Loss: 0.17901075090680804 4200/139232 train accuracy:0.8254761695861816
139it [00:50,  2.82it/s]Epoch: 22, Loss: 0.37859880719866074 8400/139232 train accuracy:0.825952410697937
209it [01:15,  2.78it/s]Epoch: 22, Loss: 0.3758896891276042 12600/139232 train accuracy:0.8284127116203308
279it [01:40,  2.81it/s]Epoch: 22, Loss: 0.3746213204520089 16800/139232 train accuracy:0.8307142853736877
349it [02:04,  2.80it/s]Epoch: 22, Loss: 0.38227582659040177 21000/139232 train accuracy:0.8289047479629517
419it [02:29,  2.81it/s]Epoch: 22, Loss: 0.3740391613188244 25200/139232 train accuracy:0.8290476202964783
489it [02:54,  2.80it/s]Epoch: 22, Loss: 0.3817776053292411 29400/139232 train accuracy:0.82833331823349
559it [03:20,  2.81it/s]Epoch: 22, Loss: 0.3770322091238839 33600/139232 train accuracy:0.8291666507720947
629it [03:45,  2.81it/s]Epoch: 22, Loss: 0.3920889427548363 37800/139232 train accuracy:0.8279629349708557
699it [04:10,  2.81it/s]Epoch: 22, Loss: 0.3747207496279762 42000/139232 train accuracy:0.8284761905670166
769it [04:35,  2.82it/s]Epoch: 22, Loss: 0.37923868815104167 46200/139232 train accuracy:0.8282900452613831
839it [05:00,  2.81it/s]Epoch: 22, Loss: 0.3914774867466518 50400/139232 train accuracy:0.8284524083137512
909it [05:25,  2.81it/s]Epoch: 22, Loss: 0.3739155796595982 54600/139232 train accuracy:0.8288278579711914
979it [05:49,  2.81it/s]Epoch: 22, Loss: 0.38089942568824403 58800/139232 train accuracy:0.8285714387893677
1049it [06:14,  2.81it/s]Epoch: 22, Loss: 0.3768057105654762 63000/139232 train accuracy:0.8289047479629517
1119it [06:39,  2.80it/s]Epoch: 22, Loss: 0.399742925734747 67200/139232 train accuracy:0.8285416960716248
1189it [07:04,  2.82it/s]Epoch: 22, Loss: 0.3754942103794643 71400/139232 train accuracy:0.8286694884300232
1259it [07:29,  2.80it/s]Epoch: 22, Loss: 0.3675343540736607 75600/139232 train accuracy:0.828941822052002
1329it [07:54,  2.80it/s]Epoch: 22, Loss: 0.39670910063244047 79800/139232 train accuracy:0.8282957673072815
1399it [08:19,  2.80it/s]Epoch: 22, Loss: 0.3877716064453125 84000/139232 train accuracy:0.8283214569091797
1469it [08:44,  2.80it/s]Epoch: 22, Loss: 0.37430579775855655 88200/139232 train accuracy:0.8284693956375122
1539it [09:09,  2.81it/s]Epoch: 22, Loss: 0.3854327392578125 92400/139232 train accuracy:0.8283766508102417
1609it [09:34,  2.81it/s]Epoch: 22, Loss: 0.39005182175409225 96600/139232 train accuracy:0.8281055688858032
1679it [09:59,  2.74it/s]Epoch: 22, Loss: 0.3884272984095982 100800/139232 train accuracy:0.8281051516532898
1749it [10:24,  2.81it/s]Epoch: 22, Loss: 0.38883629208519344 105000/139232 train accuracy:0.8279713988304138
1819it [10:49,  2.81it/s]Epoch: 22, Loss: 0.38035226004464284 109200/139232 train accuracy:0.8280768990516663
1889it [11:14,  2.81it/s]Epoch: 22, Loss: 0.3691153099423363 113400/139232 train accuracy:0.82833331823349
1959it [11:39,  2.80it/s]Epoch: 22, Loss: 0.37319463820684523 117600/139232 train accuracy:0.8286224603652954
2029it [12:04,  2.82it/s]Epoch: 22, Loss: 0.37952061244419644 121800/139232 train accuracy:0.8287109732627869
2099it [12:29,  2.81it/s]Epoch: 22, Loss: 0.3768398902529762 126000/139232 train accuracy:0.8287063241004944
2169it [12:54,  2.79it/s]Epoch: 22, Loss: 0.38058724539620536 130200/139232 train accuracy:0.8287941813468933
2239it [13:19,  2.82it/s]Epoch: 22, Loss: 0.37100652785528276 134400/139232 train accuracy:0.828913688659668
2309it [13:44,  2.81it/s]Epoch: 22, Loss: 0.3758139183407738 138600/139232 train accuracy:0.8292496204376221
2321it [13:48,  2.80it/s]
Epoch: 22, epoch Loss: 53004.734375  train accuracy:0.82929927110672

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.12it/s]
Epoch: 22, Valid Loss: 6564.79345703125  valid accuracy:0.8084033727645874
37it [00:13,  2.81it/s]Epoch: 23, Loss: 0.19419451032366072 2280/139232 train accuracy:0.8390350937843323
69it [00:25,  2.81it/s]Epoch: 23, Loss: 0.16624758765811012 4200/139232 train accuracy:0.8366666436195374
139it [00:50,  2.81it/s]Epoch: 23, Loss: 0.3789164225260417 8400/139232 train accuracy:0.8336904644966125
209it [01:15,  2.80it/s]Epoch: 23, Loss: 0.3897213309151786 12600/139232 train accuracy:0.8307142853736877
279it [01:40,  2.78it/s]Epoch: 23, Loss: 0.3915895298549107 16800/139232 train accuracy:0.8276190757751465
349it [02:04,  2.81it/s]Epoch: 23, Loss: 0.37675086611793157 21000/139232 train accuracy:0.827571451663971
419it [02:29,  2.81it/s]Epoch: 23, Loss: 0.3806948997860863 25200/139232 train accuracy:0.8271031975746155
489it [02:54,  2.81it/s]Epoch: 23, Loss: 0.36311816987537204 29400/139232 train accuracy:0.8291836977005005
559it [03:20,  2.80it/s]Epoch: 23, Loss: 0.3766364978608631 33600/139232 train accuracy:0.8295535445213318
629it [03:45,  2.79it/s]Epoch: 23, Loss: 0.3854733131045387 37800/139232 train accuracy:0.8298677206039429
699it [04:10,  2.80it/s]Epoch: 23, Loss: 0.37577503022693454 42000/139232 train accuracy:0.829714298248291
769it [04:35,  2.80it/s]Epoch: 23, Loss: 0.3714110456194196 46200/139232 train accuracy:0.8301082253456116
839it [05:00,  2.80it/s]Epoch: 23, Loss: 0.3799749465215774 50400/139232 train accuracy:0.8298611044883728
909it [05:25,  2.80it/s]Epoch: 23, Loss: 0.3656386311848958 54600/139232 train accuracy:0.830531120300293
979it [05:50,  2.80it/s]Epoch: 23, Loss: 0.3701154436383929 58800/139232 train accuracy:0.8309863805770874
1049it [06:15,  2.80it/s]Epoch: 23, Loss: 0.37898399716331843 63000/139232 train accuracy:0.8309682607650757
1119it [06:40,  2.79it/s]Epoch: 23, Loss: 0.37046177455357143 67200/139232 train accuracy:0.831250011920929
1189it [07:05,  2.79it/s]Epoch: 23, Loss: 0.36432076590401785 71400/139232 train accuracy:0.83173668384552
1259it [07:30,  2.81it/s]Epoch: 23, Loss: 0.3689886765252976 75600/139232 train accuracy:0.8318915367126465
1329it [07:55,  2.78it/s]Epoch: 23, Loss: 0.3653544689360119 79800/139232 train accuracy:0.8321303129196167
1399it [08:20,  2.80it/s]Epoch: 23, Loss: 0.3763116745721726 84000/139232 train accuracy:0.8320476412773132
1469it [08:45,  2.81it/s]Epoch: 23, Loss: 0.3702223132905506 88200/139232 train accuracy:0.8321881890296936
1539it [09:10,  2.81it/s]Epoch: 23, Loss: 0.3706990269252232 92400/139232 train accuracy:0.8325324654579163
1609it [09:35,  2.80it/s]Epoch: 23, Loss: 0.3625166538783482 96600/139232 train accuracy:0.8327846527099609
1679it [10:00,  2.66it/s]Epoch: 23, Loss: 0.37285641624813987 100800/139232 train accuracy:0.8328670859336853
1749it [10:25,  2.81it/s]Epoch: 23, Loss: 0.3773967052641369 105000/139232 train accuracy:0.8328857421875
1819it [10:50,  2.80it/s]Epoch: 23, Loss: 0.3696575637090774 109200/139232 train accuracy:0.8329487442970276
1889it [11:15,  2.80it/s]Epoch: 23, Loss: 0.37664713541666667 113400/139232 train accuracy:0.8326454758644104
1959it [11:40,  2.81it/s]Epoch: 23, Loss: 0.38505013602120536 117600/139232 train accuracy:0.8323469161987305
2029it [12:05,  2.80it/s]Epoch: 23, Loss: 0.3916353062220982 121800/139232 train accuracy:0.8320443630218506
2099it [12:30,  2.81it/s]Epoch: 23, Loss: 0.37896815708705356 126000/139232 train accuracy:0.8319761753082275
2169it [12:55,  2.81it/s]Epoch: 23, Loss: 0.37415367489769347 130200/139232 train accuracy:0.8320583701133728
2239it [13:20,  2.80it/s]Epoch: 23, Loss: 0.37152945382254465 134400/139232 train accuracy:0.8322544693946838
2309it [13:45,  2.80it/s]Epoch: 23, Loss: 0.36543730236235117 138600/139232 train accuracy:0.8323160409927368
2321it [13:49,  2.80it/s]
Epoch: 23, epoch Loss: 52150.046875  train accuracy:0.8322655558586121

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.10it/s]
Epoch: 23, Valid Loss: 6606.93896484375  valid accuracy:0.8042016625404358
37it [00:13,  2.81it/s]Epoch: 24, Loss: 0.20034608386811756 2280/139232 train accuracy:0.8333333134651184
69it [00:25,  2.79it/s]Epoch: 24, Loss: 0.16158053443545387 4200/139232 train accuracy:0.8357142806053162
139it [00:50,  2.81it/s]Epoch: 24, Loss: 0.3834495617094494 8400/139232 train accuracy:0.8336904644966125
209it [01:15,  2.81it/s]Epoch: 24, Loss: 0.37649623325892856 12600/139232 train accuracy:0.8307936787605286
279it [01:40,  2.81it/s]Epoch: 24, Loss: 0.3535228038969494 16800/139232 train accuracy:0.8342261910438538
349it [02:05,  2.80it/s]Epoch: 24, Loss: 0.37449393136160714 21000/139232 train accuracy:0.8347142934799194
419it [02:30,  2.80it/s]Epoch: 24, Loss: 0.3699527122860863 25200/139232 train accuracy:0.8347222208976746
489it [02:55,  2.80it/s]Epoch: 24, Loss: 0.37357852027529764 29400/139232 train accuracy:0.8349660038948059
559it [03:20,  2.81it/s]Epoch: 24, Loss: 0.3731492978050595 33600/139232 train accuracy:0.8349106907844543
629it [03:45,  2.81it/s]Epoch: 24, Loss: 0.366322021484375 37800/139232 train accuracy:0.8351587057113647
699it [04:10,  2.80it/s]Epoch: 24, Loss: 0.3676904587518601 42000/139232 train accuracy:0.8352142572402954
769it [04:35,  2.81it/s]Epoch: 24, Loss: 0.373546142578125 46200/139232 train accuracy:0.8353896141052246
839it [05:00,  2.81it/s]Epoch: 24, Loss: 0.37078206380208334 50400/139232 train accuracy:0.8352976441383362
909it [05:25,  2.81it/s]Epoch: 24, Loss: 0.3664549328031994 54600/139232 train accuracy:0.8355494737625122
979it [05:50,  2.81it/s]Epoch: 24, Loss: 0.34966020856584823 58800/139232 train accuracy:0.8363945484161377
1049it [06:15,  2.81it/s]Epoch: 24, Loss: 0.36500982375372026 63000/139232 train accuracy:0.8367778062820435
1119it [06:40,  2.80it/s]Epoch: 24, Loss: 0.3729515148344494 67200/139232 train accuracy:0.8364136815071106
1189it [07:05,  2.82it/s]Epoch: 24, Loss: 0.35788809640066965 71400/139232 train accuracy:0.8367787003517151
1259it [07:30,  2.80it/s]Epoch: 24, Loss: 0.3625768461681548 75600/139232 train accuracy:0.8367725014686584
1329it [07:55,  2.80it/s]Epoch: 24, Loss: 0.3782473900204613 79800/139232 train accuracy:0.8364160656929016
1399it [08:20,  2.77it/s]Epoch: 24, Loss: 0.385666998000372 84000/139232 train accuracy:0.8359047770500183
1469it [08:45,  2.80it/s]Epoch: 24, Loss: 0.3849264962332589 88200/139232 train accuracy:0.8355555534362793
1539it [09:10,  2.77it/s]Epoch: 24, Loss: 0.3569854445684524 92400/139232 train accuracy:0.8358766436576843
1609it [09:35,  2.81it/s]Epoch: 24, Loss: 0.3603020949590774 96600/139232 train accuracy:0.8360558748245239
1679it [10:00,  2.51it/s]Epoch: 24, Loss: 0.3657608177548363 100800/139232 train accuracy:0.835972249507904
1749it [10:25,  2.77it/s]Epoch: 24, Loss: 0.36275224958147323 105000/139232 train accuracy:0.8360666632652283
1819it [10:51,  2.82it/s]Epoch: 24, Loss: 0.35700477236793154 109200/139232 train accuracy:0.8362179398536682
1889it [11:16,  2.78it/s]Epoch: 24, Loss: 0.3748126220703125 113400/139232 train accuracy:0.8361728191375732
1959it [11:41,  2.81it/s]Epoch: 24, Loss: 0.3674216715494792 117600/139232 train accuracy:0.8363180160522461
2029it [12:06,  2.78it/s]Epoch: 24, Loss: 0.37150974818638394 121800/139232 train accuracy:0.836223304271698
2099it [12:31,  2.79it/s]Epoch: 24, Loss: 0.3616757347470238 126000/139232 train accuracy:0.8362063765525818
2169it [12:56,  2.77it/s]Epoch: 24, Loss: 0.36814979189918157 130200/139232 train accuracy:0.8363978266716003
2239it [13:21,  2.80it/s]Epoch: 24, Loss: 0.3658954438709077 134400/139232 train accuracy:0.836510419845581
2309it [13:46,  2.78it/s]Epoch: 24, Loss: 0.3746822974795387 138600/139232 train accuracy:0.8363203406333923
2321it [13:50,  2.79it/s]
Epoch: 24, epoch Loss: 51274.0859375  train accuracy:0.8364312648773193

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.13it/s]
Epoch: 24, Valid Loss: 6580.1025390625  valid accuracy:0.8083387017250061
37it [00:13,  2.78it/s]Epoch: 25, Loss: 0.18610151018415177 2280/139232 train accuracy:0.851754367351532
69it [00:25,  2.77it/s]Epoch: 25, Loss: 0.152183111281622 4200/139232 train accuracy:0.8526190519332886
139it [00:50,  2.76it/s]Epoch: 25, Loss: 0.35682779947916665 8400/139232 train accuracy:0.8478571176528931
209it [01:15,  2.77it/s]Epoch: 25, Loss: 0.3577382114955357 12600/139232 train accuracy:0.8470634818077087
279it [01:40,  2.81it/s]Epoch: 25, Loss: 0.35338460286458334 16800/139232 train accuracy:0.8469047546386719
349it [02:05,  2.78it/s]Epoch: 25, Loss: 0.3690655808221726 21000/139232 train accuracy:0.8446666598320007
419it [02:31,  2.78it/s]Epoch: 25, Loss: 0.3845445324125744 25200/139232 train accuracy:0.841865062713623
489it [02:56,  2.78it/s]Epoch: 25, Loss: 0.3566475132533482 29400/139232 train accuracy:0.842380940914154
559it [03:21,  2.78it/s]Epoch: 25, Loss: 0.37709216889880953 33600/139232 train accuracy:0.8410714268684387
629it [03:46,  2.78it/s]Epoch: 25, Loss: 0.3515977550688244 37800/139232 train accuracy:0.841005265712738
699it [04:11,  2.81it/s]Epoch: 25, Loss: 0.3644905308314732 42000/139232 train accuracy:0.8405952453613281
769it [04:36,  2.81it/s]Epoch: 25, Loss: 0.3513917468843006 46200/139232 train accuracy:0.8417532444000244
839it [05:01,  2.78it/s]Epoch: 25, Loss: 0.35469447544642857 50400/139232 train accuracy:0.8415277600288391
909it [05:26,  2.77it/s]Epoch: 25, Loss: 0.37332568940662203 54600/139232 train accuracy:0.8402197957038879
979it [05:51,  2.79it/s]Epoch: 25, Loss: 0.3641832624162946 58800/139232 train accuracy:0.8403061032295227
1049it [06:17,  2.76it/s]Epoch: 25, Loss: 0.3544064767020089 63000/139232 train accuracy:0.8406349420547485
1119it [06:42,  2.81it/s]Epoch: 25, Loss: 0.3733669607979911 67200/139232 train accuracy:0.8402231931686401
1189it [07:07,  2.77it/s]Epoch: 25, Loss: 0.3520213099888393 71400/139232 train accuracy:0.8404902219772339
1259it [07:32,  2.78it/s]Epoch: 25, Loss: 0.3575985572451637 75600/139232 train accuracy:0.8405687808990479
1329it [07:57,  2.81it/s]Epoch: 25, Loss: 0.35237920851934523 79800/139232 train accuracy:0.8409398794174194
1399it [08:22,  2.78it/s]Epoch: 25, Loss: 0.3723642113095238 84000/139232 train accuracy:0.8403928279876709
1469it [08:47,  2.80it/s]Epoch: 25, Loss: 0.3575489734468006 88200/139232 train accuracy:0.8406009078025818
1539it [09:12,  2.82it/s]Epoch: 25, Loss: 0.3589213634672619 92400/139232 train accuracy:0.8405194878578186
1609it [09:37,  2.80it/s]Epoch: 25, Loss: 0.36375479561941965 96600/139232 train accuracy:0.8405796885490417
1679it [10:03,  2.28it/s]Epoch: 25, Loss: 0.34800981794084823 100800/139232 train accuracy:0.8407242298126221
1749it [10:28,  2.79it/s]Epoch: 25, Loss: 0.3715649123418899 105000/139232 train accuracy:0.8403618931770325
1819it [10:53,  2.80it/s]Epoch: 25, Loss: 0.35822021484375 109200/139232 train accuracy:0.8404578566551208
1889it [11:18,  2.79it/s]Epoch: 25, Loss: 0.3717213076636905 113400/139232 train accuracy:0.8399029970169067
1959it [11:43,  2.76it/s]Epoch: 25, Loss: 0.3694563220796131 117600/139232 train accuracy:0.8395153284072876
2029it [12:08,  2.81it/s]Epoch: 25, Loss: 0.36251255580357145 121800/139232 train accuracy:0.8395237922668457
2099it [12:33,  2.81it/s]Epoch: 25, Loss: 0.3689699009486607 126000/139232 train accuracy:0.8395158648490906
2169it [12:58,  2.80it/s]Epoch: 25, Loss: 0.3737568591889881 130200/139232 train accuracy:0.8393087387084961
2239it [13:23,  2.76it/s]Epoch: 25, Loss: 0.3506956845238095 134400/139232 train accuracy:0.8393303751945496
2309it [13:48,  2.78it/s]Epoch: 25, Loss: 0.37580970400855657 138600/139232 train accuracy:0.8391702771186829
2321it [13:53,  2.79it/s]
Epoch: 25, epoch Loss: 50416.1171875  train accuracy:0.839110255241394

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.12it/s]
Epoch: 25, Valid Loss: 6651.0546875  valid accuracy:0.8030381202697754
37it [00:13,  2.80it/s]Epoch: 26, Loss: 0.19245275588262648 2280/139232 train accuracy:0.8337719440460205
69it [00:25,  2.81it/s]Epoch: 26, Loss: 0.14957781110491072 4200/139232 train accuracy:0.8461904525756836
139it [00:50,  2.80it/s]Epoch: 26, Loss: 0.3676824951171875 8400/139232 train accuracy:0.840833306312561
209it [01:15,  2.78it/s]Epoch: 26, Loss: 0.3522612072172619 12600/139232 train accuracy:0.8434920907020569
279it [01:40,  2.78it/s]Epoch: 26, Loss: 0.36231619698660716 16800/139232 train accuracy:0.8446428775787354
349it [02:05,  2.82it/s]Epoch: 26, Loss: 0.337515375046503 21000/139232 train accuracy:0.8464285731315613
419it [02:30,  2.81it/s]Epoch: 26, Loss: 0.35878775460379464 25200/139232 train accuracy:0.8449603319168091
489it [02:55,  2.78it/s]Epoch: 26, Loss: 0.3576334926060268 29400/139232 train accuracy:0.844149649143219
559it [03:20,  2.81it/s]Epoch: 26, Loss: 0.3444179861886161 33600/139232 train accuracy:0.8448511958122253
629it [03:45,  2.80it/s]Epoch: 26, Loss: 0.36383443196614584 37800/139232 train accuracy:0.8447089791297913
699it [04:10,  2.81it/s]Epoch: 26, Loss: 0.36379478817894345 42000/139232 train accuracy:0.8442142605781555
769it [04:35,  2.77it/s]Epoch: 26, Loss: 0.3495845249720982 46200/139232 train accuracy:0.8442640900611877
839it [05:00,  2.76it/s]Epoch: 26, Loss: 0.34677545456659226 50400/139232 train accuracy:0.844781756401062
909it [05:25,  2.81it/s]Epoch: 26, Loss: 0.34855169387090773 54600/139232 train accuracy:0.8450366258621216
979it [05:50,  2.79it/s]Epoch: 26, Loss: 0.3612281436011905 58800/139232 train accuracy:0.8444387912750244
1049it [06:16,  2.78it/s]Epoch: 26, Loss: 0.3593989780970982 63000/139232 train accuracy:0.8441587090492249
1119it [06:41,  2.78it/s]Epoch: 26, Loss: 0.3551806640625 67200/139232 train accuracy:0.8443005681037903
1189it [07:06,  2.81it/s]Epoch: 26, Loss: 0.35762515113467264 71400/139232 train accuracy:0.8440476059913635
1259it [07:31,  2.81it/s]Epoch: 26, Loss: 0.3408158947172619 75600/139232 train accuracy:0.8447486758232117
1329it [07:56,  2.81it/s]Epoch: 26, Loss: 0.3554760451543899 79800/139232 train accuracy:0.8445739150047302
1399it [08:21,  2.79it/s]Epoch: 26, Loss: 0.36674961635044645 84000/139232 train accuracy:0.8442500233650208
1469it [08:46,  2.81it/s]Epoch: 26, Loss: 0.3402563185918899 88200/139232 train accuracy:0.8446031808853149
1539it [09:11,  2.80it/s]Epoch: 26, Loss: 0.33606648763020835 92400/139232 train accuracy:0.8449783325195312
1609it [09:36,  2.79it/s]Epoch: 26, Loss: 0.3652395193917411 96600/139232 train accuracy:0.8448033332824707
1679it [10:01,  2.81it/s]Epoch: 26, Loss: 0.35753470284598216 100800/139232 train accuracy:0.8445833325386047
1749it [10:26,  2.81it/s]Epoch: 26, Loss: 0.35912405831473215 105000/139232 train accuracy:0.8445333242416382
1819it [10:51,  2.81it/s]Epoch: 26, Loss: 0.3460871814546131 109200/139232 train accuracy:0.8444780111312866
1889it [11:16,  2.79it/s]Epoch: 26, Loss: 0.3454147484188988 113400/139232 train accuracy:0.8448412418365479
1959it [11:41,  2.80it/s]Epoch: 26, Loss: 0.35555873325892856 117600/139232 train accuracy:0.8447619080543518
2029it [12:06,  2.80it/s]Epoch: 26, Loss: 0.35018668038504464 121800/139232 train accuracy:0.8447372913360596
2099it [12:31,  2.80it/s]Epoch: 26, Loss: 0.35799220493861605 126000/139232 train accuracy:0.8448016047477722
2169it [12:56,  2.80it/s]Epoch: 26, Loss: 0.3566254243396577 130200/139232 train accuracy:0.8448233604431152
2239it [13:21,  2.79it/s]Epoch: 26, Loss: 0.3517541213262649 134400/139232 train accuracy:0.8446577191352844
2309it [13:46,  2.81it/s]Epoch: 26, Loss: 0.3439158412388393 138600/139232 train accuracy:0.8448196053504944
2321it [13:50,  2.79it/s]
Epoch: 26, epoch Loss: 49181.5625  train accuracy:0.8447770476341248

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.12it/s]
Epoch: 26, Valid Loss: 6654.34130859375  valid accuracy:0.8057530522346497
37it [00:13,  2.81it/s]Epoch: 27, Loss: 0.18569925944010415 2280/139232 train accuracy:0.8495613932609558
69it [00:25,  2.80it/s]Epoch: 27, Loss: 0.1524764142717634 4200/139232 train accuracy:0.8504762053489685
139it [00:50,  2.80it/s]Epoch: 27, Loss: 0.34685828799293156 8400/139232 train accuracy:0.8478571176528931
209it [01:15,  2.81it/s]Epoch: 27, Loss: 0.34680158342633927 12600/139232 train accuracy:0.8487301468849182
279it [01:40,  2.79it/s]Epoch: 27, Loss: 0.33661289760044644 16800/139232 train accuracy:0.8503571152687073
349it [02:05,  2.81it/s]Epoch: 27, Loss: 0.3520560709635417 21000/139232 train accuracy:0.8496190309524536
419it [02:30,  2.81it/s]Epoch: 27, Loss: 0.3622986130487351 25200/139232 train accuracy:0.8476190567016602
489it [02:55,  2.79it/s]Epoch: 27, Loss: 0.33604274204799106 29400/139232 train accuracy:0.847449004650116
559it [03:20,  2.80it/s]Epoch: 27, Loss: 0.3416471644810268 33600/139232 train accuracy:0.8482142686843872
629it [03:45,  2.81it/s]Epoch: 27, Loss: 0.34522115071614584 37800/139232 train accuracy:0.8484391570091248
699it [04:10,  2.80it/s]Epoch: 27, Loss: 0.3486580403645833 42000/139232 train accuracy:0.8482857346534729
769it [04:35,  2.79it/s]Epoch: 27, Loss: 0.34743108840215775 46200/139232 train accuracy:0.8483549952507019
839it [05:00,  2.80it/s]Epoch: 27, Loss: 0.3558685302734375 50400/139232 train accuracy:0.8479762077331543
909it [05:25,  2.80it/s]Epoch: 27, Loss: 0.34786844889322915 54600/139232 train accuracy:0.8483333587646484
979it [05:50,  2.78it/s]Epoch: 27, Loss: 0.3513558523995536 58800/139232 train accuracy:0.8481122255325317
1049it [06:15,  2.79it/s]Epoch: 27, Loss: 0.34495887393043156 63000/139232 train accuracy:0.8479999899864197
1119it [06:40,  2.81it/s]Epoch: 27, Loss: 0.34870265415736607 67200/139232 train accuracy:0.848229169845581
1189it [07:05,  2.80it/s]Epoch: 27, Loss: 0.34606677827380955 71400/139232 train accuracy:0.848109245300293
1259it [07:30,  2.81it/s]Epoch: 27, Loss: 0.3557225690569196 75600/139232 train accuracy:0.8474206328392029
1329it [07:55,  2.81it/s]Epoch: 27, Loss: 0.34525605701264883 79800/139232 train accuracy:0.8473809361457825
1399it [08:20,  2.80it/s]Epoch: 27, Loss: 0.33389453706287203 84000/139232 train accuracy:0.8477023839950562
1469it [08:45,  2.80it/s]Epoch: 27, Loss: 0.3368771507626488 88200/139232 train accuracy:0.8481292724609375
1539it [09:10,  2.79it/s]Epoch: 27, Loss: 0.34693827311197917 92400/139232 train accuracy:0.8479762077331543
1609it [09:35,  2.82it/s]Epoch: 27, Loss: 0.3453504289899554 96600/139232 train accuracy:0.847888171672821
1679it [10:00,  2.79it/s]Epoch: 27, Loss: 0.34527445475260415 100800/139232 train accuracy:0.8479762077331543
1749it [10:26,  2.80it/s]Epoch: 27, Loss: 0.32762108212425595 105000/139232 train accuracy:0.8485714197158813
1819it [10:51,  2.79it/s]Epoch: 27, Loss: 0.35375799269903274 109200/139232 train accuracy:0.8481684923171997
1889it [11:16,  2.80it/s]Epoch: 27, Loss: 0.3386724562872024 113400/139232 train accuracy:0.8484479784965515
1959it [11:41,  2.79it/s]Epoch: 27, Loss: 0.3292857142857143 117600/139232 train accuracy:0.8487585186958313
2029it [12:06,  2.79it/s]Epoch: 27, Loss: 0.3625973946707589 121800/139232 train accuracy:0.8484482765197754
2099it [12:31,  2.80it/s]Epoch: 27, Loss: 0.34305829729352677 126000/139232 train accuracy:0.848642885684967
2169it [12:56,  2.79it/s]Epoch: 27, Loss: 0.3511916097005208 130200/139232 train accuracy:0.8484715819358826
2239it [13:21,  2.80it/s]Epoch: 27, Loss: 0.3515425618489583 134400/139232 train accuracy:0.8482738137245178
2309it [13:46,  2.79it/s]Epoch: 27, Loss: 0.3611723109654018 138600/139232 train accuracy:0.8480880260467529
2321it [13:50,  2.79it/s]
Epoch: 27, epoch Loss: 48201.6015625  train accuracy:0.8480880856513977

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/25
8 [00:31<00:00,  8.12it/s]
Epoch: 27, Valid Loss: 6680.29931640625  valid accuracy:0.8037492036819458
37it [00:13,  2.78it/s]Epoch: 28, Loss: 0.18516903831845238 2280/139232 train accuracy:0.8521929979324341
69it [00:25,  2.79it/s]Epoch: 28, Loss: 0.14987227666945685 4200/139232 train accuracy:0.8557142615318298
139it [00:50,  2.80it/s]Epoch: 28, Loss: 0.33985438755580355 8400/139232 train accuracy:0.8559523820877075
209it [01:15,  2.81it/s]Epoch: 28, Loss: 0.33103626069568454 12600/139232 train accuracy:0.855555534362793
279it [01:40,  2.80it/s]Epoch: 28, Loss: 0.3261334809802827 16800/139232 train accuracy:0.8552976250648499
349it [02:05,  2.80it/s]Epoch: 28, Loss: 0.32879612513950895 21000/139232 train accuracy:0.8563809394836426
419it [02:30,  2.79it/s]Epoch: 28, Loss: 0.34618570963541667 25200/139232 train accuracy:0.8547618985176086
489it [02:55,  2.80it/s]Epoch: 28, Loss: 0.3358839925130208 29400/139232 train accuracy:0.8548639416694641
559it [03:20,  2.77it/s]Epoch: 28, Loss: 0.3454281761532738 33600/139232 train accuracy:0.8546130657196045
629it [03:45,  2.81it/s]Epoch: 28, Loss: 0.3371598888578869 37800/139232 train accuracy:0.8547883629798889
659it [03:56,  2.79it/s]^C
Traceback (most recent call last):
  File "/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src/train_bert_proto_cascade_add_loss.py", line 565, in <module>
    gradients = tape.gradient(loss, ProtoCNN.trainable_weights)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py", line 1113, in gradient
    flat_grad = imperative_grad.imperative_grad(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py", line 67, in imperative_grad
    return pywrap_tfe.TFE_Py_TapeGradient(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py", line 160, in _gradient_function
    return grad_fn(mock_op, *out_grads)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/array_grad.py", line 801, in _ReshapeGrad
    array_ops.reshape(
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py", line 1176, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py", line 199, in reshape
    result = gen_array_ops.reshape(tensor, shape, name)
  File "/big/xw384/venvs/BERT/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py", line 8538, in reshape
    _result = pywrap_tfe.TFE_Py_FastPathExecute(
KeyboardInterrupt

(BERT) xw384@cci-bvm74:/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src$ ls
 baseline_loss.txt         losses.pkl             process_data.py                  Prototype_CNN_Bert.py     runs              train_bert_cascade.py                  training_validation_loss.png
 Bert_cnn.py               loss_log.txt           proto_losses.pkl                 Prototype_CNN.ipynb       test.py           train_bert_proto_cascade_add_loss.py   train_proto_cascade_add_loss.py
 BERT_CNN.py               mainbalancedpickle.p   ProtoryNet.py                    Prototype_CNN-old.ipynb   text_cnn_tf2.py   train_bert_proto_cascade.py           'visualization analysis'
'Data Exploration.ipynb'   original               Prototype_cnn_bert_continue.py   PrototypeCNN.py           text_cnn_tf.py    train_cascade.py
 data_helpers.py           output.log             Prototype_CNN_Bert.ipynb         __pycache__               tmux-buffer.txt   train_glove_cnn_cascade.py
(BERT) xw384@cci-bvm74:/big/xw384/schoolwork/NLP+DEEP LEARNING/Project/CASCADE/src$ tmux capture-pane -pS - > output.log

